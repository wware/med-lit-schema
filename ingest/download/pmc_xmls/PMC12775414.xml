<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" article-type="research-article" xml:lang="en" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Sci Rep</journal-id><journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id><journal-id journal-id-type="pmc-domain-id">1579</journal-id><journal-id journal-id-type="pmc-domain">scirep</journal-id><journal-title-group><journal-title>Scientific Reports</journal-title></journal-title-group><issn pub-type="epub">2045-2322</issn><publisher><publisher-name>Nature Publishing Group</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12775414</article-id><article-id pub-id-type="pmcid-ver">PMC12775414.1</article-id><article-id pub-id-type="pmcaid">12775414</article-id><article-id pub-id-type="pmcaiid">12775414</article-id><article-id pub-id-type="pmid">41353271</article-id><article-id pub-id-type="doi">10.1038/s41598-025-29921-3</article-id><article-id pub-id-type="publisher-id">29921</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Discriminative biomarker selection using hybrid multi-population evolutionary computation</article-title></title-group><contrib-group><contrib contrib-type="author"><name name-style="western"><surname>Shukla</surname><given-names initials="AK">Alok Kumar</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name name-style="western"><surname>Dwivedi</surname><given-names initials="S">Shubhra</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" corresp="yes"><name name-style="western"><surname>Mishra</surname><given-names initials="A">Aishwarya</given-names></name><address><email>aishwarya.mishra@jaipur.manipal.edu</email></address><xref ref-type="aff" rid="Aff2">2</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/00wdq3744</institution-id><institution-id institution-id-type="GRID">grid.412436.6</institution-id><institution-id institution-id-type="ISNI">0000 0004 0500 6866</institution-id><institution>Thapar Institute of Engineering &amp; Technology, </institution></institution-wrap>Patiala, Punjab India </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ROR">https://ror.org/02xzytt36</institution-id><institution-id institution-id-type="GRID">grid.411639.8</institution-id><institution-id institution-id-type="ISNI">0000 0001 0571 5193</institution-id><institution>Manipal University Jaipur, </institution></institution-wrap>Jaipur, Rajasthan India </aff></contrib-group><pub-date pub-type="epub"><day>6</day><month>12</month><year>2025</year></pub-date><pub-date pub-type="collection"><year>2026</year></pub-date><volume>16</volume><issue-id pub-id-type="pmc-issue-id">503847</issue-id><elocation-id>476</elocation-id><history><date date-type="received"><day>25</day><month>4</month><year>2025</year></date><date date-type="accepted"><day>20</day><month>11</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>06</day><month>12</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>08</day><month>01</month><year>2026</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2026-01-08 00:25:13.130"><day>08</day><month>01</month><year>2026</year></date></event></pub-history><permissions><copyright-statement>&#169; The Author(s) 2025</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbyncndlicense">https://creativecommons.org/licenses/by-nc-nd/4.0/</ali:license_ref><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article&#8217;s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article&#8217;s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link>.</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="41598_2025_Article_29921.pdf"/><abstract id="Abs1"><p id="Par1">The rapid advancement of Deoxyribonucleic acid (DNA) sequencing technology has gained more attention, especially in interpreting high-dimensional, low-sample-size microarray data for disease identification. However, conventional gene selection techniques struggle to identify optimal biomarker subsets from gene data within a feasible time. To address this, we propose a novel hybrid method for robust cancer classification and biomarker discovery. To reduce the dimensionality of gene data while preserving biologically meaningful patterns, in the first stage of our approach, Kernel Principal Component Analysis (KPCA) is utilized. The refined gene subsets are then processed by the Multi-Population Gravitational Search Algorithm (GSA) known as MPKGSA with Opposition-Based Learning (OBL). The hybridization mechanism involves using OBL to generate a set of opposite solutions for each population, which is then integrated into the GSA update process. This process provides a more diverse exploration of the search space, preventing premature convergence on suboptimal gene subsets. The effectiveness of MPKGSA was evaluated on six microarray cancer datasets and a breast cancer single-nucleotide polymorphism (SNP) dataset from the National Center for Biotechnology Information (NCBI) Gene Expression Omnibus (GEO). Numerical results demonstrate that MPKGSA excels at balancing convergence and diversity, achieving high prediction accuracy with minimal biomarker subsets. Furthermore, it outperformed existing meta-heuristic methods, selecting a small number of gene biomarkers strongly correlated with the biological response class, confirming its utility for precise cancer identification and classification.</p></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Minimum redundancy maximum relevance</kwd><kwd>Long short-term memory</kwd><kwd>Deep neural network</kwd><kwd>Convolution neural network</kwd><kwd>Intrusion detection</kwd></kwd-group><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Cell biology</kwd><kwd>Diseases</kwd></kwd-group><funding-group><award-group><funding-source><institution>Manipal University Jaipur</institution></funding-source></award-group><open-access><p>Open access funding provided by Manipal University Jaipur.</p></open-access></funding-group><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#169; Springer Nature Limited 2026</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Introduction</title><p id="Par2">The human genome is the full set of deoxyribonucleic acid sequence for humans. It consists approximately three billion base pairs in the double helix of DNA, more than 99% of them are the same among all populations, and less than 1% differ among individuals. The majority of DNA changes happen as Single Nucleotide Polymorphisms (SNPs). SNPs are the most important markers used for mapping diseases/cancers with genes. Over the past few years, microarray technology has been commonly used to measure the expression levels of thousands of genes simultaneously in a single experiment and analyze them to extract relevant genes to different areas of cancer types<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. Gene expression profiles represent the abundance of messenger ribonucleic acid (mRNA) corresponding to specific genes<sup><xref ref-type="bibr" rid="CR2">2</xref></sup>. Therefore, microarray technology has become a revolutionary tool for understanding human diseases. As a response, the rapid development and maturation of microarray technology allow researchers to measure the expression profiles of thousands of genes for discovering molecular disease biomarkers and aiding cancer diagnosis. To solve several issues like high-dimensionality, small sample size and noise, researchers have developed novel models that were effective and efficient for differentially expressed genes and for predicting the class of unknown samples<sup><xref ref-type="bibr" rid="CR3">3</xref>,<xref ref-type="bibr" rid="CR4">4</xref></sup>. The majority of high-dimensional gene expression data contains a significant amount of redundant genes, posing challenges for machine learning algorithms due to their high dimensionality. So, gene selection has been shown to be a successful method for improving performance by addressing several objectives, such as reducing the number of features and improving classification accuracy<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>.</p><p id="Par3">In the field of bioinformatics and precision medicine, high-dimensional data generated by high-throughput technologies can significantly impact medical diagnosis models<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>. Accurate cancer-type screening is critical for effective cancer identification and targeted treatment selection. To remove unnecessary genes from microarrays and retrieve useful information, several feature selection (FS) technique is applied<sup><xref ref-type="bibr" rid="CR7">7</xref></sup> to classify the cancer accurately. However, identifying relevant genes from tumors data is challenging due to the presence of redundant or irrelevant genes. However nature-inspired algorithms have shown promising results for selecting predictive genes<sup><xref ref-type="bibr" rid="CR8">8</xref></sup> in comparison with other gene methods. To alleviate this situation and enhance the confidence of microarray data analysis, an evolutionary optimized diverse ensemble learning framework was introduced in Ref.<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>, which improved cancer classification performance on gene expression datasets.</p><p id="Par4">Due to the vast search space, feature selection has become a critical task in modern bioinformatics, focusing on identifying important characteristics while eliminating redundant or irrelevant ones<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>. To address problems in microarray data, there are many challenges, such as sparsity of gene data, complicated data processing, and increased risk of overfitting, that are faced during predictive modeling on microarray data. Generally speaking, Feature selection (FS) plays a vital role in reducing the dimensionality of microarray datasets by selecting a subset of significant features from the original feature space based on their discriminative capability<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>. High False Positive Rate (FPR), often associated with classical methods, represents a significant drawback in tumor detection. To effectively reduce the dimensionality, principal component analysis (PCA) is used to identify relevant features with low FPR and high accuracy, which is highly desirable in order to handle high-dimensional data problems<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>.</p><p id="Par5">Groundbreaking study of author<sup><xref ref-type="bibr" rid="CR13">13</xref></sup> used the opposition-based learning (OBL) technique to enhance the efficacy of metaheuristic optimization algorithms, resulting in preventing slow convergence, susceptibility to overfitting, and convergence towards local minima. In OBL, candidate solutions from a stochastic iteration scheme are paired with their opposing solutions, which are located in different regions of the search space and are closer to the global optimum than random solutions<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>. Generally speaking, feature selection methods are classified into four types: filter, wrapper, hybrid, and embedded<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. In most cases, exhaustively searching for the optimal subset of features within a data set is nearly impossible. Recent literature has explored various wrapper techniques, including random, heuristic, and iterative search methods, for feature selection<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>. However, most existing FS techniques suffer from high computational costs and stagnation in local optima<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>. Conventional methods struggle to handle the large number of features in high-dimensional datasets. To effectively reduce data dimensionality, researchers have incorporated additional specific fitness functions into search algorithms for feature selection. To minimize features in high-dimensional datasets, some researchers have employed metaheuristic-based FS techniques such as Gravitational Search Algorithm (GSA), Ant Colony Optimization (ACO), Artificial Bee Colony (ABC), Genetic Algorithm (GA) and Correlation-based Feature Selection with particle swarm optimization for tumor cancer/tumor classification<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>.</p><p id="Par6">To address the aforementioned challenges and to improve diversity preservation, the gravitational search algorithm (GSA) is a straightforward and powerful optimization algorithm that maintains population diversity and enhances solution diversity for gene selection<sup><xref ref-type="bibr" rid="CR19">19</xref></sup>. Researchers have employed GSA as a wrapper method for gene selection to address existing limitations<sup><xref ref-type="bibr" rid="CR20">20</xref></sup>. To further explore GSA&#8217;s variants in gene selection, an investigation of multi-population mechanisms called the multi-population gravitational search algorithm (MPGSA) has been developed. Consequently, MPGSA effectively identifies irrelevant genes, preserves population diversity through rapid convergence, and maintains a robust balance between global and local search capabilities.</p><sec id="Sec2"><title>Contributions</title><p id="Par7">Although many existing metaheuristic algorithms yield impressive results on specific microarray datasets, few consistently perform well across diverse challenges<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>. To enhance the efficiency and predictive accuracy of selected feature subsets, our approach first pre-processes the feature space using principal component analysis to eliminate redundant and weakly correlated features before applying the multi-population gravitational search algorithm (MPGSA) based on the opposition-based learning (OBL) strategy. Secondly, in order to avoid local optima during optimization, the MPGSA algorithm employed an information-sharing mechanism in sub-populations for the diversity of solutions. Additionally, we employ an individual enhancement technique to optimize performance by classifying individuals in each sub-population into three layers. By integrating gene selection techniques with learning approaches, this method improves understanding of biological domains. Also our method is evaluated on a genomics data publicly available on the National Center for Biotechnology Information (NCBI) Gene Expression Omnibus (GEO). The main contributions of this study, outlined below, address the stagnation problem inherent in conventional optimization approaches:<list list-type="bullet"><list-item><p id="Par8">This paper introduced the KPCA strategy to strengthen the diversity of the gene subsets of the algorithm, which effectively removes noisy genes from the initial feature space.</p></list-item><list-item><p id="Par9">To improve solution diversity, opposition-based learning (OBL) and multi-population (MP) mechanisms are integrated into GSA to reduce the probability of the algorithm falling into local optima.</p></list-item><list-item><p id="Par10">Additionally, the integration of kernel PCA and MPKGSA boosts exploration and improves the performance of gene data sets to increase processing speed, reduce predictive error, and prevent incomprehensible and misleading data knowledge.</p></list-item><list-item><p id="Par11">By the help of support vector machine classification, a new fitness function is introduced. Additionally, compared to other SVM variants, it is discovered that the MPKGSA approach with SVM-R performs the best, achieving a high rate of accuracy and sensitivity.</p></list-item><list-item><p id="Par12">Moreover, to assess the microarray performance of MPKGSA determines the best gene subset in terms of accuracy and number of genes on the six microarray datasets and GEO data include <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="pmc:entrez-geo" xlink:href="GSE16619">GSE16619</ext-link> series.</p></list-item></list>In the proposed method, the OBL approach is used to increase the diversity of feature subsets. Then, we thoroughly assessed the performance of MPKGSA on several gene datasets. The article structure is as follows: A quick overview of the various evolutionary algorithms in the literature survey is given in &#8220;<xref rid="Sec3" ref-type="sec">Literature review</xref>&#8221; section. The existing feature selection method based on metaheuristics is discussed in &#8220;<xref rid="Sec4" ref-type="sec">Design and implementation of proposed method</xref>&#8221; section. Our wrapper algorithm for feature selection is compared with the support vector machine (SVM) strategy for six microarray datasets in &#8220;<xref rid="Sec14" ref-type="sec">Experimental analysis and discussion</xref>&#8221; section, which is followed by a conclusion in &#8220;<xref rid="Sec19" ref-type="sec">Conclusion</xref>&#8221; section.</p></sec></sec><sec id="Sec3"><title>Literature review</title><p id="Par13">High dimensionality is a significant characteristic of microarray data. Nonetheless, it may result in a decline in the efficacy of ML-based models. Dimensionality reduction may serve as a novel way to address challenges associated with high-dimensional features. Stability in feature selection is a challenging issue<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>. Although many feature selection methods for microarray studies have been out, their performances on microarray data have not been carefully evaluated. Therefore, wrapper-based feature selection results are strongly influenced by the underlying data distribution, sample size, and feature selection technique mechanisms<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>.</p><p id="Par14">From Ref.<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>, motivated to develop a novel hybrid multi-population adaptive genetic algorithm that can correctly identify cancer while ignoring the genes that are not important. There were two stages to the hybrid algorithm. In the first stage, multi-layer and F-score techniques were combined to create an ensemble gene selection method that filters out redundant and noisy genes in high-dimensional datasets. Then, in order to find the high-risk differential genes, a wrapper was created using a multi-population adaptive evolutionary algorithm that used naive Bayes classifiers and support vector machines as objective functions. Ten microarray sub-population datasets representing a wide variety of tumor types were used to assess the effectiveness of the author&#8217;s method. Additionally, the comparative tests showed that the hybrid approach worked better in terms of classification accuracy with an ideal number of genes than a variety of cutting-edge wrapper and filter techniques.</p><p id="Par15">Recent research has attempted to mitigate this high dimensionality through the application of diverse feature selection strategies. From Ref.<sup><xref ref-type="bibr" rid="CR24">24</xref></sup> study introduced novel ensemble feature selection methodologies utilising the Wilcoxon Signed Rank Sum test (WCSRS) and Fisher&#8217;s test (F-test). Data preprocessing was conducted in the initial phase of the trial. Subsequently, feature selection was conducted using the WCSRS and F-test, whereby the p-values from both the WCRSR and F-test were utilised for the identification of carcinogenic genes. The collected gene set was employed to categorise cancer patients via ensemble learning models, including extreme learning machines, random forest, extreme gradient boosting (XGBoost), CatBoost, and AdaBoost. We enhanced the performance of the ELM by optimising the settings of all ELMs via the Grey Wolf optimiser. The experimental investigation was conducted on colon cancer, encompassing 2000 genes from 62 people. The optimised XGBoost exhibited 100% accuracy while employing a WCSRS test for feature selection. The optimised CatBoost, conversely, exhibited 100% accuracy utilising the F-test for feature selection. This signifies a 15% enhancement compared to previously documented values in the literature.</p><p id="Par16">From Ref.<sup><xref ref-type="bibr" rid="CR25">25</xref></sup> method used a cellular learning automaton that adaptively regulated its update schemes to modify the behavior of each sub-population. An evolving population may experience many state transitions as the environment changes. A modified evolutionary method for one state might not be appropriate for the next, since each state requires different qualities from an optimizer. Additionally, because environmental changes occur often, a learning strategy may not have enough time to adjust to a newly encountered situation. As a result, the dynamic optimizer cannot unlearn its preexisting beliefs to support the behaviors needed to accept newly encountered states. To tackle this problem, we present a context-dependent learning strategy that can modify each sub-population behavior based on the circumstances of its various states. The proposed method&#8217;s performance was evaluated against several cutting-edge dynamic optimizers using the GDBG benchmark set.</p><p id="Par17">Current methodologies frequently focus on a singular purpose or address gene selection and categorisation separately, thus constraining their overall efficacy. In Ref.<sup><xref ref-type="bibr" rid="CR26">26</xref></sup> introduced a cohesive framework called MORPSO_ECD+ELM Gene selection and classification are framed as a multimodal multiobjective optimisation problem to concurrently optimise both objectives. The framework presents two principal innovations: an enhanced crowding distance metric to augment diversity preservation and an advanced multi-objective particle swarm optimisation variant (MORPSO_ECD) that integrates ECD and ring topography to efficiently navigate the MMOP solution space. Designed system together with the Extreme Learning Machine, accomplishes robust and efficient cancer categorisation. Comprehensive experimental validations indicate that the suggested method attained elevated classification accuracy while discerning biologically relevant gene subsets, offering a robust strategy to connect gene selection with cancer classification.</p><p id="Par18">The research proposed a multiple kernel learning (MKL) integrated multi-objective swarm intelligence method to find prospective biomarker genes from the transcriptome profiles of arsenicosis data<sup><xref ref-type="bibr" rid="CR27">27</xref></sup>. A multi-objective random spatial local best particle swarm optimisation (MO-RSplbestPSO) has been employed to get optimal classification accuracy while minimising the number of genes. The suggested MO-RSplbestPSO additionally directs the multiple kernel learning method, facilitating data-specific categorisation. The proposed computational framework has been utilised on the generated whole-genome DNA microarray created from blood samples obtained from a designated arsenic-exposed region in the Indian state of West Bengal. A collection of twelve biomarker genes, including four unique genes, has been effectively found for the classification of arsenic exposure and its subcategories, which may serve as future predictive biomarkers for screening arsenic-exposed populations. The biological importance of each gene is elaborated to clarify the intricate molecular networking and mechanism of toxicity.</p><p id="Par19">By Ref.<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>, the Binary HOA and BHOA-CM, an enhanced version, were examined. By altering their pace in reaction to the slope of the ground, HOA successfully climbs mountains by imitating hikers&#8217; adaptive behaviour. Continuous values were transformed into binary outputs using a hyperbolic tangent transfer function. In order to enhance the algorithm&#8217;s ability to exploit gene selection, BHOA-CM combined one-point crossover and self-adaptive mutation operators. Differential Expressed Genes analysis was the first step in finding pertinent genes. BHOA and BHOA-CM were employed with a hybrid classifier that integrated Adaptive Sparse Partial Least Square and Logistic Regression in order to optimise gene selection performance. Experimental results on six benchmark microarray datasets showed that the author&#8217;s strategy outperformed recent state-of-the-art strategies in classification accuracy while selecting fewer marker genes.</p><p id="Par20">In Ref.<sup><xref ref-type="bibr" rid="CR29">29</xref></sup>, a method was developed to create a dual-angle feature for single-modal gene data to enhance efficacy and robustness, addressing the challenge of high-dimensional tumour classification. The proposed framework comprises three components: Deep matrix factorisation, double-angle decomposition, and feature purification. A robust deep matrix factorisation model was suggested for feature learning to improve classification stability and achieve superior features in the presence of noisy data. Secondly, the double-angle feature (RDMF-DA) was constructed by cascading the RDMF features with sparse features, hence including more complete information within gene data. Third, to mitigate the impact of redundant genes on representation capability, a gene selection technique was given to refine the features using RDMF-DA, grounded in the principles of sparse representation and gene coexpression. The suggested technique was ultimately applied to gene expression profiling datasets, and its performance was thoroughly validated.</p><p id="Par21">Combining different algorithms to determine the most efficient method of SNP data processing is the primary objective of Ref.<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>. As a result, an effective technique is put forth to classify sick and healthy samples and find important SNPs. First, in this context, the nominal SNP data is converted to numeric using Mean Encoding, an intelligent technique. The redundant and unnecessary features are then eliminated by feature selection using a two-step filter approach. Lastly, classification is done using the suggested deep auto-encoder, which automatically builds its structure from input data. We use five distinct SNP datasets&#8212;thyroid cancer, mental retardation, breast cancer, colorectal cancer, and autism&#8212;obtained from the Gene Expression Omnibus (GEO) dataset to assess the suggested methodology. With 100%, 94.4%, 100%, 96%, and 99.1% accuracy, respectively, the suggested method has been successful in feature selection and classification, allowing it to classify healthy and sick samples based on specific features in thyroid cancer, mental retardation, breast cancer, colorectal cancer, and autism. When compared to previous published efforts, the results show that it has achieved excellent efficiency.</p><p id="Par22">To solve the stagnation problem, Ref.<sup><xref ref-type="bibr" rid="CR31">31</xref></sup> presented two new migration policies in a multi-population version of the kidney-inspired algorithm (KA). The first algorithm, MultiPop-KA, carried out a preset migration policy. On the other hand, the second algorithm, AutoMultiPop-KA, used an adaptive migration policy selection procedure that chooses the kind of migration depending on the average fitness of sub-populations. These strategies seek to improve the KA efficacy by leveraging a multi-population framework and combining two migration policies to attain a more sophisticated balance between exploration and exploitation. The effectiveness of suggested methods was demonstrated by experimental assessments applied to 18 benchmark feature selection problems and completed across 25 test functions. These findings suggest that the AutoMultiPop-KA strategy can greatly improve the overall quality and performance of optimization algorithms.</p></sec><sec id="Sec4"><title>Design and implementation of proposed method</title><p id="Par23">Many gene selection algorithms based on DNA datasets are used today<sup><xref ref-type="bibr" rid="CR32">32</xref></sup>. To overcome the drawbacks of rule-based systems, many gene datasets employ meta-heuristic techniques in examining large DNA data structures to identify identifiable patterns or models<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>. Additionally, effectively identifying patterns of regular activity to spot irregularities, extracting DNA sequences to spot misuse, and developing classifiers to spot tumor/cancer types are all possible with machine learning. More adaptability and deployment ability may be possible with nature-inspired methods<sup><xref ref-type="bibr" rid="CR34">34</xref></sup>. Instead of finding the optimal optimization solution, these algorithms seek to find one reasonably excellent. So, in this study, a new variant of GSA meta-heuristic algorithms is utilized. Additionally, the majority of researchers have thought of a promising and successful wrapper technique for choosing feature subsets that are optimal or nearly optimal, including Particle Swarm Optimization (PSO)<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>, TLBO<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>, DE<sup><xref ref-type="bibr" rid="CR37">37</xref></sup>, Genetic Algorithm (GA)<sup><xref ref-type="bibr" rid="CR38">38</xref></sup>. Gravitational Search Algorithm (GSA)<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>.</p><p id="Par24">To address the above issues, we propose a wrapper-based feature selection method based on KPCA and MPGSA while OBL is utilised to boost population diversity. Combining Kernel PCA model with multi-population GSA algorithm is used to enhance search efficiency and avoiding local optima stagnation. The KPCA approach reduces the high dimension of the gene datasets in the first stage of the search process, while OBL is utilised to boost population diversity when populations are generated by GSA. In used gene datasets, the variance of each of the original attributes is computed in order to evaluate the eigenvalues and eigenvectors. The second step of the gene selection procedure, MPKGSA, uses the created multi-population wrapper feature selection. The number of characteristics was decreased with the KPCA method. Once more, the MPGSA feature selection method is used to decrease features. The second phase uses the SVM-R classifier to identify the different forms of cancer or tumours. Figures <xref rid="Fig1" ref-type="fig">1</xref> and <xref rid="Fig2" ref-type="fig">2</xref> display the framework for our gene selection model.</p><sec id="Sec5"><title>Opposition-based learning (OBL)</title><p id="Par25">The concept of opposition-based learning (OBL) was first proposed in 2005<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>. Since then, OBL has been widely applied to improve the performance of metaheuristic algorithms, reinforcement learning, and other machine intelligence techniques. Using OBL to help a metaheuristic optimisation algorithm locate the global optimum is the primary objective of this work. Usually, a metaheuristic starts with a population that is generated at random and updates the current solutions in an interactive manner. OBL is used to create the opposite of the present answer. After that, OBL compares the current solution to the corresponding opposing solution and retains the better one. Therefore, OBL may facilitate the discovery of optima and accelerate the convergence of the meta-heuristic algorithm. Suppose that x is a real number that belongs to the interval [u,l]; the opposite value of several x is defined as:<disp-formula id="Equ25"><tex-math id="d33e443">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \bar{x} = u_N + l_N - x, \end{aligned}$$\end{document}</tex-math></disp-formula>where <inline-formula id="IEq1"><tex-math id="d33e447">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$u_N$$\end{document}</tex-math></inline-formula> and <inline-formula id="IEq2"><tex-math id="d33e451">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$l_N$$\end{document}</tex-math></inline-formula> are the upper and lower values of the feature selection, respectively. For higher-dimensional micro-array, let <inline-formula id="IEq3"><tex-math id="d33e455">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x=(x_1,x_2,...,x_N)$$\end{document}</tex-math></inline-formula> belongs to <inline-formula id="IEq4"><tex-math id="d33e460">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$R_N$$\end{document}</tex-math></inline-formula> be a N-dimension matrix, where <inline-formula id="IEq5"><tex-math id="d33e464">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_i$$\end{document}</tex-math></inline-formula> belongs to <inline-formula id="IEq6"><tex-math id="d33e468">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$[u_i,l_i]$$\end{document}</tex-math></inline-formula> , i=1,2,...,N . The opposite vector <inline-formula id="IEq7"><tex-math id="d33e472">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{x}$$\end{document}</tex-math></inline-formula> can be defined as:<disp-formula id="Equ26"><tex-math id="d33e476">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \bar{ {\varvec{x}}} = \left( {{\bar{x}_{1},{\bar{x}_{2}}, \ldots ,{\bar{x}_{N}}} }\right) ,\end{aligned}$$\end{document}</tex-math></disp-formula>where <inline-formula id="IEq8"><tex-math id="d33e480">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\bar{x}$$\end{document}</tex-math></inline-formula> = <inline-formula id="IEq9"><tex-math id="d33e485">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$u_i + l_i- x_i$$\end{document}</tex-math></inline-formula> , i=1,2,...,N . Furthermore, if x is a binary matrix, <inline-formula id="IEq10"><tex-math id="d33e489">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x=(x_1,x_2,...,x_N)$$\end{document}</tex-math></inline-formula> belongs to (0,1) , then <inline-formula id="IEq11"><tex-math id="d33e493">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$u_i$$\end{document}</tex-math></inline-formula>=1 , <inline-formula id="IEq12"><tex-math id="d33e497">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$l_i$$\end{document}</tex-math></inline-formula>=0 . Thus, in binary space, the opposite vector of x is defined as:<disp-formula id="Equ27"><tex-math id="d33e501">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \bar{ {\varvec{x}}} = \left( {{1-{x_{1}},1-{x_{2}}, \ldots ,1-{x_{N}}} }\right) . \end{aligned}$$\end{document}</tex-math></disp-formula></p></sec><sec id="Sec6"><title>Kernel-principal-component-analysis</title><p id="Par26">Despite the limitations, PCA is still a powerful method for data analysis, visualization, and dimensional reduction<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>. Because of numerous modifications were developed to overcome its drawbacks and broaden the scope of applications. Kernel principal component analysis, or PCA, is a nonlinear generalization of PCA using kernel methods, also known as the &#8220;kernel trick. The main idea is to map the original data non-linearly into a feature space <italic toggle="yes">Fe</italic> by<disp-formula id="Equ1"><label>1</label><tex-math id="d33e515">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \delta : R^N \rightarrow Fe, \end{aligned}$$\end{document}</tex-math></disp-formula>and then perform PCA, which implicitly defines nonlinear principal components in the original data space. Even if <italic toggle="yes">Fe</italic> has an arbitrarily large dimension, for certain choices of <inline-formula id="IEq13"><tex-math id="d33e523">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\delta$$\end{document}</tex-math></inline-formula>, it is still possible to perform PCA in <italic toggle="yes">Fe</italic>.</p><p id="Par27">Consider a microarray data set <italic toggle="yes">X</italic> containing <italic toggle="yes">S</italic> tissues of <italic toggle="yes">D</italic> biomarkers <inline-formula id="IEq14"><tex-math id="d33e542">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(D &lt; S)$$\end{document}</tex-math></inline-formula> and a non-linear transformation <inline-formula id="IEq15"><tex-math id="d33e546">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\delta (x)$$\end{document}</tex-math></inline-formula> into an <italic toggle="yes">N</italic>-dimensional feature space <italic toggle="yes">Fe</italic>. For now, let us assume that projected gene datasets are centered, so <inline-formula id="IEq16"><tex-math id="d33e557">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\dfrac{1}{S}\sum _{n=1}^{S}{\delta (x_n)}=0$$\end{document}</tex-math></inline-formula>. The <inline-formula id="IEq17"><tex-math id="d33e561">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M \times N$$\end{document}</tex-math></inline-formula> covariance matrix in feature space is given by<disp-formula id="Equ2"><label>2</label><tex-math id="d33e565">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Co = \dfrac{1}{S}\sum _{n=1}^{S}{\delta (x_n)\delta (x_n)^T}. \end{aligned}$$\end{document}</tex-math></disp-formula></p><p id="Par28">We need to solve the following eigenvalue problem<disp-formula id="Equ3"><label>3</label><tex-math id="d33e571">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Co \varvec{v}_i = \lambda _i \varvec{v}_i, \end{aligned}$$\end{document}</tex-math></disp-formula><inline-formula id="IEq18"><tex-math id="d33e575">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i=1,...,N$$\end{document}</tex-math></inline-formula>. Our goal is to solve this equation without working directly in the feature space as, due to its size, this will be computationally inefficient. Substituting <italic toggle="yes">Co</italic> from (<xref rid="Equ2" ref-type="disp-formula">2</xref>) we get<disp-formula id="Equ4"><label>4</label><tex-math id="d33e585">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \dfrac{1}{S} \sum _{n=1}^{S} {\delta (x_n)\{\delta (x_n)^T \varvec{v}_i\}} = \lambda _i \varvec{v}_i. \end{aligned}$$\end{document}</tex-math></disp-formula></p><p id="Par29">Provided <inline-formula id="IEq19"><tex-math id="d33e591">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda _i &gt; 0$$\end{document}</tex-math></inline-formula>, the vector <inline-formula id="IEq20"><tex-math id="d33e595">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v_i$$\end{document}</tex-math></inline-formula> is given by a linear combination of the <inline-formula id="IEq21"><tex-math id="d33e599">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\delta (x_n)$$\end{document}</tex-math></inline-formula> and so <inline-formula id="IEq22"><tex-math id="d33e603">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\forall \ i \ \exists$$\end{document}</tex-math></inline-formula> column vector <inline-formula id="IEq23"><tex-math id="d33e607">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\alpha }_i \in R^S$$\end{document}</tex-math></inline-formula> such that:<disp-formula id="Equ5"><label>5</label><tex-math id="d33e612">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \ v_i = \sum _{n=1}^{S}{\alpha _{in}\delta (x_n)}. \end{aligned}$$\end{document}</tex-math></disp-formula></p><p id="Par30">Substituting (<xref rid="Equ2" ref-type="disp-formula">2</xref>) and (<xref rid="Equ5" ref-type="disp-formula">5</xref>) into (<xref rid="Equ3" ref-type="disp-formula">3</xref>), we obtain<disp-formula id="Equ6"><label>6</label><tex-math id="d33e627">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \dfrac{1}{S}\sum _{n=1}^{S}{\delta (x_n)\delta (x_n)^T} \sum _{m=1}^{S}{\alpha _{im}\delta (x_m)^T} = \lambda _i \sum _{n=1}^{S}{\alpha _{in}\delta (x_n)^T}. \end{aligned}$$\end{document}</tex-math></disp-formula></p><p id="Par31">The key thing here is to express last equation in terms of kernel function defined as <inline-formula id="IEq24"><tex-math id="d33e633">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k(x_n, x_m) = \delta (x_n)^T\delta (x_m)$$\end{document}</tex-math></inline-formula>. It is done by multiplying both sides by <inline-formula id="IEq25"><tex-math id="d33e637">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\delta (x_l)^T$$\end{document}</tex-math></inline-formula> which results to the next:<disp-formula id="Equ7"><label>7</label><tex-math id="d33e641">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \dfrac{1}{S}\sum _{n=1}^{S}{k(x_l, x_m)} \sum _{m=1}^{S}{\alpha _{im}k(x_n, x_m)} = \lambda _i \sum _{n=1}^{S}{\alpha _{in}k(x_l, x_m)}, \end{aligned}$$\end{document}</tex-math></disp-formula>or in matrix notation<disp-formula id="Equ8"><label>8</label><tex-math id="d33e646">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} K^2 \varvec{\alpha }_i = \lambda _i S K \varvec{\alpha }_i. \end{aligned}$$\end{document}</tex-math></disp-formula></p><p id="Par32">If we remove a factor of K from both sides, we obtain the following eigenvalue problem<disp-formula id="Equ9"><label>9</label><tex-math id="d33e652">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} K \varvec{\alpha }_i = \lambda _i S \varvec{\alpha }_i. \end{aligned}$$\end{document}</tex-math></disp-formula></p><p id="Par33">By solving the problem,m we find eigenvectors <inline-formula id="IEq26"><tex-math id="d33e658">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\varvec{\alpha }_i$$\end{document}</tex-math></inline-formula>. Note that solutions of (<xref rid="Equ8" ref-type="disp-formula">8</xref>) and (<xref rid="Equ9" ref-type="disp-formula">9</xref>) differ only by eigenvectors that correspond to zero eigenvalues of K, hence removing <italic toggle="yes">K</italic> from both sides of (<xref rid="Equ8" ref-type="disp-formula">8</xref>) does not affect principal components.</p><p id="Par34">So far, we assumed that the projected data set has zero mean. But in general, it will not be the case. The standard way to centralize a data set is to compute the mean and subtract it from every data point. Here, we wish to avoid working in feature space and express everything regarding kernel function. Let&#8217;s denote the projected data set after centering as <inline-formula id="IEq27"><tex-math id="d33e676">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widetilde{\delta }(x_n)$$\end{document}</tex-math></inline-formula>.<disp-formula id="Equ10"><label>10</label><tex-math id="d33e680">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \widetilde{\delta }(x_s) = \delta (x_s) - \frac{1}{S}\sum _{l=1}^{S} \delta (x_l), \end{aligned}$$\end{document}</tex-math></disp-formula>and the corresponding elements of the Gram matrix<disp-formula id="Equ11"><label>11</label><tex-math id="d33e685">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} K_{sm} &amp; = \widetilde{\delta }(x_s)^T\widetilde{\delta }(x_m) = \delta (x_s)^T\delta (x_m) - \sum _{l=1}^{S}{\delta (x_s)^T\delta (x_l)} \\&amp; \quad - \sum _{l=1}^{S}{\delta (x_l)^T\delta (x_m)} + \dfrac{1}{S^2}\sum _{j=1}^{S}\sum _{l=1}^{S}{\delta (x_j)^T\delta (x_l)}\\ &amp; = k(x_s, x_m) - \sum _{l=1}^{S}{k(x_s, x_l)} - \sum _{l=1}^{S}{k(x_l, x_m)} + \dfrac{1}{S^2}\sum _{j=1}^{S}\sum _{l=1}^{S}{k(x_j, x_l)}, \end{aligned}$$\end{document}</tex-math></disp-formula>or in a matrix notation<disp-formula id="Equ12"><label>12</label><tex-math id="d33e690">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \widetilde{K} = K - 1_SK - K1_S + 1_SK1_S, \end{aligned}$$\end{document}</tex-math></disp-formula>where <inline-formula id="IEq28"><tex-math id="d33e695">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widetilde{K}$$\end{document}</tex-math></inline-formula> is centered kernel matrix, <inline-formula id="IEq29"><tex-math id="d33e700">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1_S$$\end{document}</tex-math></inline-formula> is <inline-formula id="IEq30"><tex-math id="d33e704">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$S \times S$$\end{document}</tex-math></inline-formula> matrix in which every element equals to <inline-formula id="IEq31"><tex-math id="d33e708">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\dfrac{1}{S}$$\end{document}</tex-math></inline-formula><sup><xref ref-type="bibr" rid="CR42">42</xref></sup>. So, we can evaluate <inline-formula id="IEq32"><tex-math id="d33e715">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widetilde{K}$$\end{document}</tex-math></inline-formula> using only the kernel function.</p><p id="Par35">After solving the eigenvalue problem <inline-formula id="IEq33"><tex-math id="d33e721">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\widetilde{K}\varvec{\alpha }_i = \lambda _i S \varvec{\alpha }_i$$\end{document}</tex-math></inline-formula>, We can find projections of principal components in terms of kernel function. Using (<xref rid="Equ5" ref-type="disp-formula">5</xref>), projection of a point <italic toggle="yes">x</italic> onto eigenvector <italic toggle="yes">i</italic> is given by<disp-formula id="Equ13"><label>13</label><tex-math id="d33e734">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \delta (x)^T \varvec{v}_i = \sum _{s=1}^{S}{\alpha _{in}\delta (x)^T\delta (x_s)} = \sum _{s=1}^{S}{\alpha _{in}k(x, x_s)}. \end{aligned}$$\end{document}</tex-math></disp-formula></p><p id="Par36">Note that neither (<xref rid="Equ3" ref-type="disp-formula">3</xref>) nor (<xref rid="Equ13" ref-type="disp-formula">13</xref>) requires the <inline-formula id="IEq34"><tex-math id="d33e747">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\delta (x)$$\end{document}</tex-math></inline-formula> in explicit form, we only need their dot product to use kernel function without actually performing the map <inline-formula id="IEq35"><tex-math id="d33e751">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\delta$$\end{document}</tex-math></inline-formula>.<fig id="Fig1" position="float" orientation="portrait"><label>Fig. 1</label><caption><p>Multi-population scheme for evolutionary gene selection.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="MO1" position="float" orientation="portrait" xlink:href="41598_2025_29921_Fig1_HTML.jpg"/></fig></p><p id="Par37">Kernel principal component analysis (KPCA) provides a powerful nonlinear dimensionality reduction approach for gene expression analysis. Given a microarray dataset <inline-formula id="IEq36"><tex-math id="d33e764">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$X = \{x_1, x_2, \ldots , x_n\} \in \mathbb {R}^d$$\end{document}</tex-math></inline-formula> where <italic toggle="yes">n</italic> is the number of samples and <italic toggle="yes">d</italic> is the number of genes, KPCA transforms the data while preserving complex gene interactions.<disp-formula id="Equ28"><tex-math id="d33e774">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} \phi : \mathbb {R}^d \rightarrow \mathscr {F}, \quad x \mapsto \phi (x), \end{aligned}$$\end{document}</tex-math></disp-formula>where <inline-formula id="IEq37"><tex-math id="d33e778">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi$$\end{document}</tex-math></inline-formula> maps the gene expression vectors to a higher-dimensional feature space <inline-formula id="IEq38"><tex-math id="d33e783">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathscr {F}$$\end{document}</tex-math></inline-formula> implicitly defined by the kernel function <inline-formula id="IEq39"><tex-math id="d33e787">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k(x_i,x_j) = \langle \phi (x_i), \phi (x_j) \rangle$$\end{document}</tex-math></inline-formula>. The algorithm begins by constructing the kernel matrix <inline-formula id="IEq40"><tex-math id="d33e791">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$K \in \mathbb {R}^{n \times n}$$\end{document}</tex-math></inline-formula>:<disp-formula id="Equ29"><tex-math id="d33e795">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} K_{ij} = k(x_i, x_j). \end{aligned}$$\end{document}</tex-math></disp-formula></p><p id="Par38">Common kernel choices for gene expression data including Radial Basis Function (RBF), Polynomial Kernel. The kernel matrix is centered to remove biases:<disp-formula id="Equ30"><tex-math id="d33e800">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} K_c = K - 1_n K - K 1_n + 1_n K 1_n, \end{aligned}$$\end{document}</tex-math></disp-formula>where <inline-formula id="IEq41"><tex-math id="d33e804">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$1_n$$\end{document}</tex-math></inline-formula> is an <inline-formula id="IEq42"><tex-math id="d33e808">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n \times n$$\end{document}</tex-math></inline-formula> matrix with all elements equal to <inline-formula id="IEq43"><tex-math id="d33e812">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{1}{n}$$\end{document}</tex-math></inline-formula>. This step ensures the data has a zero mean in the feature space. KPCA solves the eigenvalue problem:<disp-formula id="Equ31"><tex-math id="d33e816">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} K_c v_i = \lambda _i v_i. \end{aligned}$$\end{document}</tex-math></disp-formula></p><p id="Par39">The eigenvalues <inline-formula id="IEq44"><tex-math id="d33e821">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\lambda _i$$\end{document}</tex-math></inline-formula> are sorted in descending order, and the top <italic toggle="yes">m</italic> eigenvectors corresponding to the largest eigenvalues are selected. Each eigenvector <inline-formula id="IEq45"><tex-math id="d33e828">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$v_i$$\end{document}</tex-math></inline-formula> represents a principal component in the feature space. The gene expression data is projected onto the new feature space:<disp-formula id="Equ32"><tex-math id="d33e832">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} z_i = \sum _{j=1}^{n} \alpha _j k(x_i, x_j), \end{aligned}$$\end{document}</tex-math></disp-formula>where <inline-formula id="IEq46"><tex-math id="d33e836">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha _j$$\end{document}</tex-math></inline-formula> is the <italic toggle="yes">j</italic>-th component of the eigenvector. The transformed dataset <inline-formula id="IEq47"><tex-math id="d33e844">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Z = \{z_1, z_2, \ldots , z_n\} \in \mathbb {R}^m$$\end{document}</tex-math></inline-formula> captures the most biologically relevant variations in the gene expression data.</p><p id="Par40">The combination of KPCA with the multi-population evolutionary algorithm enables efficient search for optimal gene subsets in the transformed feature space. This approach is particularly effective for identifying small biomarker panels from thousands of genes, discovering nonlinear gene interactions that affect disease phenotypes, and improving classification performance while maintaining biological interpretability.</p></sec><sec id="Sec7"><title>Multi-population scheme</title><p id="Par41">Several multi-population methods have been implemented into evolutionary algorithms to solve numerous problems to improve the searchability of EAs<sup><xref ref-type="bibr" rid="CR43">43</xref></sup>. Inspired by biological/natural evolution processes. firstly, this method decomposes the initial population in multi-population into several small sub-populations. Then, these sub-populations are evaluated in parallel using GSA. Finally, to find optimal solutions, different sub-populations collaborate to search other local areas.</p><p id="Par42">The size of the population can significantly influence the average calculation time of EAs, transforming exponential time into polynomial time under certain circumstances. Studies have revealed that introducing a population can enhance the first striking probability<sup><xref ref-type="bibr" rid="CR44">44</xref>,<xref ref-type="bibr" rid="CR45">45</xref></sup>. Therefore, adjusting the population size to an appropriate value is advisable to minimize calculation time and improve the striking probability. A practical approach to managing population size, which reduces calculation time without compromising diversity, involves dividing a large initial population into multiple smaller sub-populations and performing parallel executions. The prevailing research literature presents two primary approaches. The first approach involves a multi-population scheme, where each sub-population follows a distinct strategy. However, one specific sub-population maintains the same search strategy throughout the process. The second approach is a single population scheme incorporating multiple strategies and parameters. A set of parameters is selected as the current parameters based on specific rules. This approach frequently switches between multiple evolutionary strategies, with each evolution using only one strategy<sup><xref ref-type="bibr" rid="CR46">46</xref></sup>. It is possible to adjust the algorithm parameters to leverage parallel computing and reduce computational time to ensure compatibility with parallel processing. With this in mind, the algorithm proposed in this study divides the entire population into equal N sub-populations. Each subpopulation size is set to Pop/N, and mutation strategies and control parameters are applied. Notably, Pop&#8217;s overall population size remains, thereby preserving population diversity and preventing premature convergence, as seen in Fig. <xref rid="Fig2" ref-type="fig">2</xref>.</p><sec id="Sec8"><title>Information exchange scheme</title><p id="Par43">In this study, we have utilized cross-sub-population migration as an information communication scheme that replaces solutions based on the solution quality implemented by probabilistic choosing<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>. Then, we find the pairs of sub-populations suitable for migration based on the levels of sub-populations. We use the distance levels to decide which sub-populations to migrate to or from Ref.<sup><xref ref-type="bibr" rid="CR47">47</xref></sup>. The rationale behind this approach is that sub-populations exhibiting higher fitness distance are more likely to benefit from migration than those with lower distance. Once the pair of sub-populations to migrate from is determined, we can calculate the distance between the solution being replaced, and then the sub-population will be selected. The utilization of distance is rooted in diversity, recognizing that a more diverse population offers increased opportunities for discovering optimal solutions.<fig id="Fig2" position="float" orientation="portrait"><label>Fig. 2</label><caption><p>Architecture of the proposed wrapper model.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="MO2" position="float" orientation="portrait" xlink:href="41598_2025_29921_Fig2_HTML.jpg"/></fig></p></sec></sec><sec id="Sec9"><title>Gravitational search algorithm</title><p id="Par44">Gravitational search algorithm (GSA) is a nature-inspired metaheuristic optimization technique that mimics Newton&#8217;s law of gravitation to solve complex feature selection problems in high-dimensional genomic data<sup><xref ref-type="bibr" rid="CR48">48</xref></sup>. In GSA, candidate solutions (gene subsets) are treated as masses in a search space, where their fitness determines their gravitational attraction. Higher-quality solutions exert stronger forces on others. Every agent is also attracted to every other agent. Newton&#8217;s universal law of gravity is used to calculate the gravitational force of each element, and Newton&#8217;s rule of movement is used to calculate the speed of each factor. The agents can scan the search space for the best answers after applying the gravitational force. GSA has a number of advantageous characteristics over other evolutionary systems, including ease of usage, reliable performance, and fewer tweaking limitations. The method skips over each mass randomly generated value throughout the whole search space in a system with pop agents. The gravitational forces (F) from agent j on agent i at a specific moment <inline-formula id="IEq48"><tex-math id="d33e901">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t_0$$\end{document}</tex-math></inline-formula> are defined by Eq. (14) as the learning duration.<disp-formula id="Equ14"><label>14</label><tex-math id="d33e905">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Fr_{i,j}^{d}\left( t_0 \right) =Gr\left( t_0 \right) \frac{M_{pi}^{t_0}\text {*}M_{aj}^{t_0}}{R_{pi}^{t_0}+ \phi }\left( x_{j}^{d}\left( t_0 \right) +x_{i}^{d}\left( t_0 \right) \right) . \end{aligned}$$\end{document}</tex-math></disp-formula></p><p id="Par45"><inline-formula id="IEq49"><tex-math id="d33e910">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_{aj}^{t_0} \!\!~\!\!\;\;$$\end{document}</tex-math></inline-formula> represents the active gravitational mass connected with pop <italic toggle="yes">j</italic>, whereas <inline-formula id="IEq50"><tex-math id="d33e917">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_{pi}^{t}$$\end{document}</tex-math></inline-formula> represents the passive gravitational mass associated with pop <italic toggle="yes">j</italic>. The Euclidian distance between two agents <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic> is represented as <inline-formula id="IEq51"><tex-math id="d33e931">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\;\;\!\!~\!\;\;R_{i,j}^{t}$$\end{document}</tex-math></inline-formula>, <italic toggle="yes">i</italic>, <inline-formula id="IEq52"><tex-math id="d33e938">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G(t_0)$$\end{document}</tex-math></inline-formula> is the gravity constant at time <inline-formula id="IEq53"><tex-math id="d33e942">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t_0$$\end{document}</tex-math></inline-formula>, and <inline-formula id="IEq54"><tex-math id="d33e946">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\phi$$\end{document}</tex-math></inline-formula> is a small constant. The formula of <inline-formula id="IEq55"><tex-math id="d33e950">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$Gr\left( t \right)$$\end{document}</tex-math></inline-formula> is estimated using Eq. (15).<disp-formula id="Equ15"><label>15</label><tex-math id="d33e955">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Gr(t)=G_0*exp(-alpha*\frac{iter}{\aleph }). \end{aligned}$$\end{document}</tex-math></disp-formula></p><p id="Par46"><inline-formula id="IEq56"><tex-math id="d33e960">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{G}_{0}}$$\end{document}</tex-math></inline-formula> is set to 100, <inline-formula id="IEq57"><tex-math id="d33e964">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\textit{iter}$$\end{document}</tex-math></inline-formula> displays the current iteration, and <inline-formula id="IEq58"><tex-math id="d33e968">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\aleph$$\end{document}</tex-math></inline-formula> displays the maximum number of generations. The alpha value, which was obtained straight from<sup><xref ref-type="bibr" rid="CR49">49</xref></sup>, is 20. Equation (16) is used to determine the total force acting on <italic toggle="yes">i</italic>.<disp-formula id="Equ16"><label>16</label><tex-math id="d33e979">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} Fr_{i}^{d}\left( t_0 \right) =\underset{j=1,j\ne i}{\overset{N}{\mathop \sum }}\,ran{{d}_{j}}Fr_{i,j}^{d}\left( t_0 \right) , \end{aligned}$$\end{document}</tex-math></disp-formula>where <inline-formula id="IEq59"><tex-math id="d33e985">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ran{{d}_{j}}$$\end{document}</tex-math></inline-formula> indicates that the random number is in the range of 0 to 1. According to the law of motion idea, an agent&#8217;s acceleration is inversely proportional to its mass and relative to the resulting force; hence, Eq. (19) may be used to quantify the acceleration of all pops.<disp-formula id="Equ17"><label>17</label><tex-math id="d33e989">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} A_{i}^{d}\left( t \right) =\frac{Fr_{i}^{d}\left( t_n \right) }{M_{i,i}^{t}}, \end{aligned}$$\end{document}</tex-math></disp-formula>where <inline-formula id="IEq60"><tex-math id="d33e994">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ran{{d}_{j}}$$\end{document}</tex-math></inline-formula> denotes the random value in the interval [0, 1], <inline-formula id="IEq61"><tex-math id="d33e998">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t_n$$\end{document}</tex-math></inline-formula> denotes the precise time, and <inline-formula id="IEq62"><tex-math id="d33e1002">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_{i,i}^{t}$$\end{document}</tex-math></inline-formula> denotes the mass of object <italic toggle="yes">i</italic>. First, GSA initializes all masses with random integers. Every mass serves as a potential solution. Equations (15)&#8211;(17) are used to determine accelerations, total forces, and the gravitational constant. We may update the gravitational and inertial masses using the equations above, as shown in Eqs. (18) and (19).<disp-formula id="Equ18"><label>18</label><tex-math id="d33e1010">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} &amp; m_i (t)= \frac{fr_i (t_n)-worse(t_n))}{(best(t_n)-worse(t_n))}, \end{aligned}$$\end{document}</tex-math></disp-formula><disp-formula id="Equ19"><label>19</label><tex-math id="d33e1014">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} &amp; M_i (t_n) = \frac{m_i (t_n)}{\sum _{j=1}^{nPop}(m_j (t_n) )}. \end{aligned}$$\end{document}</tex-math></disp-formula></p><p id="Par47">Equations (20) and (21) define worst (<inline-formula id="IEq63"><tex-math id="d33e1020">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t_n$$\end{document}</tex-math></inline-formula>) and best (<inline-formula id="IEq64"><tex-math id="d33e1024">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t_n$$\end{document}</tex-math></inline-formula>), while <inline-formula id="IEq65"><tex-math id="d33e1028">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$f_i (t_n)$$\end{document}</tex-math></inline-formula> denotes the fitness value of the agent <italic toggle="yes">i</italic> at time <inline-formula id="IEq66"><tex-math id="d33e1035">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t_n$$\end{document}</tex-math></inline-formula>.<disp-formula id="Equ20"><label>20</label><tex-math id="d33e1040">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} &amp; best(t_n)= min_{j \in (1,...,nPop)} fr_j (t), \end{aligned}$$\end{document}</tex-math></disp-formula><disp-formula id="Equ21"><label>21</label><tex-math id="d33e1044">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} &amp; worse(t_n)= max_{j \in (1,...,nPop)} fr_j (t), \end{aligned}$$\end{document}</tex-math></disp-formula>where j=1,2,...,nPop. Additionally, an agent&#8217;s upcoming velocity is calculated as a proportion of its current velocity plus acceleration. Consequently, Eqs. (22) and (23) might be used to determine its position and velocity.<disp-formula id="Equ22"><label>22</label><tex-math id="d33e1049">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} &amp; v_{i}^{d}\left( t_n+1 \right) =rand_{i} * v_{i}^{d}\left( t_n \right) + A_{i}^{d}(t_n), \end{aligned}$$\end{document}</tex-math></disp-formula><disp-formula id="Equ23"><label>23</label><tex-math id="d33e1053">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} &amp; x_{i}^{d}\left( t_n+1 \right) = x_{i}^{d}\left( t_n \right) + v_{i}^{d}(t_n+1). \end{aligned}$$\end{document}</tex-math></disp-formula></p><p id="Par48">In the interval [0,1], <inline-formula id="IEq67"><tex-math id="d33e1059">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$rand_i$$\end{document}</tex-math></inline-formula> is a uniform random variable. We give the search a randomized characteristic by using this random integer.</p><p id="Par49">For biomarkers, to improve their population diversity in the search space, kernel principal component analysis (KPCA) and the MP-gravitational optimization algorithm, called MPKGSA, are introduced. Kernel principal component analysis is introduced for feature dimensionality to extract the most essential features. The obtained features are input for dimensionality reduction. The method&#8217;s overall performance can be improved by effectively transforming a multidimensional input set. The capacity to summarize the entire input. Then, MPKGSA incorporates a division of the entire population into sub-populations. This ground-breaking mechanism leverages chaos theory to promote efficient exploitation of potential local regions while effectively improving the quality of neighborhood structures and preserving population diversity. Additionally, the migration mechanism facilitates the sharing of valuable information among the sub-populations throughout the search process. Furthermore, integrating the differential evolution strategy into the GSA enhances the local search capabilities of the proposed variant. This integration boosts the GSA algorithm&#8217;s ability to explore local optima and significantly improves the overall quality of the generated solutions. The main aim is to strike a balance between exploitation and exploration. The entire procedure of our method is ascertained as follows:<list list-type="bullet"><list-item><p id="Par50">Set up the GSA random population. The generated population, or Pop, is set to 90. GSA uses OBL to increase the population diversity of its search.</p></list-item><list-item><p id="Par51">To initialise the population, use the binary encoding approach. The generated population is designated as such and represented in binary form. Each length may represent a few genes in the reduced dataset by use of encoding.</p></list-item><list-item><p id="Par52">As shown in Fig. <xref rid="Fig1" ref-type="fig">1</xref>, divide the entire population into subpopulations.</p></list-item><list-item><p id="Par53">Use the new fitness function to determine the fitness value for each population while taking accuracy into account.</p></list-item><list-item><p id="Par54">After the first phase, choose a population with a high fitness value since the intelligent population is a target. Then, update the position value to create a new updated mass. Update the old pop according to the most recent population value. Determine the new pop fitness and compare it to the old pop. If the new pop fitness is lower, use MPKGSA solutions as a starting point to obtain the most recent, optimal solution.</p></list-item><list-item><p id="Par55">Stay after if the most recent best fitness value satisfies the termination criterion; proceed to the preceding step.</p></list-item><list-item><p id="Par56">The output is a subset of the SVM-based fitness and optimal gene.</p></list-item></list>In Algorithm 1, the Multi-Population Kernel Gravitational Search Algorithm (MPKGSA) combines kernel-based dimensionality reduction with an enhanced gravitational search metaheuristic for optimal biomarker selection from high-dimensional gene expression data. The algorithm operates through several key phases. The algorithm begins with opposition-based population initialization to enhance exploration:<disp-formula id="Equ33"><tex-math id="d33e1091">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} P_i = {\left\{ \begin{array}{ll} x_{i,j} = lb_j + ub_j - x_{i,j} &amp; \text {with probability } p_{obl} \\ x_{i,j} \sim \mathscr {U}(lb_j, ub_j) &amp; \text {otherwise}, \end{array}\right. } \end{aligned}$$\end{document}</tex-math></disp-formula>where <inline-formula id="IEq68"><tex-math id="d33e1095">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_{i,j}$$\end{document}</tex-math></inline-formula> represents gene <italic toggle="yes">j</italic> in solution <italic toggle="yes">i</italic>, and <inline-formula id="IEq69"><tex-math id="d33e1106">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$lb_j$$\end{document}</tex-math></inline-formula>, <inline-formula id="IEq70"><tex-math id="d33e1110">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ub_j$$\end{document}</tex-math></inline-formula> are the min/max expression values for gene <italic toggle="yes">j</italic>. Each solution&#8217;s mass <inline-formula id="IEq71"><tex-math id="d33e1117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M_i(t)$$\end{document}</tex-math></inline-formula> at iteration <italic toggle="yes">t</italic> is computed based on fitness:<disp-formula id="Equ34"><tex-math id="d33e1124">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} M_i(t) = \frac{\xi _i(t) - \text {worst}(t)}{\text {best}(t) - \text {worst}(t)}, \quad \text {best}(t) = \max _j \xi _j(t). \end{aligned}$$\end{document}</tex-math></disp-formula></p><p id="Par57">The gravitational force between solutions follows:<disp-formula id="Equ35"><tex-math id="d33e1129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} F_{ij}^d(t) = G(t)\frac{M_i(t)M_j(t)}{R_{ij}(t)+\epsilon }(x_j^d(t)-x_i^d(t)), \end{aligned}$$\end{document}</tex-math></disp-formula>where <inline-formula id="IEq72"><tex-math id="d33e1133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G(t) = G_0e^{-\alpha t/t_{max}}$$\end{document}</tex-math></inline-formula> controls the search intensity. Solutions update positions based on:<disp-formula id="Equ36"><tex-math id="d33e1137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} a_i^d(t)&amp;= \frac{\sum _{j\in Kbest} F_{ij}^d(t)}{M_i(t)} \\ v_i^d(t+1)&amp;= rand_i \times v_i^d(t) + a_i^d(t) \\ x_i^d(t+1)&amp;= x_i^d(t) + v_i^d(t+1). \end{aligned}$$\end{document}</tex-math></disp-formula></p><p id="Par58">The population is divided into <inline-formula id="IEq73"><tex-math id="d33e1142">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${nsub_{pop}}$$\end{document}</tex-math></inline-formula> subpopulations that evolve semi-independently. Top solutions <inline-formula id="IEq74"><tex-math id="d33e1146">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\delta _i$$\end{document}</tex-math></inline-formula> migrate between subpopulations:<disp-formula id="Equ37"><tex-math id="d33e1150">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} E_k = \text {argmax}_{P_i \in S_k} \xi (P_i), \quad S_{k+1} \leftarrow S_{k+1} \cup E_k. \end{aligned}$$\end{document}</tex-math></disp-formula></p><p id="Par59">Each <inline-formula id="IEq75"><tex-math id="d33e1155">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$x_i$$\end{document}</tex-math></inline-formula> represents a candidate biomarker panel, Fitness <inline-formula id="IEq76"><tex-math id="d33e1159">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\xi$$\end{document}</tex-math></inline-formula> typically combines a fitness function based on Eq. (24). The gravitational metaphor naturally handles. The final output is the solution with maximal fitness across all runs, representing the most discriminative and parsimonious biomarker set.</p><p id="Par60">
<fig position="anchor" id="Figa" orientation="portrait"><label>Algorithm 1</label><caption><p>Our MPKGSA to find the optimal set of biomarkers.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="anchor" id="MO3" orientation="portrait" xlink:href="41598_2025_29921_Figa_HTML.jpg"/></fig>
</p></sec><sec id="Sec10"><title>Support vector machine</title><p id="Par61">The support vector machine learning algorithm to address classification difficulties was proposed by Vapnik<sup><xref ref-type="bibr" rid="CR50">50</xref></sup>. The kernel functions have drawn much attention in recent decades, especially as Support Vector Machines (SVMs) have become more and more prominent. Since the kernel (k) function offers a straightforward connection between linearity and non-linearity for algorithms that can be stated in terms of dot products, it can be applied to a wide range of situations. The problem can be solved in various ways, but in this publication, we have employed three SVM kernels extracted from the LibSVM tool<sup><xref ref-type="bibr" rid="CR51">51</xref></sup>.</p><sec id="Sec11"><title>Kernel function and parameters of SVM</title><p id="Par62">The primary learning algorithms have drawn much attention in recent decades, especially since SVM has become more widely used. Since the kernel (k) function provides a straightforward connection between linearity and non-linearity for algorithms that can be expressed in terms of dot products, it can be used in various applications. Three kernel functions that are formulated as follows will be listed in this article:<list list-type="bullet"><list-item><p id="Par63">Linear function (SVM-L) <inline-formula id="IEq77"><tex-math id="d33e1193">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k\left( {{R}_{i}}\;\;\!\!~\!\!\;,\;\;\!\!~\!\!\;\;{{R}_{j}} \right) =\left( {{R}_{i}}^{T}\text {* }\!\!~\!\!\;\;{{R}_{j}}+d \right)$$\end{document}</tex-math></inline-formula>.</p></list-item><list-item><p id="Par64">Polynomial function (SVM-P) <inline-formula id="IEq78"><tex-math id="d33e1200">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k\left( {{R}_{i}}\;\;\!\!~\!\!\;,\;\;\!\!~\!\!\;\;{{R}_{j}} \right) ={{\left( {{R}_{i}}^{T}\text {* }\!\!~\!\!\;\;{{R}_{j}}+d \right) }^{p}}$$\end{document}</tex-math></inline-formula>.</p></list-item><list-item><p id="Par65">RBF function (SVM-R) <inline-formula id="IEq79"><tex-math id="d33e1207">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k\left( {{R}_{i}}\;\;\!\!~\!\!\;,\;\;\!\!~\!\!\;\;{{R}_{j}} \right) =\;\;\!\!~\!\!\;\;exp\;\;\!\!~\!\!\;\;\!\!~\!\!\;\;\left\{ -\;\;\!\!~\!\!\;\;\frac{{{\left| {{R}_{i}}-{{R}_{j}} \right| }^{2}}}{2{{\sigma }^{2}}} \right\}$$\end{document}</tex-math></inline-formula>,</p></list-item></list>where d is a constant value, <inline-formula id="IEq80"><tex-math id="d33e1212">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{R}_{i}}$$\end{document}</tex-math></inline-formula> and <inline-formula id="IEq81"><tex-math id="d33e1216">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{R}_{j}}$$\end{document}</tex-math></inline-formula> are records or instances, and p is the order of function.</p></sec><sec id="Sec12"><title>New fitness function</title><p id="Par66">The best gene subsets identified by the fitness function alone may still contain potential duplication because the essential functions do not aim to restrict the number of biomarkers. We speculate that a similar classification accuracy can be obtained from a subset of less essential genes. A novel fitness function is being researched to lessen the number of genes and increase classification accuracy in order to get around the problem. The recently proposed fitness function is demonstrated by Eq. (24):<disp-formula id="Equ24"><label>24</label><tex-math id="d33e1224">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} fit=\;\;\!\!~\!\!\;\;\alpha \text {*}\frac{\beta }{\;\;\!\!~\!\!\;\;\theta }+\left( 1-\alpha \right) \text {*}\delta . \end{aligned}$$\end{document}</tex-math></disp-formula></p><p id="Par67"><italic toggle="yes">fit</italic> indicates the fitness value; <inline-formula id="IEq82"><tex-math id="d33e1232">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\delta$$\end{document}</tex-math></inline-formula> represents the classification accuracy by SVM; <inline-formula id="IEq83"><tex-math id="d33e1236">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\theta$$\end{document}</tex-math></inline-formula> measures the length of the chromosome; <inline-formula id="IEq84"><tex-math id="d33e1240">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\beta$$\end{document}</tex-math></inline-formula> represents the upper bound of a selected gene from the candidate solutions; and the constant <inline-formula id="IEq85"><tex-math id="d33e1244">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha$$\end{document}</tex-math></inline-formula> value falls between 0 and 1.</p></sec><sec id="Sec13"><title>Datasets description</title><p id="Par68">Efficient datasets are required to assess the efficacy and dependability of any microarray program. In this paper, the evaluation of the Evolutionary techniques is carried out on six widely-used microarray datasets available in<sup><xref ref-type="bibr" rid="CR52">52</xref>,<xref ref-type="bibr" rid="CR53">53</xref></sup>. It is worth mentioning that all datasets have numerical features. The reason for choosing binary/multi datasets is that they are common in the literature. Table <xref rid="Tab1" ref-type="table">1</xref> summarize the properties of the datasets for each dataset, the number of features (#genes), classes, and number of samples (#instances). <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="pmc:entrez-geo" xlink:href="GSE16619">GSE16619</ext-link> series<sup><xref ref-type="bibr" rid="CR54">54</xref></sup> includes SNP data related to BC with more than 500.000 SNPs. This study used 111 individuals, 69 as cases and 42 as controls.<table-wrap id="Tab1" position="float" orientation="portrait"><label>Table 1</label><caption><p>Summary of genomic datasets used for biomarker selection.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">No.</th><th align="left" colspan="1" rowspan="1">Dataset</th><th align="left" colspan="1" rowspan="1">Instances</th><th align="left" colspan="1" rowspan="1">Genes</th><th align="left" colspan="1" rowspan="1">Classes</th><th align="left" colspan="1" rowspan="1">No.</th><th align="left" colspan="1" rowspan="1">Dataset</th><th align="left" colspan="1" rowspan="1">Instances</th><th align="left" colspan="1" rowspan="1">Genes</th><th align="left" colspan="1" rowspan="1">Classes</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">1</td><td align="left" colspan="1" rowspan="1">CNS</td><td align="left" colspan="1" rowspan="1">60</td><td align="left" colspan="1" rowspan="1">7129</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">SRBCT</td><td align="left" colspan="1" rowspan="1">83</td><td align="left" colspan="1" rowspan="1">2308</td><td align="left" colspan="1" rowspan="1">4</td></tr><tr><td align="left" colspan="1" rowspan="1">3</td><td align="left" colspan="1" rowspan="1">MLL</td><td align="left" colspan="1" rowspan="1">77</td><td align="left" colspan="1" rowspan="1">12582</td><td align="left" colspan="1" rowspan="1">3</td><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">Lung cancer</td><td align="left" colspan="1" rowspan="1">181</td><td align="left" colspan="1" rowspan="1">12533</td><td align="left" colspan="1" rowspan="1">2</td></tr><tr><td align="left" colspan="1" rowspan="1">5</td><td align="left" colspan="1" rowspan="1">Ovarian cancer</td><td align="left" colspan="1" rowspan="1">253</td><td align="left" colspan="1" rowspan="1">15154</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">Leukemia</td><td align="left" colspan="1" rowspan="1">72</td><td align="left" colspan="1" rowspan="1">5327</td><td align="left" colspan="1" rowspan="1">3</td></tr></tbody></table></table-wrap></p><p id="Par69">There are two types of microarray datasets presented in the literature: binary class and multi-class datasets. In this study, we have used six gene expression datasets for different types of tumors/cancer. For example, the CNS dataset represents central nervous system embryonal tumors with 60 samples across 7129 gene expressions, classified into two distinct tumor types. This dataset contains gene expression profiles that typically distinguish between classic medulloepitheliomas and malignant gliomas or other CNS tumor variants<sup><xref ref-type="bibr" rid="CR55">55</xref></sup>. The SRBCT dataset, containing 83 samples with 2308 gene expressions across four classes, stands as one of the most renowned benchmark datasets in cancer genomics, originally introduced by Ref.<sup><xref ref-type="bibr" rid="CR52">52</xref></sup>. This dataset encompasses four morphologically similar but molecularly distinct tumor types: Ewing sarcoma, rhabdomyosarcoma, non-Hodgkin lymphoma, and neuroblastoma, collectively known as small round blue cell tumors due to their similar microscopic appearance. The MLL dataset focuses on acute leukemias characterized by mixed lineage leukemia gene rearrangements, comprising 77 samples with 12,582 gene expressions distributed across three classes. This dataset typically represents acute lymphoblastic leukemia, acute myeloid leukemia, and mixed lineage leukemia subtypes, each requiring distinct therapeutic approaches.</p><p id="Par70">The lung cancer dataset contains 181 samples with 12,533 gene expressions classified into two primary categories, representing the largest sample size among the datasets examined. This dataset typically distinguishes between major lung cancer subtypes such as adenocarcinoma and squamous cell carcinoma, or alternatively between normal and tumor tissue samples. The substantial sample size provides better statistical power for machine learning applications, though the high dimensionality still necessitates robust feature selection methodologies to identify clinically relevant biomarkers. The ovarian cancer dataset represents the highest-dimensional challenge among all datasets, containing 253 samples with 15,154 gene expressions across two classes. This dataset, likely derived from Ref.<sup><xref ref-type="bibr" rid="CR56">56</xref></sup>, typically focuses on distinguishing between normal and cancerous ovarian tissue or different stages and grades of ovarian malignancy. The combination of substantial sample size and extremely high dimensionality creates significant computational demands and requires sophisticated algorithms capable of handling large-scale genomic data efficiently. The leukemia dataset comprises 72 samples with 5327 gene expressions distributed across three classes for gene expression-based cancer classification. The three classes likely encompass acute lymphoblastic leukemia, acute myeloid leukemia, and chronic lymphocytic leukemia subtypes.</p></sec></sec></sec><sec id="Sec14"><title>Experimental analysis and discussion</title><p id="Par71">In this experiment, the simulation model is built on MATLAB 2020a software. Different experiments have been carried out for GSA, current EA, and state-of-the-art gene selection methods. The proposed system is created using the Windows 10 operating system with 16 GB of RAM and an Intel i7 processor running at 2.4 GHz. Our work focuses on applying several methods that are inspired by nature. This section demonstrates the gene selection technique based on fitness functions and algorithms inspired by nature. Each optimization technique uses the fitness function to select the best characteristics. To decrease the number of characteristics and increase classification accuracy, a population size of 90 and several iterations of 100 in each bio-inspired technique can be seen in Table <xref rid="Tab2" ref-type="table">2</xref>. The population size (Pop) of 90 solutions provides sufficient diversity to explore the vast search space of potential gene combinations. The algorithm runs for 100 generations, allowing adequate iterations to converge toward optimal gene subsets without overfitting to the training data, with this entire process repeated across 10 independent runs to ensure statistical reliability of the results. The chromosome length corresponds directly to the dimensionality (D) of the microarray dataset, enabling the algorithm to evaluate all potential genes during the evolutionary process. Performance evaluation uses classification accuracy as the fitness metric (Fit), directly optimizing the biological relevance of selected gene signatures for diagnostic of cancers. The inertia weight (<inline-formula id="IEq86"><tex-math id="d33e1392">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\omega$$\end{document}</tex-math></inline-formula> = 0.7) controls the momentum from previous iterations, balancing exploration of new gene combinations with exploitation of promising regions in the search space, while the gravitational constant <inline-formula id="IEq87"><tex-math id="d33e1396">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G_0$$\end{document}</tex-math></inline-formula> = 20<sup><xref ref-type="bibr" rid="CR48">48</xref></sup> appropriately scales the attraction forces between solutions to facilitate effective local search refinement. Selecting a limited number of significant qualities that improve classification performance is the main objective of feature selection. A confusion matrix that summarizes the number of samples that the classifiers correctly or erroneously predicted is used to assess the classifier&#8217;s performance, as seen in Tables <xref rid="Tab2" ref-type="table">2</xref> and <xref rid="Tab3" ref-type="table">3</xref>.<table-wrap id="Tab2" position="float" orientation="portrait"><label>Table 2</label><caption><p>Used parameters for nature-inspired method.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">S. No.</th><th align="left" colspan="1" rowspan="1">Parameters</th><th align="left" colspan="1" rowspan="1">Value</th><th align="left" colspan="1" rowspan="1">Parameters</th><th align="left" colspan="1" rowspan="1">Value</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">1.</td><td align="left" colspan="1" rowspan="1">Population (Pop)</td><td align="left" colspan="1" rowspan="1">90</td><td align="left" colspan="1" rowspan="1"><inline-formula id="IEq88"><tex-math id="d33e1444">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\omega$$\end{document}</tex-math></inline-formula></td><td align="left" colspan="1" rowspan="1">0.7</td></tr><tr><td align="left" colspan="1" rowspan="1">2.</td><td align="left" colspan="1" rowspan="1">Number of generations</td><td align="left" colspan="1" rowspan="1">100</td><td align="left" colspan="1" rowspan="1"><inline-formula id="IEq89"><tex-math id="d33e1458">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$G_0$$\end{document}</tex-math></inline-formula></td><td align="left" colspan="1" rowspan="1">20</td></tr><tr><td align="left" colspan="1" rowspan="1">3.</td><td align="left" colspan="1" rowspan="1">Runs</td><td align="left" colspan="1" rowspan="1">10</td><td align="left" colspan="1" rowspan="1">Pc</td><td align="left" colspan="1" rowspan="1">0.6</td></tr><tr><td align="left" colspan="1" rowspan="1">4.</td><td align="left" colspan="1" rowspan="1">Chromosome length</td><td align="left" colspan="1" rowspan="1">D</td><td align="left" colspan="1" rowspan="1">Pm</td><td align="left" colspan="1" rowspan="1">0.4</td></tr><tr><td align="left" colspan="1" rowspan="1">5.</td><td align="left" colspan="1" rowspan="1">Performance</td><td align="left" colspan="1" rowspan="1">Accuracy (Fit)</td><td align="left" colspan="1" rowspan="1"><inline-formula id="IEq90"><tex-math id="d33e1494">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c_1$$\end{document}</tex-math></inline-formula> and <inline-formula id="IEq91"><tex-math id="d33e1498">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$c_2$$\end{document}</tex-math></inline-formula></td><td align="left" colspan="1" rowspan="1">1.4</td></tr></tbody></table></table-wrap><table-wrap id="Tab3" position="float" orientation="portrait"><label>Table 3</label><caption><p>Confusion matrix.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2" colspan="1"/><th align="left" rowspan="2" colspan="1"/><th align="left" colspan="2" rowspan="1">Actual</th><th align="left" colspan="1" rowspan="1"/></tr><tr><th align="left" colspan="1" rowspan="1">Positive</th><th align="left" colspan="1" rowspan="1">Negative</th><th align="left" colspan="1" rowspan="1">Total</th></tr></thead><tbody><tr><td align="left" rowspan="3" colspan="1">Predicted</td><td align="left" colspan="1" rowspan="1">Positive</td><td align="left" colspan="1" rowspan="1"><italic toggle="yes">T</italic>
<italic toggle="yes">P</italic></td><td align="left" colspan="1" rowspan="1"><italic toggle="yes">F</italic>
<italic toggle="yes">P</italic></td><td align="left" colspan="1" rowspan="1"><inline-formula id="IEq92"><tex-math id="d33e1550">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$T{P}+ F{P}$$\end{document}</tex-math></inline-formula></td></tr><tr><td align="left" colspan="1" rowspan="1">Negative</td><td align="left" colspan="1" rowspan="1"><italic toggle="yes">F</italic>
<italic toggle="yes">N</italic></td><td align="left" colspan="1" rowspan="1"><italic toggle="yes">T</italic>
<italic toggle="yes">N</italic></td><td align="left" colspan="1" rowspan="1"><inline-formula id="IEq93"><tex-math id="d33e1572">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F{N}+T{N}$$\end{document}</tex-math></inline-formula></td></tr><tr><td align="left" colspan="1" rowspan="1">Total</td><td align="left" colspan="1" rowspan="1"><inline-formula id="IEq94"><tex-math id="d33e1580">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$T{P}+F{N}$$\end{document}</tex-math></inline-formula></td><td align="left" colspan="1" rowspan="1"><inline-formula id="IEq95"><tex-math id="d33e1585">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$F{P}+T{N}$$\end{document}</tex-math></inline-formula></td><td align="left" colspan="1" rowspan="1"/></tr></tbody></table></table-wrap></p><sec id="Sec15"><title>Performance measures</title><p id="Par72">A set of performance metrics is established to assess the effectiveness of the proposed technique and other EA techniques. These metrics, which include accuracy,Sensitivity, Specificity, F-measure and Matthews Correlation Coefficient (MCC), are defined as follows:<disp-formula id="Equ38"><tex-math id="d33e1593">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\begin{aligned} &amp; Accuracy=\frac{TP+TN}{TP+TN+FP+FN}, \\ &amp; \text {Sensitivity (Sen) } = \frac{TP}{TP + FN }, \\ &amp; \text {Specificity (Sep)} = \frac{TN}{TN + FP}, \\ &amp; \text {F-measure (Fmes)} = \frac{2*TP}{2*TP + FN + FP}, \\ &amp; \text {MCC} = \frac{(TN \times TP - FN \times FP)}{} {\sqrt{(TP + FP)(TP + FN)(TN + FP)(TN + FN)}} \end{aligned}$$\end{document}</tex-math></disp-formula></p><p id="Par73">We assessed the effectiveness of wrapper FS approaches using the six gene datasets, where <italic toggle="yes">TP</italic>, <italic toggle="yes">TN</italic>, <italic toggle="yes">FP</italic>, and <italic toggle="yes">FN</italic> stand for True Positive, True Negative, False Positive, and False Negative, respectively, based on the confusion matrix<sup><xref ref-type="bibr" rid="CR57">57</xref></sup>.</p></sec><sec id="Sec16"><title>Experimental results and analysis</title><p id="Par74">The effectiveness of the suggested approach is demonstrated using the microarray gene expression data. For experimental purposes, microarray gene datasets are gathered from Ref.<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>. While the genes are organised in columns of the data matrix, the samples are maintained in rows during the experiments. A critical aspect of FS approaches is assessing the quality of the selected subsets, as seen in Table <xref rid="Tab4" ref-type="table">4</xref>. The filter-based approach with learning algorithms should be included in the evaluation process. The evaluators consider the classification performance of the chosen features and converge in this study of wrappers, including SVM variants. The more relevant the desired qualities are, the higher the classification accuracy of a subset. Increasing classification accuracy is one objective of FS methods; reducing the number of selected attributes and fewer features in the solution is another essential objective.<table-wrap id="Tab4" position="float" orientation="portrait"><label>Table 4</label><caption><p>Classification accuracy with top 100 genes selected by FS methods using SVM variants.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Classifiers</th><th align="left" colspan="1" rowspan="1">FS methods</th><th align="left" colspan="1" rowspan="1">Leukemia</th><th align="left" colspan="1" rowspan="1">SRBCT</th><th align="left" colspan="1" rowspan="1">CNS</th><th align="left" colspan="1" rowspan="1">Ovarian</th><th align="left" colspan="1" rowspan="1">Lung</th><th align="left" colspan="1" rowspan="1">MLL</th></tr></thead><tbody><tr><td align="left" rowspan="6" colspan="1">SVM-R</td><td align="left" colspan="1" rowspan="1">Without FS</td><td align="left" colspan="1" rowspan="1">71.32</td><td align="left" colspan="1" rowspan="1">74.55</td><td align="left" colspan="1" rowspan="1">70.85</td><td align="left" colspan="1" rowspan="1">73.24</td><td align="left" colspan="1" rowspan="1">78.75</td><td align="left" colspan="1" rowspan="1">73.12</td></tr><tr><td align="left" colspan="1" rowspan="1">PCA</td><td align="left" colspan="1" rowspan="1">88.79</td><td align="left" colspan="1" rowspan="1">88.84</td><td align="left" colspan="1" rowspan="1">71.69</td><td align="left" colspan="1" rowspan="1">87.71</td><td align="left" colspan="1" rowspan="1">91.84</td><td align="left" colspan="1" rowspan="1">87.75</td></tr><tr><td align="left" colspan="1" rowspan="1">KPCA</td><td align="left" colspan="1" rowspan="1">79.93</td><td align="left" colspan="1" rowspan="1">91.96</td><td align="left" colspan="1" rowspan="1">69.91</td><td align="left" colspan="1" rowspan="1">88.93</td><td align="left" colspan="1" rowspan="1">94.83</td><td align="left" colspan="1" rowspan="1">90.89</td></tr><tr><td align="left" colspan="1" rowspan="1">MRMR</td><td align="left" colspan="1" rowspan="1">81.77</td><td align="left" colspan="1" rowspan="1">78.86</td><td align="left" colspan="1" rowspan="1">70.84</td><td align="left" colspan="1" rowspan="1">82.90</td><td align="left" colspan="1" rowspan="1">92.79</td><td align="left" colspan="1" rowspan="1">84.73</td></tr><tr><td align="left" colspan="1" rowspan="1">CMIM</td><td align="left" colspan="1" rowspan="1">79.79</td><td align="left" colspan="1" rowspan="1">77.89</td><td align="left" colspan="1" rowspan="1">68.79</td><td align="left" colspan="1" rowspan="1">80.80</td><td align="left" colspan="1" rowspan="1">91.60</td><td align="left" colspan="1" rowspan="1">83.86</td></tr><tr><td align="left" colspan="1" rowspan="1">JMI</td><td align="left" colspan="1" rowspan="1">84.73</td><td align="left" colspan="1" rowspan="1">73.84</td><td align="left" colspan="1" rowspan="1">59.73</td><td align="left" colspan="1" rowspan="1">80.71</td><td align="left" colspan="1" rowspan="1">88.87</td><td align="left" colspan="1" rowspan="1">82.74</td></tr><tr><td align="left" rowspan="6" colspan="1">SVM-P</td><td align="left" colspan="1" rowspan="1">Without FS</td><td align="left" colspan="1" rowspan="1">68.24</td><td align="left" colspan="1" rowspan="1">68.95</td><td align="left" colspan="1" rowspan="1">70.25</td><td align="left" colspan="1" rowspan="1">78.93</td><td align="left" colspan="1" rowspan="1">70.32</td><td align="left" colspan="1" rowspan="1">69.52</td></tr><tr><td align="left" colspan="1" rowspan="1">PCA</td><td align="left" colspan="1" rowspan="1">74.81</td><td align="left" colspan="1" rowspan="1">70.87</td><td align="left" colspan="1" rowspan="1">84.79</td><td align="left" colspan="1" rowspan="1">93.25</td><td align="left" colspan="1" rowspan="1">77.80</td><td align="left" colspan="1" rowspan="1">71.73</td></tr><tr><td align="left" colspan="1" rowspan="1">KPCA</td><td align="left" colspan="1" rowspan="1">78.98</td><td align="left" colspan="1" rowspan="1">74.91</td><td align="left" colspan="1" rowspan="1">88.89</td><td align="left" colspan="1" rowspan="1">95.85</td><td align="left" colspan="1" rowspan="1">78.80</td><td align="left" colspan="1" rowspan="1">77.83</td></tr><tr><td align="left" colspan="1" rowspan="1">MRMR</td><td align="left" colspan="1" rowspan="1">76.88</td><td align="left" colspan="1" rowspan="1">72.87</td><td align="left" colspan="1" rowspan="1">76.79</td><td align="left" colspan="1" rowspan="1">93.14</td><td align="left" colspan="1" rowspan="1">74.80</td><td align="left" colspan="1" rowspan="1">73.73</td></tr><tr><td align="left" colspan="1" rowspan="1">CMIM</td><td align="left" colspan="1" rowspan="1">71.84</td><td align="left" colspan="1" rowspan="1">70.87</td><td align="left" colspan="1" rowspan="1">81.80</td><td align="left" colspan="1" rowspan="1">83.89</td><td align="left" colspan="1" rowspan="1">73.79</td><td align="left" colspan="1" rowspan="1">74.73</td></tr><tr><td align="left" colspan="1" rowspan="1">JMI</td><td align="left" colspan="1" rowspan="1">69.84</td><td align="left" colspan="1" rowspan="1">69.74</td><td align="left" colspan="1" rowspan="1">83.60</td><td align="left" colspan="1" rowspan="1">83.47</td><td align="left" colspan="1" rowspan="1">75.53</td><td align="left" colspan="1" rowspan="1">72.85</td></tr><tr><td align="left" rowspan="6" colspan="1">SVM-L</td><td align="left" colspan="1" rowspan="1">Without FS</td><td align="left" colspan="1" rowspan="1">65.32</td><td align="left" colspan="1" rowspan="1">81.27</td><td align="left" colspan="1" rowspan="1">66.43</td><td align="left" colspan="1" rowspan="1">63.31</td><td align="left" colspan="1" rowspan="1">72.98</td><td align="left" colspan="1" rowspan="1">74.65</td></tr><tr><td align="left" colspan="1" rowspan="1">PCA</td><td align="left" colspan="1" rowspan="1">66.86</td><td align="left" colspan="1" rowspan="1">84.91</td><td align="left" colspan="1" rowspan="1">68.82</td><td align="left" colspan="1" rowspan="1">68.89</td><td align="left" colspan="1" rowspan="1">84.75</td><td align="left" colspan="1" rowspan="1">77.74</td></tr><tr><td align="left" colspan="1" rowspan="1">KPCA</td><td align="left" colspan="1" rowspan="1">71.84</td><td align="left" colspan="1" rowspan="1">86.88</td><td align="left" colspan="1" rowspan="1">71.80</td><td align="left" colspan="1" rowspan="1">67.90</td><td align="left" colspan="1" rowspan="1">89.83</td><td align="left" colspan="1" rowspan="1">76.81</td></tr><tr><td align="left" colspan="1" rowspan="1">MRMR</td><td align="left" colspan="1" rowspan="1">68.86</td><td align="left" colspan="1" rowspan="1">88.76</td><td align="left" colspan="1" rowspan="1">73.82</td><td align="left" colspan="1" rowspan="1">64.91</td><td align="left" colspan="1" rowspan="1">83.78</td><td align="left" colspan="1" rowspan="1">72.74</td></tr><tr><td align="left" colspan="1" rowspan="1">CMIM</td><td align="left" colspan="1" rowspan="1">68.89</td><td align="left" colspan="1" rowspan="1">90.78</td><td align="left" colspan="1" rowspan="1">75.84</td><td align="left" colspan="1" rowspan="1">69.76</td><td align="left" colspan="1" rowspan="1">84.64</td><td align="left" colspan="1" rowspan="1">73.75</td></tr><tr><td align="left" colspan="1" rowspan="1">JMI</td><td align="left" colspan="1" rowspan="1">70.76</td><td align="left" colspan="1" rowspan="1">92.69</td><td align="left" colspan="1" rowspan="1">77.65</td><td align="left" colspan="1" rowspan="1">70.80</td><td align="left" colspan="1" rowspan="1">81.68</td><td align="left" colspan="1" rowspan="1">77.76</td></tr></tbody></table></table-wrap></p><p id="Par75">In the other section of the experimental part of the study, we use tenfold cross-validation to assess our system performance. First, we explained the six data sets on DNA cancer that were used to determine the system&#8217;s effectiveness. As a result, existing traditional algorithms are compared and analyzed with the learning method. According to KPCA, we have selected the top 100 genes from the original gene dataset. To determine classification accuracy, we consider five distinct filter-based feature-selection methods, such as KPCA, MRMR, JMI, CMIM, and PCA, including without FS, as shown in Table <xref rid="Tab4" ref-type="table">4</xref>. The comparative analysis of classification accuracy across six genomic datasets reveals distinct performance patterns when combining different Support Vector Machine variants with various feature selection methods. The results demonstrate that no single combination outperforms others across all datasets, indicating that the optimal approach is dataset-dependent and influenced by the underlying biological characteristics and data structure of each cancer type. The performance variations range from extremely poor results ( low for Ovarian cancer with SVM-P) to excellent classification accuracy (high for Lung cancer with SVM-R and KPCA), highlighting the critical importance of appropriate method selection for genomic data analysis. SVM-R demonstrates the most consistent and robust performance across the majority of datasets, achieving the highest accuracy scores in four out of six datasets. The Lung cancer dataset shows exceptional performance with SVM-R, reaching 94.83% accuracy when combined with Kernel Principal Component Analysis (KPCA), followed by 92.79% with Minimum Redundancy Maximum Relevance (MRMR) feature selection. This superior performance on lung cancer data suggests that the radial basis function kernel effectively captures the nonlinear relationships inherent in lung cancer gene expression patterns. The SRBCT dataset also responds well to SVM-R, achieving 91.96% accuracy with KPCA, indicating that the complex multi-class nature of small round blue cell tumors benefits from the non-linear mapping capabilities of the RBF kernel. However, SVM-R shows more modest performance on the CNS dataset, with accuracies ranging from 59.73 to 71.69%, suggesting that central nervous system tumor classification may require different analytical approaches or that the dataset&#8217;s small sample size limits the effectiveness of complex kernel methods. The polynomial kernel SVM variant exhibits highly dataset-specific performance patterns, with remarkable variation across different cancer types. Most notably, SVM-P does not show good performance on the Ovarian cancer dataset across all feature selection methods. This failure likely results from the polynomial kernel&#8217;s tendency to create overly complex decision boundaries that do not generalize well to the high-dimensional, sparse nature of ovarian cancer genomic data. Conversely, SVM-P achieves its best performance on the CNS dataset, reaching 88.89% accuracy with KPCA, suggesting that central nervous system tumor classification benefits from the polynomial kernel&#8217;s ability to capture specific types of feature interactions. The linear SVM variant provides moderate but consistent performance across most datasets, offering the advantage of model interpretability and computational efficiency. SVM-L achieves its highest performance on the SRBCT dataset, with JMI feature selection yielding 92.69% accuracy, demonstrating that the four-class small round blue cell tumor classification can be effectively handled through linear decision boundaries when appropriate feature selection is applied. The Lung cancer dataset also shows strong performance with SVM-L, reaching 89.83% accuracy when combined with KPCA, indicating that despite the complexity of lung cancer genomics, linear relationships between selected features can provide effective classification. The consistent moderate performance of SVM-L across datasets makes it a reliable baseline approach, particularly valuable in clinical applications where model interpretability is crucial for understanding the biological basis of classification decisions.<table-wrap id="Tab5" position="float" orientation="portrait"><label>Table 5</label><caption><p>Comparative experimental best results of SVMs on six gene datasets.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2" colspan="1">Datasets</th><th align="left" rowspan="2" colspan="1">Measures</th><th align="left" colspan="3" rowspan="1">Classifiers</th><th align="left" rowspan="2" colspan="1">Datasets</th><th align="left" rowspan="2" colspan="1">Measures</th><th align="left" colspan="3" rowspan="1">Classifiers</th></tr><tr><th align="left" colspan="1" rowspan="1">SVM-R</th><th align="left" colspan="1" rowspan="1">SVM-L</th><th align="left" colspan="1" rowspan="1">SVM-P</th><th align="left" colspan="1" rowspan="1">SVM-R</th><th align="left" colspan="1" rowspan="1">SVM-L</th><th align="left" colspan="1" rowspan="1">SVM-P</th></tr></thead><tbody><tr><td align="left" rowspan="5" colspan="1">Leukemia</td><td align="left" colspan="1" rowspan="1">Acc</td><td align="left" colspan="1" rowspan="1">94.95</td><td align="left" colspan="1" rowspan="1">93.93</td><td align="left" colspan="1" rowspan="1">88.86</td><td align="left" rowspan="5" colspan="1">Lung</td><td align="left" colspan="1" rowspan="1">Acc</td><td align="left" colspan="1" rowspan="1">94.96</td><td align="left" colspan="1" rowspan="1">93.94</td><td align="left" colspan="1" rowspan="1">90.91</td></tr><tr><td align="left" colspan="1" rowspan="1">Sen</td><td align="left" colspan="1" rowspan="1">95.96</td><td align="left" colspan="1" rowspan="1">88.81</td><td align="left" colspan="1" rowspan="1">79.88</td><td align="left" colspan="1" rowspan="1">Sen</td><td align="left" colspan="1" rowspan="1">93.95</td><td align="left" colspan="1" rowspan="1">89.95</td><td align="left" colspan="1" rowspan="1">91.92</td></tr><tr><td align="left" colspan="1" rowspan="1">Sep</td><td align="left" colspan="1" rowspan="1">94.95</td><td align="left" colspan="1" rowspan="1">82.83</td><td align="left" colspan="1" rowspan="1">80.86</td><td align="left" colspan="1" rowspan="1">Sep</td><td align="left" colspan="1" rowspan="1">93.94</td><td align="left" colspan="1" rowspan="1">94.94</td><td align="left" colspan="1" rowspan="1">90.91</td></tr><tr><td align="left" colspan="1" rowspan="1">Fmes</td><td align="left" colspan="1" rowspan="1">95.96</td><td align="left" colspan="1" rowspan="1">89.87</td><td align="left" colspan="1" rowspan="1">85.86</td><td align="left" colspan="1" rowspan="1">Fmes</td><td align="left" colspan="1" rowspan="1">91.91</td><td align="left" colspan="1" rowspan="1">88.90</td><td align="left" colspan="1" rowspan="1">89.90</td></tr><tr><td align="left" colspan="1" rowspan="1">MCC</td><td align="left" colspan="1" rowspan="1">92.91</td><td align="left" colspan="1" rowspan="1">89.82</td><td align="left" colspan="1" rowspan="1">81.80</td><td align="left" colspan="1" rowspan="1">MCC</td><td align="left" colspan="1" rowspan="1">90.89</td><td align="left" colspan="1" rowspan="1">89.88</td><td align="left" colspan="1" rowspan="1">81.80</td></tr><tr><td align="left" rowspan="5" colspan="1">CNS</td><td align="left" colspan="1" rowspan="1">Acc</td><td align="left" colspan="1" rowspan="1">93.94</td><td align="left" colspan="1" rowspan="1">91.92</td><td align="left" colspan="1" rowspan="1">90.93</td><td align="left" rowspan="5" colspan="1">SRBCT</td><td align="left" colspan="1" rowspan="1">Acc</td><td align="left" colspan="1" rowspan="1">97.98</td><td align="left" colspan="1" rowspan="1">96.95</td><td align="left" colspan="1" rowspan="1">94.95</td></tr><tr><td align="left" colspan="1" rowspan="1">Sen</td><td align="left" colspan="1" rowspan="1">95.96</td><td align="left" colspan="1" rowspan="1">93.92</td><td align="left" colspan="1" rowspan="1">90.91</td><td align="left" colspan="1" rowspan="1">Sen</td><td align="left" colspan="1" rowspan="1">94.96</td><td align="left" colspan="1" rowspan="1">94.95</td><td align="left" colspan="1" rowspan="1">93.94</td></tr><tr><td align="left" colspan="1" rowspan="1">Sep</td><td align="left" colspan="1" rowspan="1">92.92</td><td align="left" colspan="1" rowspan="1">91.92</td><td align="left" colspan="1" rowspan="1">92.93</td><td align="left" colspan="1" rowspan="1">Sep</td><td align="left" colspan="1" rowspan="1">94.94</td><td align="left" colspan="1" rowspan="1">90.91</td><td align="left" colspan="1" rowspan="1">93.94</td></tr><tr><td align="left" colspan="1" rowspan="1">Fmes</td><td align="left" colspan="1" rowspan="1">92.93</td><td align="left" colspan="1" rowspan="1">92.91</td><td align="left" colspan="1" rowspan="1">91.92</td><td align="left" colspan="1" rowspan="1">Fmes</td><td align="left" colspan="1" rowspan="1">95.96</td><td align="left" colspan="1" rowspan="1">92.91</td><td align="left" colspan="1" rowspan="1">93.93</td></tr><tr><td align="left" colspan="1" rowspan="1">MCC</td><td align="left" colspan="1" rowspan="1">88.89</td><td align="left" colspan="1" rowspan="1">84.83</td><td align="left" colspan="1" rowspan="1">86.87</td><td align="left" colspan="1" rowspan="1">MCC</td><td align="left" colspan="1" rowspan="1">96.97</td><td align="left" colspan="1" rowspan="1">88.90</td><td align="left" colspan="1" rowspan="1">92.93</td></tr><tr><td align="left" rowspan="5" colspan="1">Ovarian</td><td align="left" colspan="1" rowspan="1">Acc</td><td align="left" colspan="1" rowspan="1">93.94</td><td align="left" colspan="1" rowspan="1">92.91</td><td align="left" colspan="1" rowspan="1">91.92</td><td align="left" rowspan="5" colspan="1">MLL</td><td align="left" colspan="1" rowspan="1">Acc</td><td align="left" colspan="1" rowspan="1">96.97</td><td align="left" colspan="1" rowspan="1">95.96</td><td align="left" colspan="1" rowspan="1">91.92</td></tr><tr><td align="left" colspan="1" rowspan="1">Sen</td><td align="left" colspan="1" rowspan="1">94.96</td><td align="left" colspan="1" rowspan="1">89.91</td><td align="left" colspan="1" rowspan="1">88.93</td><td align="left" colspan="1" rowspan="1">Sen</td><td align="left" colspan="1" rowspan="1">97.98</td><td align="left" colspan="1" rowspan="1">92.96</td><td align="left" colspan="1" rowspan="1">95.93</td></tr><tr><td align="left" colspan="1" rowspan="1">Sep</td><td align="left" colspan="1" rowspan="1">95.94</td><td align="left" colspan="1" rowspan="1">90.94</td><td align="left" colspan="1" rowspan="1">91.92</td><td align="left" colspan="1" rowspan="1">Sep</td><td align="left" colspan="1" rowspan="1">98.98</td><td align="left" colspan="1" rowspan="1">93.16</td><td align="left" colspan="1" rowspan="1">91.92</td></tr><tr><td align="left" colspan="1" rowspan="1">Fmes</td><td align="left" colspan="1" rowspan="1">94.95</td><td align="left" colspan="1" rowspan="1">92.94</td><td align="left" colspan="1" rowspan="1">90.92</td><td align="left" colspan="1" rowspan="1">Fmes</td><td align="left" colspan="1" rowspan="1">93.95</td><td align="left" colspan="1" rowspan="1">91.96</td><td align="left" colspan="1" rowspan="1">90.92</td></tr><tr><td align="left" colspan="1" rowspan="1">MCC</td><td align="left" colspan="1" rowspan="1">92.93</td><td align="left" colspan="1" rowspan="1">89.88</td><td align="left" colspan="1" rowspan="1">88.84</td><td align="left" colspan="1" rowspan="1">MCC</td><td align="left" colspan="1" rowspan="1">87.92</td><td align="left" colspan="1" rowspan="1">91.12</td><td align="left" colspan="1" rowspan="1">85.84</td></tr></tbody></table></table-wrap></p><p id="Par76">From Table <xref rid="Tab5" ref-type="table">5</xref>, SVM-L achieves the best performance on the MLL dataset with 95.96% accuracy, complemented by sensitivity (92.96%) and F-measure (91.96%), indicating that the three-class MLL leukemia classification can be effectively handled through linear decision boundaries in the selected feature space. The SRBCT dataset also demonstrates strong linear separability with SVM-L achieving 96.95% accuracy. However, SVM-L shows some performance degradation in specific metrics, particularly evident in the Leukemia dataset, where the MCC drops significantly compared to sensitivity and specificity scores, and most notably in the MLL dataset, where the MCC score shows an anomalous value of 88.90%, likely indicating a computational or reporting error that warrants investigation. The polynomial SVM exhibits the most variable performance characteristics across datasets, with significant fluctuations in effectiveness that appear strongly dependent on the underlying biological and technical characteristics of each genomic dataset. SVM-P achieves the best performance on the SRBCT dataset with 94.95% accuracy and balanced sensitivity (93.94%) and specificity (93.94%). Conversely, SVM-P shows its weakest performance on the Leukemia dataset with 88.86% accuracy and notably reduced sensitivity (79.88%) and specificity (80.86%). The intermediate performance on other datasets, with accuracies ranging from 90.91% to 91.92%, indicates that while SVM-P can provide reasonable classification results, its application requires careful consideration of dataset-specific characteristics and potentially more extensive hyperparameter optimization.<table-wrap id="Tab6" position="float" orientation="portrait"><label>Table 6</label><caption><p>The comparative analysis for GSA and the proposed method.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="2" colspan="1">Datasets</th><th align="left" rowspan="2" colspan="1">Measures</th><th align="left" colspan="3" rowspan="1">GSA</th><th align="left" colspan="3" rowspan="1">Proposed</th></tr><tr><th align="left" colspan="1" rowspan="1">Best</th><th align="left" colspan="1" rowspan="1">Avg</th><th align="left" colspan="1" rowspan="1">Worse</th><th align="left" colspan="1" rowspan="1">Best</th><th align="left" colspan="1" rowspan="1">Avg</th><th align="left" colspan="1" rowspan="1">Worse</th></tr></thead><tbody><tr><td align="left" rowspan="2" colspan="1">Leukemia cancer</td><td align="left" colspan="1" rowspan="1">Acc</td><td align="left" colspan="1" rowspan="1">95.25</td><td align="left" colspan="1" rowspan="1">88.25</td><td align="left" colspan="1" rowspan="1">80.51</td><td align="left" colspan="1" rowspan="1">97.85</td><td align="left" colspan="1" rowspan="1">87.31</td><td align="left" colspan="1" rowspan="1">82.52</td></tr><tr><td align="left" colspan="1" rowspan="1">#feat</td><td align="left" colspan="1" rowspan="1">27</td><td align="left" colspan="1" rowspan="1">21</td><td align="left" colspan="1" rowspan="1">33</td><td align="left" colspan="1" rowspan="1">17</td><td align="left" colspan="1" rowspan="1">18</td><td align="left" colspan="1" rowspan="1">30</td></tr><tr><td align="left" rowspan="2" colspan="1">MLL</td><td align="left" colspan="1" rowspan="1">Acc</td><td align="left" colspan="1" rowspan="1">92.88</td><td align="left" colspan="1" rowspan="1">86.54</td><td align="left" colspan="1" rowspan="1">77.52</td><td align="left" colspan="1" rowspan="1">94.25</td><td align="left" colspan="1" rowspan="1">90.51</td><td align="left" colspan="1" rowspan="1">79.63</td></tr><tr><td align="left" colspan="1" rowspan="1">#feat</td><td align="left" colspan="1" rowspan="1">21</td><td align="left" colspan="1" rowspan="1">28</td><td align="left" colspan="1" rowspan="1">39</td><td align="left" colspan="1" rowspan="1">18</td><td align="left" colspan="1" rowspan="1">19</td><td align="left" colspan="1" rowspan="1">24</td></tr><tr><td align="left" rowspan="2" colspan="1">Ovarian</td><td align="left" colspan="1" rowspan="1">Acc</td><td align="left" colspan="1" rowspan="1">91.78</td><td align="left" colspan="1" rowspan="1">84.65</td><td align="left" colspan="1" rowspan="1">77.63</td><td align="left" colspan="1" rowspan="1">96.75</td><td align="left" colspan="1" rowspan="1">88.67</td><td align="left" colspan="1" rowspan="1">79.32</td></tr><tr><td align="left" colspan="1" rowspan="1">#feat</td><td align="left" colspan="1" rowspan="1">17</td><td align="left" colspan="1" rowspan="1">24</td><td align="left" colspan="1" rowspan="1">35</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1">22</td><td align="left" colspan="1" rowspan="1">26</td></tr><tr><td align="left" rowspan="2" colspan="1">CNS</td><td align="left" colspan="1" rowspan="1">Acc</td><td align="left" colspan="1" rowspan="1">90.54</td><td align="left" colspan="1" rowspan="1">81.99</td><td align="left" colspan="1" rowspan="1">76.32</td><td align="left" colspan="1" rowspan="1">95.25</td><td align="left" colspan="1" rowspan="1">88.05</td><td align="left" colspan="1" rowspan="1">74.38</td></tr><tr><td align="left" colspan="1" rowspan="1">#feat</td><td align="left" colspan="1" rowspan="1">24</td><td align="left" colspan="1" rowspan="1">38</td><td align="left" colspan="1" rowspan="1">44</td><td align="left" colspan="1" rowspan="1">18</td><td align="left" colspan="1" rowspan="1">26</td><td align="left" colspan="1" rowspan="1">34</td></tr><tr><td align="left" rowspan="2" colspan="1">SRBCT</td><td align="left" colspan="1" rowspan="1">Acc</td><td align="left" colspan="1" rowspan="1">99.25</td><td align="left" colspan="1" rowspan="1">88.07</td><td align="left" colspan="1" rowspan="1">94.52</td><td align="left" colspan="1" rowspan="1">100</td><td align="left" colspan="1" rowspan="1">94.25</td><td align="left" colspan="1" rowspan="1">92.56</td></tr><tr><td align="left" colspan="1" rowspan="1">#feat</td><td align="left" colspan="1" rowspan="1">17</td><td align="left" colspan="1" rowspan="1">25</td><td align="left" colspan="1" rowspan="1">36</td><td align="left" colspan="1" rowspan="1">11</td><td align="left" colspan="1" rowspan="1">20</td><td align="left" colspan="1" rowspan="1">27</td></tr><tr><td align="left" rowspan="2" colspan="1">Lung cancer</td><td align="left" colspan="1" rowspan="1">Acc</td><td align="left" colspan="1" rowspan="1">97.71</td><td align="left" colspan="1" rowspan="1">94.63</td><td align="left" colspan="1" rowspan="1">86.52</td><td align="left" colspan="1" rowspan="1">100</td><td align="left" colspan="1" rowspan="1">95.36</td><td align="left" colspan="1" rowspan="1">87.25</td></tr><tr><td align="left" colspan="1" rowspan="1">#feat</td><td align="left" colspan="1" rowspan="1">22</td><td align="left" colspan="1" rowspan="1">30</td><td align="left" colspan="1" rowspan="1">41</td><td align="left" colspan="1" rowspan="1">15</td><td align="left" colspan="1" rowspan="1">20</td><td align="left" colspan="1" rowspan="1">29</td></tr></tbody></table></table-wrap></p><p id="Par77">Table <xref rid="Tab6" ref-type="table">6</xref> compares the performance of the Gravitational Search Algorithm (GSA) and a proposed method across six microarray datasets (Leukemia Cancer, MLL, Ovarian, CNS, SRBCT, and Lung Cancer), evaluating accuracy (Acc) and the number of selected features (feat) using best, average (Avg), and worst-case metrics. The proposed method consistently outperforms GSA in terms of best and average accuracy across all datasets, achieving perfect accuracy 100% for SRBCT and Lung Cancer in the best case, and higher average accuracies. Additionally, the proposed method selects fewer features in most cases, with best-case feature counts as low as 11 for SRBCT and 14 for Ovarian, compared to GSA&#8217;s 17 for both, indicating greater efficiency in identifying compact, relevant gene subsets. While GSA shows competitive worst-case accuracies, the proposed method generally maintains better worst-case performance and fewer features, highlighting its robustness and effectiveness for gene selection in cancer classification tasks.<fig id="Fig3" position="float" orientation="portrait"><label>Fig. 3</label><caption><p>Convergence graph on three gene datasets.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="MO4" position="float" orientation="portrait" xlink:href="41598_2025_29921_Fig3_HTML.jpg"/></fig></p><p id="Par78">An analysis of Fig. <xref rid="Fig3" ref-type="fig">3</xref> reveals the comparative performance of several optimization algorithms, including the proposed method, evaluated on the SRBCT, Ovarian, and Lung cancer gene datasets. Each graph plots the average fitness values as a measure of solution quality against the number of iterations, providing insights into the convergence behavior and effectiveness of the algorithms. The algorithms evaluated include our method, TLBO, GA, DE, PSO, and GSA. In the SRBCT dataset, the proposed method consistently outperforms the other algorithms, achieving the highest average fitness values across all iterations. TLBO and GA show competitive performance but plateau at slightly lower fitness levels, while DE, PSO, and GSA exhibit slower convergence and significantly lower fitness values. The Ovarian dataset reveals a tight performance among the top algorithms, with the proposed method and TLBO leading in fitness values. GA and DE perform moderately, while PSO and GSA lag. Notably, all algorithms converge quickly, reaching stable fitness levels by around 20 iterations. For the Lung dataset, the proposed method again demonstrates superior performance, achieving the highest fitness value. TIBO and GA follow closely, while DE, PSO, and GSA trail behind. Across all three datasets, the proposed method consistently ranks at the top, showcasing its robustness and adaptability to varying gene expression profiles. Similarly, Fig. <xref rid="Fig4" ref-type="fig">4</xref> shows that ours performs better than the existing state-of-the-art techniques over 100 iterations and early iterations in all three datasets. In other words, our method outperforms other methods and obtains an excellent fitness value.<fig id="Fig4" position="float" orientation="portrait"><label>Fig. 4</label><caption><p>Convergence graph on three gene datasets.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="MO5" position="float" orientation="portrait" xlink:href="41598_2025_29921_Fig4_HTML.jpg"/></fig><fig id="Fig5" position="float" orientation="portrait"><label>Fig. 5</label><caption><p>PR curve on six gene datasets.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="MO6" position="float" orientation="portrait" xlink:href="41598_2025_29921_Fig5_HTML.jpg"/></fig></p><p id="Par79">The average PR curves of the five wrapper methods and our six microarray gene datasets are shown in Fig. <xref rid="Fig5" ref-type="fig">5</xref>. It can be seen that TLBO and GSA show moderate AUC values in most of the CNS and Ovarian data, while DE has the lowest convergence. It is worth mentioning that 100 iterations were enough for GA and PSO to come close to our modest goal in all cases. To obtain statistically meaningful findings, 10 independent folds are performed for each method. Results, including average classification accuracies, are calculated for each approach after a certain number of iterations. Convergence curves are also included for each approach.<table-wrap id="Tab7" position="float" orientation="portrait"><label>Table 7</label><caption><p>Comparative analysis of five evolutionary algorithms and the proposed method.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Dataset</th><th align="left" colspan="1" rowspan="1">Measures</th><th align="left" colspan="1" rowspan="1">GA</th><th align="left" colspan="1" rowspan="1">PSO</th><th align="left" colspan="1" rowspan="1">DE</th><th align="left" colspan="1" rowspan="1">TLBO</th><th align="left" colspan="1" rowspan="1">GSA</th><th align="left" colspan="1" rowspan="1">Proposed</th></tr></thead><tbody><tr><td align="left" rowspan="3" colspan="1">Leukemia cancer</td><td align="left" colspan="1" rowspan="1">Acc &#177; Std</td><td align="left" colspan="1" rowspan="1">86.25 &#177; 1.45</td><td align="left" colspan="1" rowspan="1">84.52 &#177; 1.25</td><td align="left" colspan="1" rowspan="1">87.23 &#177; 1.85</td><td align="left" colspan="1" rowspan="1">90.25 &#177; 2.01</td><td align="left" colspan="1" rowspan="1">92.65 &#177; 1.88</td><td align="left" colspan="1" rowspan="1">94.71 &#177; 0.57</td></tr><tr><td align="left" colspan="1" rowspan="1">#feat</td><td align="left" colspan="1" rowspan="1">39</td><td align="left" colspan="1" rowspan="1">41</td><td align="left" colspan="1" rowspan="1">34</td><td align="left" colspan="1" rowspan="1">29</td><td align="left" colspan="1" rowspan="1">27</td><td align="left" colspan="1" rowspan="1">17</td></tr><tr><td align="left" colspan="1" rowspan="1">ETime</td><td align="left" colspan="1" rowspan="1">845.25</td><td align="left" colspan="1" rowspan="1">945.25</td><td align="left" colspan="1" rowspan="1">1120.52</td><td align="left" colspan="1" rowspan="1">1554.23</td><td align="left" colspan="1" rowspan="1">1104.27</td><td align="left" colspan="1" rowspan="1">711.35</td></tr><tr><td align="left" rowspan="3" colspan="1">MLL</td><td align="left" colspan="1" rowspan="1">Acc &#177; Std</td><td align="left" colspan="1" rowspan="1">80.25 &#177; 2.54</td><td align="left" colspan="1" rowspan="1">82.52 &#177; 2.87</td><td align="left" colspan="1" rowspan="1">88.30 &#177; 3.07</td><td align="left" colspan="1" rowspan="1">87.41 &#177; 2.98</td><td align="left" colspan="1" rowspan="1">88.94 &#177; 2.47</td><td align="left" colspan="1" rowspan="1">91.63 &#177; 2.06</td></tr><tr><td align="left" colspan="1" rowspan="1">#feat</td><td align="left" colspan="1" rowspan="1">34</td><td align="left" colspan="1" rowspan="1">32</td><td align="left" colspan="1" rowspan="1">29</td><td align="left" colspan="1" rowspan="1">37</td><td align="left" colspan="1" rowspan="1">25</td><td align="left" colspan="1" rowspan="1">18</td></tr><tr><td align="left" colspan="1" rowspan="1">ETime</td><td align="left" colspan="1" rowspan="1">622.38</td><td align="left" colspan="1" rowspan="1">751.02</td><td align="left" colspan="1" rowspan="1">811.25</td><td align="left" colspan="1" rowspan="1">965.32</td><td align="left" colspan="1" rowspan="1">888.25</td><td align="left" colspan="1" rowspan="1">711.02</td></tr><tr><td align="left" rowspan="3" colspan="1">Ovarian</td><td align="left" colspan="1" rowspan="1">Acc &#177; Std</td><td align="left" colspan="1" rowspan="1">90.21 &#177; 2.14</td><td align="left" colspan="1" rowspan="1">91.25 &#177; 2.98</td><td align="left" colspan="1" rowspan="1">88.72 &#177; 2.45</td><td align="left" colspan="1" rowspan="1">89.65 &#177; 1.69</td><td align="left" colspan="1" rowspan="1">88.14 &#177; 1.35</td><td align="left" colspan="1" rowspan="1">93.66 &#177; 1.02</td></tr><tr><td align="left" colspan="1" rowspan="1">#feat</td><td align="left" colspan="1" rowspan="1">25</td><td align="left" colspan="1" rowspan="1">24</td><td align="left" colspan="1" rowspan="1">21</td><td align="left" colspan="1" rowspan="1">29</td><td align="left" colspan="1" rowspan="1">21</td><td align="left" colspan="1" rowspan="1">14</td></tr><tr><td align="left" colspan="1" rowspan="1">ETime</td><td align="left" colspan="1" rowspan="1">1132.05</td><td align="left" colspan="1" rowspan="1">1223.52</td><td align="left" colspan="1" rowspan="1">1377.95</td><td align="left" colspan="1" rowspan="1">1425.08</td><td align="left" colspan="1" rowspan="1">1423.57</td><td align="left" colspan="1" rowspan="1">966.52</td></tr><tr><td align="left" rowspan="3" colspan="1">CNS</td><td align="left" colspan="1" rowspan="1">Acc &#177; Std</td><td align="left" colspan="1" rowspan="1">69.52 &#177; 1.25</td><td align="left" colspan="1" rowspan="1">74.85 &#177; 2.31</td><td align="left" colspan="1" rowspan="1">76.33 &#177; 3.01</td><td align="left" colspan="1" rowspan="1">75.98 &#177; 0.99</td><td align="left" colspan="1" rowspan="1">77.25 &#177; 1.24</td><td align="left" colspan="1" rowspan="1">81.65 &#177; 0.45</td></tr><tr><td align="left" colspan="1" rowspan="1">#feat</td><td align="left" colspan="1" rowspan="1">30</td><td align="left" colspan="1" rowspan="1">34</td><td align="left" colspan="1" rowspan="1">28</td><td align="left" colspan="1" rowspan="1">27</td><td align="left" colspan="1" rowspan="1">25</td><td align="left" colspan="1" rowspan="1">18</td></tr><tr><td align="left" colspan="1" rowspan="1">ETime</td><td align="left" colspan="1" rowspan="1">877.98</td><td align="left" colspan="1" rowspan="1">811.63</td><td align="left" colspan="1" rowspan="1">799.25</td><td align="left" colspan="1" rowspan="1">1000.2</td><td align="left" colspan="1" rowspan="1">975.87</td><td align="left" colspan="1" rowspan="1">623.25</td></tr><tr><td align="left" rowspan="3" colspan="1">SRBCT</td><td align="left" colspan="1" rowspan="1">Acc &#177; Std</td><td align="left" colspan="1" rowspan="1">95.63 &#177; 1.32</td><td align="left" colspan="1" rowspan="1">94.85 &#177; 1.02</td><td align="left" colspan="1" rowspan="1">96.35 &#177; 0.96</td><td align="left" colspan="1" rowspan="1">93.02 &#177; 1.88</td><td align="left" colspan="1" rowspan="1">94.25 &#177; 0.91</td><td align="left" colspan="1" rowspan="1">99.52 &#177; 0.38</td></tr><tr><td align="left" colspan="1" rowspan="1">#feat</td><td align="left" colspan="1" rowspan="1">19</td><td align="left" colspan="1" rowspan="1">21</td><td align="left" colspan="1" rowspan="1">22</td><td align="left" colspan="1" rowspan="1">17</td><td align="left" colspan="1" rowspan="1">27</td><td align="left" colspan="1" rowspan="1">11</td></tr><tr><td align="left" colspan="1" rowspan="1">ETime</td><td align="left" colspan="1" rowspan="1">889.25</td><td align="left" colspan="1" rowspan="1">966.37</td><td align="left" colspan="1" rowspan="1">1552.74</td><td align="left" colspan="1" rowspan="1">966.52</td><td align="left" colspan="1" rowspan="1">877.63</td><td align="left" colspan="1" rowspan="1">844.25</td></tr><tr><td align="left" rowspan="3" colspan="1">Lung cancer</td><td align="left" colspan="1" rowspan="1">Acc &#177; Std</td><td align="left" colspan="1" rowspan="1">94.25 &#177; 0.96</td><td align="left" colspan="1" rowspan="1">92.22 &#177; 1.36</td><td align="left" colspan="1" rowspan="1">91.52 &#177; 0.96</td><td align="left" colspan="1" rowspan="1">93.52 &#177; 0.68</td><td align="left" colspan="1" rowspan="1">91.55 &#177; 1.44</td><td align="left" colspan="1" rowspan="1">95.22 &#177; 0.31</td></tr><tr><td align="left" colspan="1" rowspan="1">#feat</td><td align="left" colspan="1" rowspan="1">22</td><td align="left" colspan="1" rowspan="1">19</td><td align="left" colspan="1" rowspan="1">31</td><td align="left" colspan="1" rowspan="1">37</td><td align="left" colspan="1" rowspan="1">32</td><td align="left" colspan="1" rowspan="1">15</td></tr><tr><td align="left" colspan="1" rowspan="1">ETime</td><td align="left" colspan="1" rowspan="1">788.63</td><td align="left" colspan="1" rowspan="1">688.52</td><td align="left" colspan="1" rowspan="1">744.25</td><td align="left" colspan="1" rowspan="1">975.25</td><td align="left" colspan="1" rowspan="1">833.41</td><td align="left" colspan="1" rowspan="1">522.85</td></tr></tbody></table></table-wrap></p><p id="Par80">The comparative performance of the proposed method against five evolutionary algorithms (Genetic Algorithm, Particle Swarm Optimization, Differential Evolution, Teaching-Learning-Based Optimization, and Gravitational Search Algorithm) is summarized in Table <xref rid="Tab7" ref-type="table">7</xref>. The evaluation uses six microarray datasets and metrics for precision (Acc &#177; Std), feature selection count (feat), and execution time (ETime). The proposed method consistently achieves the highest accuracy with the lowest standard deviations on 94.71 &#177; 0.57 for Leukemia Cancer, 99.52 &#177; 0.38 for SRBCT and selects the fewest features as 11 for SRBCT, 14 for Ovarian, demonstrating superior efficiency and precision in gene selection for cancer classification. Additionally, it exhibits the lowest execution times (secs) in most datasets 522.85 for Lung Cancer, outperforming the other algorithms, which require more features and longer runtimes, thus highlighting the proposed method&#8217;s effectiveness and computational efficiency. Table <xref rid="Tab8" ref-type="table">8</xref> display the best accuracy and selected number of features in our and GA. From Table <xref rid="Tab8" ref-type="table">8</xref>, findings indicated that, on average, 97.66% of the Lung cancer data achieves the average classification accuracy on TLBO, and our method with SVM-R demonstrated good performance values compared to the other on gene datasets and was very competitive regarding fitness values.<table-wrap id="Tab8" position="float" orientation="portrait"><label>Table 8</label><caption><p>Comparative analysis of the experimental performance on the best F-measure six gene datasets.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Data</th><th align="left" colspan="1" rowspan="1">Kfold</th><th align="left" colspan="1" rowspan="1">Proposed</th><th align="left" colspan="1" rowspan="1">GA</th><th align="left" colspan="1" rowspan="1">PSO</th><th align="left" colspan="1" rowspan="1">DE</th><th align="left" colspan="1" rowspan="1">TLBO</th><th align="left" colspan="1" rowspan="1">GSA</th><th align="left" colspan="1" rowspan="1">Data</th><th align="left" colspan="1" rowspan="1">Proposed</th><th align="left" colspan="1" rowspan="1">GA</th><th align="left" colspan="1" rowspan="1">PSO</th><th align="left" colspan="1" rowspan="1">DE</th><th align="left" colspan="1" rowspan="1">TLBO</th><th align="left" colspan="1" rowspan="1">GSA</th></tr></thead><tbody><tr><td align="left" rowspan="5" colspan="1">Lung</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">98.52</td><td align="left" colspan="1" rowspan="1">94.25</td><td align="left" colspan="1" rowspan="1">93.48</td><td align="left" colspan="1" rowspan="1">96.02</td><td align="left" colspan="1" rowspan="1">91.26</td><td align="left" colspan="1" rowspan="1">90.32</td><td align="left" rowspan="5" colspan="1">SRBCT</td><td align="left" colspan="1" rowspan="1">99.65</td><td align="left" colspan="1" rowspan="1">95.63</td><td align="left" colspan="1" rowspan="1">92.66</td><td align="left" colspan="1" rowspan="1">94.78</td><td align="left" colspan="1" rowspan="1">91.33</td><td align="left" colspan="1" rowspan="1">96.38</td></tr><tr><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">100</td><td align="left" colspan="1" rowspan="1">96.22</td><td align="left" colspan="1" rowspan="1">90.25</td><td align="left" colspan="1" rowspan="1">91.99</td><td align="left" colspan="1" rowspan="1">93.78</td><td align="left" colspan="1" rowspan="1">91.63</td><td align="left" colspan="1" rowspan="1">98.62</td><td align="left" colspan="1" rowspan="1">95.84</td><td align="left" colspan="1" rowspan="1">93.88</td><td align="left" colspan="1" rowspan="1">91.02</td><td align="left" colspan="1" rowspan="1">90.02</td><td align="left" colspan="1" rowspan="1">93.78</td></tr><tr><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">97.66</td><td align="left" colspan="1" rowspan="1">89.32</td><td align="left" colspan="1" rowspan="1">93.78</td><td align="left" colspan="1" rowspan="1">90.48</td><td align="left" colspan="1" rowspan="1">93.65</td><td align="left" colspan="1" rowspan="1">89.3</td><td align="left" colspan="1" rowspan="1">100</td><td align="left" colspan="1" rowspan="1">97.25</td><td align="left" colspan="1" rowspan="1">96.71</td><td align="left" colspan="1" rowspan="1">93.65</td><td align="left" colspan="1" rowspan="1">93.78</td><td align="left" colspan="1" rowspan="1">96.78</td></tr><tr><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">95.63</td><td align="left" colspan="1" rowspan="1">90.64</td><td align="left" colspan="1" rowspan="1">90.55</td><td align="left" colspan="1" rowspan="1">92.78</td><td align="left" colspan="1" rowspan="1">100</td><td align="left" colspan="1" rowspan="1">88.12</td><td align="left" colspan="1" rowspan="1">99.03</td><td align="left" colspan="1" rowspan="1">98.36</td><td align="left" colspan="1" rowspan="1">90.01</td><td align="left" colspan="1" rowspan="1">95.78</td><td align="left" colspan="1" rowspan="1">91.85</td><td align="left" colspan="1" rowspan="1">95.63</td></tr><tr><td align="left" colspan="1" rowspan="1">10</td><td align="left" colspan="1" rowspan="1">90.88</td><td align="left" colspan="1" rowspan="1">91.36</td><td align="left" colspan="1" rowspan="1">91.65</td><td align="left" colspan="1" rowspan="1">91.66</td><td align="left" colspan="1" rowspan="1">88.25</td><td align="left" colspan="1" rowspan="1">88.88</td><td align="left" colspan="1" rowspan="1">97.52</td><td align="left" colspan="1" rowspan="1">92.65</td><td align="left" colspan="1" rowspan="1">93.66</td><td align="left" colspan="1" rowspan="1">96.55</td><td align="left" colspan="1" rowspan="1">93.88</td><td align="left" colspan="1" rowspan="1">97.12</td></tr><tr><td align="left" rowspan="5" colspan="1">MLL</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">88.25</td><td align="left" colspan="1" rowspan="1">87.36</td><td align="left" colspan="1" rowspan="1">79.36</td><td align="left" colspan="1" rowspan="1">84.32</td><td align="left" colspan="1" rowspan="1">76.95</td><td align="left" colspan="1" rowspan="1">77.41</td><td align="left" rowspan="5" colspan="1">CNS</td><td align="left" colspan="1" rowspan="1">88.25</td><td align="left" colspan="1" rowspan="1">84.63</td><td align="left" colspan="1" rowspan="1">86.36</td><td align="left" colspan="1" rowspan="1">77.52</td><td align="left" colspan="1" rowspan="1">76.35</td><td align="left" colspan="1" rowspan="1">81.35</td></tr><tr><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">90.78</td><td align="left" colspan="1" rowspan="1">80.02</td><td align="left" colspan="1" rowspan="1">78.21</td><td align="left" colspan="1" rowspan="1">77.94</td><td align="left" colspan="1" rowspan="1">77.25</td><td align="left" colspan="1" rowspan="1">72.36</td><td align="left" colspan="1" rowspan="1">80.02</td><td align="left" colspan="1" rowspan="1">80.01</td><td align="left" colspan="1" rowspan="1">87.54</td><td align="left" colspan="1" rowspan="1">78.63</td><td align="left" colspan="1" rowspan="1">79.62</td><td align="left" colspan="1" rowspan="1">82.65</td></tr><tr><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">89.34</td><td align="left" colspan="1" rowspan="1">83.55</td><td align="left" colspan="1" rowspan="1">77.65</td><td align="left" colspan="1" rowspan="1">71.65</td><td align="left" colspan="1" rowspan="1">78.38</td><td align="left" colspan="1" rowspan="1">78.62</td><td align="left" colspan="1" rowspan="1">88.14</td><td align="left" colspan="1" rowspan="1">81.36</td><td align="left" colspan="1" rowspan="1">86.55</td><td align="left" colspan="1" rowspan="1">78.95</td><td align="left" colspan="1" rowspan="1">77.85</td><td align="left" colspan="1" rowspan="1">80.05</td></tr><tr><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">91.87</td><td align="left" colspan="1" rowspan="1">81.63</td><td align="left" colspan="1" rowspan="1">72.96</td><td align="left" colspan="1" rowspan="1">75.38</td><td align="left" colspan="1" rowspan="1">70.14</td><td align="left" colspan="1" rowspan="1">77.62</td><td align="left" colspan="1" rowspan="1">81.11</td><td align="left" colspan="1" rowspan="1">82.63</td><td align="left" colspan="1" rowspan="1">85.96</td><td align="left" colspan="1" rowspan="1">71.02</td><td align="left" colspan="1" rowspan="1">79.65</td><td align="left" colspan="1" rowspan="1">80</td></tr><tr><td align="left" colspan="1" rowspan="1">10</td><td align="left" colspan="1" rowspan="1">92.45</td><td align="left" colspan="1" rowspan="1">80.32</td><td align="left" colspan="1" rowspan="1">79.03</td><td align="left" colspan="1" rowspan="1">75.33</td><td align="left" colspan="1" rowspan="1">74.63</td><td align="left" colspan="1" rowspan="1">71.02</td><td align="left" colspan="1" rowspan="1">82.94</td><td align="left" colspan="1" rowspan="1">86.55</td><td align="left" colspan="1" rowspan="1">83.78</td><td align="left" colspan="1" rowspan="1">70.09</td><td align="left" colspan="1" rowspan="1">80.54</td><td align="left" colspan="1" rowspan="1">79.99</td></tr><tr><td align="left" rowspan="5" colspan="1">Leukemia</td><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">80.26</td><td align="left" colspan="1" rowspan="1">77.61</td><td align="left" colspan="1" rowspan="1">82.12</td><td align="left" colspan="1" rowspan="1">80.32</td><td align="left" colspan="1" rowspan="1">80.32</td><td align="left" colspan="1" rowspan="1">71.6</td><td align="left" rowspan="5" colspan="1">Ovarian</td><td align="left" colspan="1" rowspan="1">84.65</td><td align="left" colspan="1" rowspan="1">80.03</td><td align="left" colspan="1" rowspan="1">79.54</td><td align="left" colspan="1" rowspan="1">79.63</td><td align="left" colspan="1" rowspan="1">80.24</td><td align="left" colspan="1" rowspan="1">88.95</td></tr><tr><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">81.63</td><td align="left" colspan="1" rowspan="1">76.95</td><td align="left" colspan="1" rowspan="1">81.96</td><td align="left" colspan="1" rowspan="1">79.03</td><td align="left" colspan="1" rowspan="1">81.33</td><td align="left" colspan="1" rowspan="1">74.63</td><td align="left" colspan="1" rowspan="1">88.06</td><td align="left" colspan="1" rowspan="1">80.07</td><td align="left" colspan="1" rowspan="1">77.25</td><td align="left" colspan="1" rowspan="1">80.05</td><td align="left" colspan="1" rowspan="1">81.99</td><td align="left" colspan="1" rowspan="1">80.41</td></tr><tr><td align="left" colspan="1" rowspan="1">6</td><td align="left" colspan="1" rowspan="1">82.78</td><td align="left" colspan="1" rowspan="1">74.02</td><td align="left" colspan="1" rowspan="1">88.45</td><td align="left" colspan="1" rowspan="1">82.33</td><td align="left" colspan="1" rowspan="1">78.14</td><td align="left" colspan="1" rowspan="1">75.95</td><td align="left" colspan="1" rowspan="1">87.09</td><td align="left" colspan="1" rowspan="1">81.65</td><td align="left" colspan="1" rowspan="1">79.6</td><td align="left" colspan="1" rowspan="1">78.14</td><td align="left" colspan="1" rowspan="1">82.47</td><td align="left" colspan="1" rowspan="1">78.58</td></tr><tr><td align="left" colspan="1" rowspan="1">8</td><td align="left" colspan="1" rowspan="1">81.66</td><td align="left" colspan="1" rowspan="1">70.22</td><td align="left" colspan="1" rowspan="1">81.97</td><td align="left" colspan="1" rowspan="1">78.41</td><td align="left" colspan="1" rowspan="1">77.96</td><td align="left" colspan="1" rowspan="1">78.55</td><td align="left" colspan="1" rowspan="1">88.95</td><td align="left" colspan="1" rowspan="1">83.74</td><td align="left" colspan="1" rowspan="1">78.18</td><td align="left" colspan="1" rowspan="1">77.11</td><td align="left" colspan="1" rowspan="1">81.63</td><td align="left" colspan="1" rowspan="1">77.94</td></tr><tr><td align="left" colspan="1" rowspan="1">10</td><td align="left" colspan="1" rowspan="1">78.22</td><td align="left" colspan="1" rowspan="1">74.3</td><td align="left" colspan="1" rowspan="1">79.99</td><td align="left" colspan="1" rowspan="1">79.86</td><td align="left" colspan="1" rowspan="1">73.85</td><td align="left" colspan="1" rowspan="1">73.45</td><td align="left" colspan="1" rowspan="1">87.65</td><td align="left" colspan="1" rowspan="1">83.74</td><td align="left" colspan="1" rowspan="1">77.98</td><td align="left" colspan="1" rowspan="1">79.65</td><td align="left" colspan="1" rowspan="1">85.27</td><td align="left" colspan="1" rowspan="1">72.85</td></tr></tbody></table></table-wrap></p><p id="Par81">
<fig id="Fig6" position="float" orientation="portrait"><label>Fig. 6</label><caption><p>Comparison of computational time on six gene datasets.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="MO7" position="float" orientation="portrait" xlink:href="41598_2025_29921_Fig6_HTML.jpg"/></fig>
</p><p id="Par82">Figure <xref rid="Fig6" ref-type="fig">6</xref> presents a comparative analysis of the execution times for six optimization algorithms, TLBO, PSO, DE, GA, and GSA, across six gene datasets: Leukemia, CNS, Ovarian, Lung, SRBCT, and MLL. The proposed method consistently demonstrates the lowest execution times across all datasets. This simplicity allows TLBO to maintain competitive execution times, particularly in datasets like Leukemia and Ovarian. Traditional algorithms, including GA, DE, PSO, and GSA, exhibit varying levels of efficiency. GA and DE show moderate execution times, with GA often slower due to its reliance on computationally intensive operations like crossover and mutation, as well as population-based evaluations that require extensive fitness calculations. PSO and GSA, on the other hand, tend to perform less efficiently, especially in high-dimensional datasets such as Lung and MLL.<fig id="Fig7" position="float" orientation="portrait"><label>Fig. 7</label><caption><p>Boxplot on lung cancer, MLL, leukemia gene datasets.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="MO8" position="float" orientation="portrait" xlink:href="41598_2025_29921_Fig7_HTML.jpg"/></fig></p><p id="Par83">The boxplot described in Figs. <xref rid="Fig7" ref-type="fig">7</xref> and <xref rid="Fig8" ref-type="fig">8</xref> visualizes MCC performance metric for six algorithms: Our, Genetic Algorithm (GA), Particle Swarm Optimization (PSO), Differential Evolution (DE), Teaching-Learning-Based Optimization (TLBO), and Gravitational Search Algorithm (GSA) across six gene datasets. The median MCC values indicate the central tendency of each algorithm&#8217;s performance, with our algorithm and PSO both achieving the highest median MCC, followed by TLBO, while GA, DE, and GSA each have a median MCC. The interquartile range (IQR) shown in the boxplot represents the spread of MCC values within the middle 50% of the data, indicating variability in performance consistency. Additionally, the boxplot includes the minimum and maximum MCC values for each algorithm, highlighting the full range of performance across the datasets. Since the description of used methods across used datasets suggests that the MCC values are averaged across datasets, the Proposed algorithm has superior performance based on its higher median MCC, while the lower medians of GA, DE, and GSA indicate relatively less consistent performance in optimizing gene selection for six cancer datasets.<table-wrap id="Tab9" position="float" orientation="portrait"><label>Table 9</label><caption><p>Comparative analysis performance on NCBI <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="pmc:entrez-geo" xlink:href="GSE16619">GSE16619</ext-link> series includes SNP data related to BC.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Algorithms</th><th align="left" colspan="1" rowspan="1">Acc</th><th align="left" colspan="1" rowspan="1">Sen</th><th align="left" colspan="1" rowspan="1">Sep</th><th align="left" colspan="1" rowspan="1">Fmes</th><th align="left" colspan="1" rowspan="1">MCC</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">GA</td><td align="left" colspan="1" rowspan="1">89.52</td><td align="left" colspan="1" rowspan="1">90.65</td><td align="left" colspan="1" rowspan="1">87.25</td><td align="left" colspan="1" rowspan="1">89.06</td><td align="left" colspan="1" rowspan="1">88.65</td></tr><tr><td align="left" colspan="1" rowspan="1">PSO</td><td align="left" colspan="1" rowspan="1">88.74</td><td align="left" colspan="1" rowspan="1">87.65</td><td align="left" colspan="1" rowspan="1">88.63</td><td align="left" colspan="1" rowspan="1">88.62</td><td align="left" colspan="1" rowspan="1">87.56</td></tr><tr><td align="left" colspan="1" rowspan="1">DE</td><td align="left" colspan="1" rowspan="1">81.25</td><td align="left" colspan="1" rowspan="1">85.25</td><td align="left" colspan="1" rowspan="1">91.52</td><td align="left" colspan="1" rowspan="1">85.15</td><td align="left" colspan="1" rowspan="1">88.96</td></tr><tr><td align="left" colspan="1" rowspan="1">TLBO</td><td align="left" colspan="1" rowspan="1">83.65</td><td align="left" colspan="1" rowspan="1">90.36</td><td align="left" colspan="1" rowspan="1">88.96</td><td align="left" colspan="1" rowspan="1">84.78</td><td align="left" colspan="1" rowspan="1">84.25</td></tr><tr><td align="left" colspan="1" rowspan="1">GSA</td><td align="left" colspan="1" rowspan="1">89.32</td><td align="left" colspan="1" rowspan="1">88.03</td><td align="left" colspan="1" rowspan="1">83.33</td><td align="left" colspan="1" rowspan="1">83.25</td><td align="left" colspan="1" rowspan="1">80.55</td></tr><tr><td align="left" colspan="1" rowspan="1">Our</td><td align="left" colspan="1" rowspan="1">93.52</td><td align="left" colspan="1" rowspan="1">95.62</td><td align="left" colspan="1" rowspan="1">94.12</td><td align="left" colspan="1" rowspan="1">93.52</td><td align="left" colspan="1" rowspan="1">96.52</td></tr></tbody></table></table-wrap></p><p id="Par84">Table <xref rid="Tab9" ref-type="table">9</xref> shows a comprehensive performance comparison of various nature-inspired optimization algorithms applied to SNP microarray data from the NCBI GEO dataset <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="pmc:entrez-geo" xlink:href="GSE16619">GSE16619</ext-link>, which contains breast cancer (BC)-related genetic information. The proposed method results are compared with the Acc and Sen, Sep , Fmeas, MCC achieved using the GA, PSO, DE,TLBO, GSA and our algorithm. As can be clearly seen, the performance of the proposed wrapper was significantly better and outperformed the compared methods on the given BC data. The evaluation employs five standard metrics that assess different aspects of classification performance when identifying breast cancer biomarkers from the SNP data. Genetic Algorithm (GA) demonstrates strong overall performance with 89.52% accuracy, showing balanced sensitivity (90.65%) and specificity (87.25%), indicating its effectiveness in correctly identifying both positive (cancer) and negative (normal) cases. Particle Swarm Optimization (PSO) shows slightly lower but comparable results (88.74% accuracy), with particularly good specificity (88.63%), suggesting it may be more conservative in making positive predictions.</p><p id="Par85">Differential Evolution (DE) exhibits an interesting performance profile, where while its accuracy is lower (81.25%), it achieves the highest specificity (91.52%) among the conventional methods, indicating exceptional ability to correctly identify negative cases, though at the cost of some overall accuracy. Teaching-Learning-Based Optimization (TLBO) shows good sensitivity (90.36%) but relatively lower F-measure (84.78%), suggesting it may struggle slightly with precision in its positive predictions. Gravitational Search Algorithm (GSA) maintains high accuracy (89.32%) but shows the lowest specificity (83.33%) among the baseline methods, indicating a tendency toward more false positives.</p><p id="Par86">The proposed &#8220;Our&#8221; method outperforms all other approaches across every metric, achieving 93.52% accuracy, 95.62% sensitivity, and 94.12% specificity, demonstrating its superior capability to correctly classify both cancer and normal samples in the SNP microarray data. The particularly high Matthews Correlation Coefficient (MCC) of 96.52% strongly suggests that this method maintains excellent performance even when accounting for potential class imbalances in the breast cancer dataset. These results indicate that the proposed approach may be better at identifying meaningful SNP patterns associated with breast cancer while minimizing both false positives and false negatives compared to established optimization algorithms.<fig id="Fig8" position="float" orientation="portrait"><label>Fig. 8</label><caption><p>Boxplot on SRBCT, CNS, ovarian gene datasets.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="MO9" position="float" orientation="portrait" xlink:href="41598_2025_29921_Fig8_HTML.jpg"/></fig></p></sec><sec id="Sec17"><title>Statistical analysis</title><p id="Par87">The Friedman test<sup><xref ref-type="bibr" rid="CR58">58</xref></sup> is a non-parametric statistical method used to detect differences in treatments across multiple related samples, making it ideal for analyzing repeated measures or matched data in bioinformatics, such as gene expression levels across different conditions. It ranks the observations within each subject across treatments and evaluates whether the rank sums differ significantly to test the null hypothesis that all treatments have identical effects. This test is particularly valuable when data violates normality assumptions, offering a robust alternative to parametric tests. By accounting for within-subject variability, the Friedman test ensures reliable comparisons, though post-hoc tests are often needed to identify specific pairwise differences. The Table <xref rid="Tab10" ref-type="table">10</xref> presents the average rankings of six optimization algorithms based on the Friedman test, a non-parametric statistical method used to compare multiple algorithms across different datasets. The rankings reveal clear performance differences among the algorithms, with the proposed method (denoted as OUR) achieving the best possible ranking of 1, indicating superior performance compared to all other methods. Differential Evolution (DE) follows as the second-best performing algorithm with an average ranking of 5.1667, demonstrating its effectiveness as a conventional optimization approach. Particle Swarm Optimization (PSO) obtains a ranking of 4.3333, placing it in the middle of the performance spectrum. The remaining algorithms&#8212;Genetic Algorithm (GA), Teaching-Learning-Based Optimization (TLBO), and Gravitational Search Algorithm (GSA)&#8212;show relatively similar performance levels with rankings of 3.6667, 3.3333, and 3.5 respectively. These closely clustered rankings suggest comparable effectiveness among these three methods, though all are outperformed by both the proposed method and DE. The significant gap between the top-ranked proposed method (1) and the next best algorithm (DE at 5.1667) highlights the substantial performance improvement achieved by the novel approach. These rankings provide valuable insights for algorithm selection in optimization tasks, with the proposed method emerging as the clear preferred choice based on this statistical evaluation. The results demonstrate the effectiveness of the Friedman test in discriminating between algorithm performances and establishing robust performance hierarchies. Friedman statistic (distributed according to chi-square with 5 degrees of freedom): 16.761905. P-value computed by Friedman Test: 0.004974.<table-wrap id="Tab10" position="float" orientation="portrait"><label>Table 10</label><caption><p>Average rankings of the algorithms based on MCC values (Friedman).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Algorithm</th><th align="left" colspan="1" rowspan="1">Ranking</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">GA</td><td align="left" colspan="1" rowspan="1">3.6667</td></tr><tr><td align="left" colspan="1" rowspan="1">PSO</td><td align="left" colspan="1" rowspan="1">4.3333</td></tr><tr><td align="left" colspan="1" rowspan="1">DE</td><td align="left" colspan="1" rowspan="1">5.1667</td></tr><tr><td align="left" colspan="1" rowspan="1">TLBO</td><td align="left" colspan="1" rowspan="1">3.3333</td></tr><tr><td align="left" colspan="1" rowspan="1">GSA</td><td align="left" colspan="1" rowspan="1">3.5</td></tr><tr><td align="left" colspan="1" rowspan="1">OUR</td><td align="left" colspan="1" rowspan="1">1</td></tr></tbody></table></table-wrap></p><p id="Par88">The Table <xref rid="Tab11" ref-type="table">11</xref> presents a post-hoc statistical comparison of multiple nature-inspired algorithms using the Friedman test with a significance level <inline-formula id="IEq96"><tex-math id="d33e3557">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(\alpha )$$\end{document}</tex-math></inline-formula> set at 0.05. The Friedman test, a non-parametric alternative to repeated-measures ANOVA, ranks the algorithms across different datasets to detect significant performance differences. The table lists five algorithms in descending order of their statistical significance: Differential Evolution (DE), Particle Swarm Optimization (PSO), Genetic Algorithm (GA), Gravitational Search Algorithm (GSA), and Teaching-Learning-Based Optimization (TLBO). Each algorithm&#8217;s performance is compared against a control method (presumably the best-performing one, denoted as <inline-formula id="IEq97"><tex-math id="d33e3561">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$R_0$$\end{document}</tex-math></inline-formula>) through the standardized test statistic <inline-formula id="IEq98"><tex-math id="d33e3565">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$z = (R_0 - R_i)/SE$$\end{document}</tex-math></inline-formula>, where <inline-formula id="IEq99"><tex-math id="d33e3569">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$R_0$$\end{document}</tex-math></inline-formula> is the control&#8217;s average rank, <inline-formula id="IEq100"><tex-math id="d33e3574">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$R_i$$\end{document}</tex-math></inline-formula> is the algorithm&#8217;s average rank, and SE is the standard error of the difference. The p-values indicate the probability of observing the given differences under the null hypothesis (no performance difference). DE shows the strongest statistical significance with <inline-formula id="IEq101"><tex-math id="d33e3578">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p = 0.000115$$\end{document}</tex-math></inline-formula>, far below the <inline-formula id="IEq102"><tex-math id="d33e3582">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha$$\end{document}</tex-math></inline-formula> threshold, suggesting it outperforms the control method with high confidence. PSO follows with <inline-formula id="IEq103"><tex-math id="d33e3586">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p = 0.002028$$\end{document}</tex-math></inline-formula>, also significant, though less so than DE. GA, GSA, and TLBO exhibit progressively weaker evidence against the null hypothesis, with p-values of 0.013555, 0.020638, and 0.030754, respectively. While these values are below the conventional <inline-formula id="IEq104"><tex-math id="d33e3590">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(\alpha )$$\end{document}</tex-math></inline-formula> = 0.05, their significance is marginal compared to DE and PSO. The Holm and Li columns represent adjusted p-value thresholds for multiple comparisons. The Holm procedure, a step-down method, sequentially tightens the significance threshold to control the family-wise error rate (FWER). Here, DE, PSO, and GA remain significant under Holm&#8217;s correction, as their p-values are below their respective adjusted thresholds (0.01, 0.0125, and 0.016667). GSA and TLBO, however, fail to meet their stricter Holm thresholds (0.025 and 0.05, respectively).<table-wrap id="Tab11" position="float" orientation="portrait"><label>Table 11</label><caption><p>Post Hoc comparison Table for <inline-formula id="IEq105"><tex-math id="d33e3600">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha =0.05$$\end{document}</tex-math></inline-formula> (FRIEDMAN).</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1"><italic toggle="yes">i</italic></th><th align="left" colspan="1" rowspan="1">Algorithm</th><th align="left" colspan="1" rowspan="1"><inline-formula id="IEq106"><tex-math id="d33e3621">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$z=(R_0 - R_i)/SE$$\end{document}</tex-math></inline-formula></th><th align="left" colspan="1" rowspan="1"><italic toggle="yes">p</italic></th><th align="left" colspan="1" rowspan="1">Holm</th><th align="left" colspan="1" rowspan="1">Li</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">5</td><td align="left" colspan="1" rowspan="1">DE</td><td align="left" colspan="1" rowspan="1">3.857584</td><td align="left" colspan="1" rowspan="1">0.000115</td><td align="left" colspan="1" rowspan="1">0.01</td><td align="left" colspan="1" rowspan="1">0.051013</td></tr><tr><td align="left" colspan="1" rowspan="1">4</td><td align="left" colspan="1" rowspan="1">PSO</td><td align="left" colspan="1" rowspan="1">3.086067</td><td align="left" colspan="1" rowspan="1">0.002028</td><td align="left" colspan="1" rowspan="1">0.0125</td><td align="left" colspan="1" rowspan="1">0.051013</td></tr><tr><td align="left" colspan="1" rowspan="1">3</td><td align="left" colspan="1" rowspan="1">GA</td><td align="left" colspan="1" rowspan="1">2.468854</td><td align="left" colspan="1" rowspan="1">0.013555</td><td align="left" colspan="1" rowspan="1">0.016667</td><td align="left" colspan="1" rowspan="1">0.051013</td></tr><tr><td align="left" colspan="1" rowspan="1">2</td><td align="left" colspan="1" rowspan="1">GSA</td><td align="left" colspan="1" rowspan="1">2.31455</td><td align="left" colspan="1" rowspan="1">0.020638</td><td align="left" colspan="1" rowspan="1">0.025</td><td align="left" colspan="1" rowspan="1">0.051013</td></tr><tr><td align="left" colspan="1" rowspan="1">1</td><td align="left" colspan="1" rowspan="1">TLBO</td><td align="left" colspan="1" rowspan="1">2.160247</td><td align="left" colspan="1" rowspan="1">0.030754</td><td align="left" colspan="1" rowspan="1">0.05</td><td align="left" colspan="1" rowspan="1">0.05</td></tr></tbody></table></table-wrap></p><p id="Par89">Li&#8217;s procedure rejects those hypotheses that have an unadjusted p-value <inline-formula id="IEq107"><tex-math id="d33e3700">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\le 0.05$$\end{document}</tex-math></inline-formula>.</p></sec><sec id="Sec18"><title>Biological interpretation</title><p id="Par90">From a biological perspective, only a small subset of genes in microarray datasets is relevant for the diagnostic and prognostic prediction of cancer. The proposed method aims to identify an optimal, compact subset of genes that achieves high classification accuracy across six gene datasets. Analyzing these selected genes alongside those reported in the literature is crucial to uncovering their biological significance for each dataset. In this section, we evaluate the final subset of genes selected by our proposed model (see Table <xref rid="Tab12" ref-type="table">12</xref>), focusing on the most significant genes identified for each of the six datasets, emphasizing their optimality and classification accuracy.<table-wrap id="Tab12" position="float" orientation="portrait"><label>Table 12</label><caption><p>Optimal number of genes selected by our method.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" colspan="1" rowspan="1">Datasets</th><th align="left" colspan="1" rowspan="1">Accuracy</th><th align="left" colspan="1" rowspan="1">#Feat</th><th align="left" colspan="1" rowspan="1">Interpretation of gene</th></tr></thead><tbody><tr><td align="left" colspan="1" rowspan="1">Leukaemia</td><td align="left" colspan="1" rowspan="1">97.85</td><td align="left" colspan="1" rowspan="1">17</td><td align="left" colspan="1" rowspan="1"><p>AFFX-HUMTFRR/M11507_3_at, AB002318_at, AC002115_cds1_at, D13897_rna2_at,</p><p>D14822_at, D25215_at, D83782_at,</p><p>HG1019-HT1019_at, HG4297-HT4567_at, J04794_at, L06499_at,</p><p>M14123_xpt3_at, M62402_at, U07563_cds1_at, V00535_rna2_s_at, X84213_s_at</p></td></tr><tr><td align="left" colspan="1" rowspan="1">MLL</td><td align="left" colspan="1" rowspan="1">94.25</td><td align="left" colspan="1" rowspan="1">18</td><td align="left" colspan="1" rowspan="1"><p>AFFX-HUMGAPDH/M33197_5_at, 31677_at, 32416_at, 33702_f_at,</p><p>35600_at, 36076_g_at,</p><p>37208_at, 37548_at, 38335_at, 38674_at, 39048_at,</p><p>39773_at, 40072_at, 40504_at, 41159_at,</p><p>41180_i_at, 41206_r_at, 41731_g_at</p></td></tr><tr><td align="left" colspan="1" rowspan="1">Ovarian</td><td align="left" colspan="1" rowspan="1">96.75</td><td align="left" colspan="1" rowspan="1">14</td><td align="left" colspan="1" rowspan="1"><p>MZ0.16141209, MZ1.9090029, MZ3.5555556,</p><p>, MZ6.8306324, MZ7.7889223, MZ10.369405, MZ12.38191,</p><p>MZ17.406119, MZ22.835709, MZ28.800563,</p><p>MZ14608.301, MZ14728.11, MZ15067.552</p></td></tr><tr><td align="left" colspan="1" rowspan="1">CNS</td><td align="left" colspan="1" rowspan="1">95.25</td><td align="left" colspan="1" rowspan="1">18</td><td align="left" colspan="1" rowspan="1"><p>AFFX-BioDn-5_st, AC000061_cds2_at, D50922_at, D86096_cds3_at, HG1723-HT1729_at,</p><p>HG3514-HT3708_at, K03008_cds1_at, L14542_at, L41919_rna1_at, M18731_at,</p><p>M60748_at, M77142_at, M88282_at, U08998_at,</p><p>U31875_at, U72066_at, X04688_at, X14346_at</p></td></tr><tr><td align="left" colspan="1" rowspan="1">SRBCT</td><td align="left" colspan="1" rowspan="1">100</td><td align="left" colspan="1" rowspan="1">11</td><td align="left" colspan="1" rowspan="1"><p>gene15, gene102, gene170, gene321, gene409,</p><p>gene585, gene985, gene1194,</p><p>gene1427, gene1504, gene1972</p></td></tr><tr><td align="left" colspan="1" rowspan="1">Lung cancer</td><td align="left" colspan="1" rowspan="1">100</td><td align="left" colspan="1" rowspan="1">15</td><td align="left" colspan="1" rowspan="1"><p>AFFX-hum_alu_at, AFFX-HUMTFRR/M11507_5_at,</p><p>32398_s_at, 33015_at, 34600_s_at,</p><p>35494_at, 36395_at, 32316_s_at, 32974_at, 34526_s_at, 1381_at,</p><p>1020_s_at, 354_s_at, 172_at, 110_at</p></td></tr></tbody></table></table-wrap></p><p id="Par91">Table <xref rid="Tab12" ref-type="table">12</xref> presents gene selected by our method across six cancer types, demonstrating high classification accuracy ranging from 94.25 to 100%. While these results show strong discriminative power, the biological interpretation requires careful consideration of each gene molecular functions and clinical relevance. For leukemia, the 17-gene signature includes well-characterized hematopoietic markers such as <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="pmc:entrez-nucleotide" xlink:href="J04794">J04794</ext-link> (myeloperoxidase, MPO), a key enzyme in myeloid cells that serves as a standard immunohistochemical marker for acute myeloid leukemia (AML). The signature also contains <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="pmc:entrez-nucleotide" xlink:href="L06499">L06499</ext-link> (cathepsin G, CTSG), a serine protease expressed in neutrophil granules, and <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="pmc:entrez-nucleotide" xlink:href="M62402">M62402</ext-link> (CD33), a transmembrane receptor used clinically as an immunotherapy target in AML. These markers collectively suggest our algorithm has captured essential features of myeloid differentiation and leukocyte activation pathways. Particularly noteworthy is the inclusion of <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="pmc:entrez-nucleotide" xlink:href="D14822">D14822</ext-link> (CEBPA), a transcription factor critical for granulocytic differentiation whose mutations are recognized in the WHO classification of AML. The presence of <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="pmc:entrez-nucleotide" xlink:href="V00535">V00535</ext-link> (a hemoglobin subunit) and several immunoglobulin-related transcripts (e.g., <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="pmc:entrez-nucleotide" xlink:href="X84213">X84213</ext-link>) indicates the signature appropriately discriminates between myeloid and lymphoid lineages, crucial for accurate leukemia classification. The co-selection of these biologically validated markers with less characterized genes (e.g., <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="pmc:entrez-nucleotide" xlink:href="AB002318">AB002318</ext-link>) suggests our method maintains sensitivity to both established and potentially novel biomarkers.</p><p id="Par92">The ovarian cancer gene signature identified by our method demonstrates compelling biological significance through its inclusion of multiple molecular markers with well-characterized roles in ovarian cancer pathogenesis. The signature contains GAPDH (AFFX-HUMGAPDH/M33197_5_at), a crucial glycolytic enzyme whose overexpression is strongly associated with tumor progression and development of chemoresistance in ovarian carcinomas. Particularly significant is the detection of HOXA9 (36076_g_at), a member of the HOX gene family whose dysregulation represents a molecular hallmark of ovarian cancer, known to critically influence cellular proliferation, adhesion dynamics, and metastatic dissemination through modulation of key oncogenic pathways.The signature encompasses genes participating in several fundamental ovarian cancer-related biological processes. These include critical DNA repair mechanisms, potentially involving BRCA1/2-associated genes (38674_at), which are especially relevant given the importance of homologous recombination deficiency in ovarian cancer biology. Additionally, the signature captures genes involved in extracellular matrix remodeling, likely including matrix metalloproteinases (37208_at), which facilitate tumor invasion and metastasis. Genes such as 41159_at and 41731_g_at can be involved in clinically relevant processes including peritoneal metastasis formation, the maintenance of stem cell-like properties in tumor cells.</p><p id="Par93">The lung cancer gene signature includes several markers with well-established diagnostic significance, such as TTF-1 (35494_at, NKX2-1), a crucial transcription factor that serves as a key immunohistochemical marker for lung adenocarcinoma differentiation. The presence of mesothelin (36395_at) is particularly noteworthy as it represents a well-characterized marker for malignant pleural mesothelioma, suggesting our algorithm can distinguish between these histologically challenging differential diagnoses. The inclusion of surfactant-associated proteins (potentially represented by 33015_at and 34600_s_at) aligns with the alveolar origin of many lung adenocarcinomas. The signature also contains genes likely involved in cellular proliferation (32398_s_at) and apoptosis regulation (32974_at), processes frequently dysregulated in non-small cell lung cancer. The combination of well-characterized diagnostic markers (TTF-1, mesothelin) with less studied genes (1381_at, 172_at) indicates our approach maintains sensitivity to both established and potentially novel biomarkers in lung cancer pathology.</p></sec></sec><sec id="Sec19"><title>Conclusion</title><p id="Par94">In the current era, microarray technology enables the simultaneous sequencing of thousands of gene expression levels in biological samples. One of the most prevailing applications is the prediction of cancer or tumor types. However, classifying microarray data is challenging due to its high dimensionality and small sample sizes. Gene selection techniques offer a practical solution to address these challenges in microarray data analysis. In the literature, several bio-inspired wrapper methods have been applied for gene selection and cancer classification, demonstrating promising classification accuracy. Nevertheless, identifying genes linked to cancer-associated biomarkers is critical for understanding the complex origins and expression networks of cancer. By enabling biologists to identify a subset of genes as biomarkers, wrapper-based feature selection provides a promising approach for gene selection. To identify genes associated with cancer, this study proposed a multi-population GSA algorithm combining Opposition-Based Learning (OBL) with kernel Principal Component Analysis (kPCA) method, termed MPKGSA, in order to achieve primary objectives: selecting the most predictive genes and achieving the highest classification accuracy from gene expression datasets. The MPKGSA method aims to distinguish cancer stages and uncover biologically relevant relationships within gene pools, thereby revealing underlying biological mechanisms and guiding clinical decision-making. The performance of MPKGSA was evaluated against other bioinspired techniques on six microarray datasets. Additionally, to evaluate proposed approach performance we have used SNP dataset obtained from Gene Expression Omnibus (GEO) related to breast cancer of the National Center for Biotechnology Information (NCBI). Experimental results demonstrated that MPKGSA outperformed state-of-the-art methods in classification accuracy by effectively selecting highly relevant genes for tumor classification. In the future, a new hybrid evolutionary model with deep learning, based on CNN, will be proposed for the classification of cancer/tumor.</p></sec></body><back><fn-group><fn><p><bold>Publisher&#8217;s note</bold></p><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><notes notes-type="author-contribution"><title>Author contributions</title><p>Alok Kumar Shukla analyzed the data and wrote the main manuscript, Shubhra Dwivedi structured the manuscript and proposed method and analysis tools, and Aishwarya Mishra organized the manuscript, design, and figures.</p></notes><notes notes-type="funding-information"><title>Funding</title><p>Open access funding provided by Manipal University Jaipur. Open Access charges will be provided by Manipal University Jaipur, Jaipur, Rajasthan, India.</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>Data will be available on request to the corresponding author.</p></notes><notes><title>Declarations</title><notes id="FPar1" notes-type="COI-statement"><title>Competing interests</title><p id="Par99">The authors declare no competing interests.</p></notes></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><citation-alternatives><element-citation id="ec-CR1" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yaqoob</surname><given-names>A</given-names></name><name name-style="western"><surname>Verma</surname><given-names>NK</given-names></name><name name-style="western"><surname>Aziz</surname><given-names>RM</given-names></name><name name-style="western"><surname>Shah</surname><given-names>MA</given-names></name></person-group><article-title>Rna-seq analysis for breast cancer detection: a study on paired tissue samples using hybrid optimization and deep learning techniques</article-title><source>J. Cancer Res. Clin. Oncol.</source><year>2024</year><volume>150</volume><fpage>455</fpage><pub-id pub-id-type="pmid">39390265</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s00432-024-05968-z</pub-id><pub-id pub-id-type="pmcid">PMC11467072</pub-id></element-citation><mixed-citation id="mc-CR1" publication-type="journal">Yaqoob, A., Verma, N. K., Aziz, R. M. &amp; Shah, M. A. Rna-seq analysis for breast cancer detection: a study on paired tissue samples using hybrid optimization and deep learning techniques. <italic toggle="yes">J. Cancer Res. Clin. Oncol.</italic><bold>150</bold>, 455 (2024).<pub-id pub-id-type="pmid">39390265</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s00432-024-05968-z</pub-id><pub-id pub-id-type="pmcid">PMC11467072</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR2"><label>2.</label><citation-alternatives><element-citation id="ec-CR2" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yaqoob</surname><given-names>A</given-names></name><etal/></person-group><article-title>Sga-driven feature selection and random forest classification for enhanced breast cancer diagnosis: A comparative study</article-title><source>Sci. Rep.</source><year>2025</year><volume>15</volume><fpage>10944</fpage><pub-id pub-id-type="pmid">40159513</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-025-95786-1</pub-id><pub-id pub-id-type="pmcid">PMC11955515</pub-id></element-citation><mixed-citation id="mc-CR2" publication-type="journal">Yaqoob, A. et al. Sga-driven feature selection and random forest classification for enhanced breast cancer diagnosis: A comparative study. <italic toggle="yes">Sci. Rep.</italic><bold>15</bold>, 10944 (2025).<pub-id pub-id-type="pmid">40159513</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-025-95786-1</pub-id><pub-id pub-id-type="pmcid">PMC11955515</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR3"><label>3.</label><citation-alternatives><element-citation id="ec-CR3" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Agarwalla</surname><given-names>P</given-names></name><name name-style="western"><surname>Mukhopadhyay</surname><given-names>S</given-names></name></person-group><article-title>Gene expression selection for cancer classification using intelligent collaborative filtering and hamming distance guided multi-objective swarm optimization</article-title><source>Appl. Soft Comput.</source><year>2025</year><volume>1</volume><fpage>112654</fpage></element-citation><mixed-citation id="mc-CR3" publication-type="journal">Agarwalla, P. &amp; Mukhopadhyay, S. Gene expression selection for cancer classification using intelligent collaborative filtering and hamming distance guided multi-objective swarm optimization. <italic toggle="yes">Appl. Soft Comput.</italic><bold>1</bold>, 112654 (2025).</mixed-citation></citation-alternatives></ref><ref id="CR4"><label>4.</label><citation-alternatives><element-citation id="ec-CR4" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Saheed</surname><given-names>YK</given-names></name><name name-style="western"><surname>Balogun</surname><given-names>BF</given-names></name><name name-style="western"><surname>Odunayo</surname><given-names>BJ</given-names></name><name name-style="western"><surname>Abdulsalam</surname><given-names>M</given-names></name></person-group><article-title>Microarray gene expression data classification via Wilcoxon sign rank sum and novel grey wolf optimized ensemble learning models</article-title><source>IEEE/ACM Trans. Comput. Biol. Bioinf.</source><year>2023</year><volume>20</volume><fpage>3575</fpage><lpage>3587</lpage><pub-id pub-id-type="doi">10.1109/TCBB.2023.3305429</pub-id><pub-id pub-id-type="pmid">37581968</pub-id></element-citation><mixed-citation id="mc-CR4" publication-type="journal">Saheed, Y. K., Balogun, B. F., Odunayo, B. J. &amp; Abdulsalam, M. Microarray gene expression data classification via Wilcoxon sign rank sum and novel grey wolf optimized ensemble learning models. <italic toggle="yes">IEEE/ACM Trans. Comput. Biol. Bioinf.</italic><bold>20</bold>, 3575&#8211;3587. 10.1109/TCBB.2023.3305429 (2023).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/TCBB.2023.3305429</pub-id><pub-id pub-id-type="pmid">37581968</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR5"><label>5.</label><citation-alternatives><element-citation id="ec-CR5" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dey</surname><given-names>A</given-names></name><name name-style="western"><surname>Das Sharma</surname><given-names>K</given-names></name><name name-style="western"><surname>Sanyal</surname><given-names>T</given-names></name><name name-style="western"><surname>Bhattacharjee</surname><given-names>P</given-names></name><name name-style="western"><surname>Bhattacharjee</surname><given-names>P</given-names></name></person-group><article-title>Identification of biomarkers for arsenicosis employing multiple kernel learning embedded multiobjective swarm intelligence</article-title><source>IEEE Trans. NanoBiosci.</source><year>2023</year><volume>22</volume><fpage>383</fpage><lpage>392</lpage><pub-id pub-id-type="doi">10.1109/TNB.2022.3194091</pub-id><pub-id pub-id-type="pmid">35895661</pub-id></element-citation><mixed-citation id="mc-CR5" publication-type="journal">Dey, A., Das Sharma, K., Sanyal, T., Bhattacharjee, P. &amp; Bhattacharjee, P. Identification of biomarkers for arsenicosis employing multiple kernel learning embedded multiobjective swarm intelligence. <italic toggle="yes">IEEE Trans. NanoBiosci.</italic><bold>22</bold>, 383&#8211;392. 10.1109/TNB.2022.3194091 (2023).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/TNB.2022.3194091</pub-id><pub-id pub-id-type="pmid">35895661</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR6"><label>6.</label><citation-alternatives><element-citation id="ec-CR6" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vashistha</surname><given-names>R</given-names></name><name name-style="western"><surname>Noor</surname><given-names>Z</given-names></name><name name-style="western"><surname>Dasgupta</surname><given-names>S</given-names></name><name name-style="western"><surname>Pu</surname><given-names>J</given-names></name><name name-style="western"><surname>Deng</surname><given-names>S</given-names></name></person-group><article-title>Application of statistical machine learning in biomarker selection</article-title><source>Sci. Rep.</source><year>2023</year><volume>13</volume><fpage>18331</fpage><pub-id pub-id-type="pmid">37884606</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-023-45323-9</pub-id><pub-id pub-id-type="pmcid">PMC10603146</pub-id></element-citation><mixed-citation id="mc-CR6" publication-type="journal">Vashistha, R., Noor, Z., Dasgupta, S., Pu, J. &amp; Deng, S. Application of statistical machine learning in biomarker selection. <italic toggle="yes">Sci. Rep.</italic><bold>13</bold>, 18331 (2023).<pub-id pub-id-type="pmid">37884606</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s41598-023-45323-9</pub-id><pub-id pub-id-type="pmcid">PMC10603146</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR7"><label>7.</label><mixed-citation publication-type="other">Yaqoob, A., Verma, N.&#160;K., Aziz, R.&#160;M. &amp; Saxena, A. Enhancing feature selection through metaheuristic hybrid cuckoo search and harris hawks optimization for cancer classification. In <italic toggle="yes">Metaheuristics for Machine Learning: Algorithms and Applications</italic> 95&#8211;134 (2024).</mixed-citation></ref><ref id="CR8"><label>8.</label><citation-alternatives><element-citation id="ec-CR8" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shah</surname><given-names>E</given-names></name><name name-style="western"><surname>Maji</surname><given-names>P</given-names></name></person-group><article-title>Multi-view kernel learning for identification of disease genes</article-title><source>IEEE/ACM Trans. Comput. Biol. Bioinf.</source><year>2023</year><volume>20</volume><fpage>2278</fpage><lpage>2290</lpage><pub-id pub-id-type="doi">10.1109/TCBB.2023.3247033</pub-id><pub-id pub-id-type="pmid">37027602</pub-id></element-citation><mixed-citation id="mc-CR8" publication-type="journal">Shah, E. &amp; Maji, P. Multi-view kernel learning for identification of disease genes. <italic toggle="yes">IEEE/ACM Trans. Comput. Biol. Bioinf.</italic><bold>20</bold>, 2278&#8211;2290. 10.1109/TCBB.2023.3247033 (2023).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/TCBB.2023.3247033</pub-id><pub-id pub-id-type="pmid">37027602</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR9"><label>9.</label><citation-alternatives><element-citation id="ec-CR9" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Qiu</surname><given-names>Y</given-names></name><name name-style="western"><surname>Li</surname><given-names>R</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>X</given-names></name></person-group><article-title>Simultaneous svm parameters and feature selection optimization based on improved slime mould algorithm</article-title><source>IEEE Access</source><year>2024</year><volume>12</volume><fpage>18215</fpage><lpage>18236</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2024.3351943</pub-id></element-citation><mixed-citation id="mc-CR9" publication-type="journal">Qiu, Y., Li, R. &amp; Zhang, X. Simultaneous svm parameters and feature selection optimization based on improved slime mould algorithm. <italic toggle="yes">IEEE Access</italic><bold>12</bold>, 18215&#8211;18236. 10.1109/ACCESS.2024.3351943 (2024).</mixed-citation></citation-alternatives></ref><ref id="CR10"><label>10.</label><citation-alternatives><element-citation id="ec-CR10" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bonilla-Huerta</surname><given-names>E</given-names></name><name name-style="western"><surname>Hern&#225;ndez-Montiel</surname><given-names>A</given-names></name><name name-style="western"><surname>Morales-Caporal</surname><given-names>R</given-names></name><name name-style="western"><surname>Arjona-L&#243;pez</surname><given-names>M</given-names></name></person-group><article-title>Hybrid framework using multiple-filters and an embedded approach for an efficient selection and classification of microarray data</article-title><source>IEEE/ACM Trans. Comput. Biol. Bioinform.</source><year>2016</year><volume>13</volume><fpage>12</fpage><lpage>26</lpage><pub-id pub-id-type="pmid">26336138</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/TCBB.2015.2474384</pub-id></element-citation><mixed-citation id="mc-CR10" publication-type="journal">Bonilla-Huerta, E., Hern&#225;ndez-Montiel, A., Morales-Caporal, R. &amp; Arjona-L&#243;pez, M. Hybrid framework using multiple-filters and an embedded approach for an efficient selection and classification of microarray data. <italic toggle="yes">IEEE/ACM Trans. Comput. Biol. Bioinform.</italic><bold>13</bold>, 12&#8211;26 (2016).<pub-id pub-id-type="pmid">26336138</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/TCBB.2015.2474384</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR11"><label>11.</label><citation-alternatives><element-citation id="ec-CR11" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Chen</surname><given-names>Y</given-names></name><name name-style="western"><surname>Li</surname><given-names>Y</given-names></name><name name-style="western"><surname>Narayan</surname><given-names>R</given-names></name><name name-style="western"><surname>Subramanian</surname><given-names>A</given-names></name><name name-style="western"><surname>Xie</surname><given-names>X</given-names></name></person-group><article-title>Gene expression inference with deep learning</article-title><source>Bioinformatics</source><year>2016</year><volume>32</volume><fpage>1832</fpage><lpage>1839</lpage><pub-id pub-id-type="pmid">26873929</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/bioinformatics/btw074</pub-id><pub-id pub-id-type="pmcid">PMC4908320</pub-id></element-citation><mixed-citation id="mc-CR11" publication-type="journal">Chen, Y., Li, Y., Narayan, R., Subramanian, A. &amp; Xie, X. Gene expression inference with deep learning. <italic toggle="yes">Bioinformatics</italic><bold>32</bold>, 1832&#8211;1839 (2016).<pub-id pub-id-type="pmid">26873929</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/bioinformatics/btw074</pub-id><pub-id pub-id-type="pmcid">PMC4908320</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="other">Kurita, T. Principal component analysis (pca). In <italic toggle="yes">Computer Vision: A Reference Guide</italic> 1013&#8211;1016 (Springer, 2021).</mixed-citation></ref><ref id="CR13"><label>13.</label><citation-alternatives><element-citation id="ec-CR13" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mahdavi</surname><given-names>S</given-names></name><name name-style="western"><surname>Rahnamayan</surname><given-names>S</given-names></name><name name-style="western"><surname>Deb</surname><given-names>K</given-names></name></person-group><article-title>Opposition based learning: A literature review</article-title><source>Swarm Evol. Comput.</source><year>2018</year><volume>39</volume><fpage>1</fpage><lpage>23</lpage></element-citation><mixed-citation id="mc-CR13" publication-type="journal">Mahdavi, S., Rahnamayan, S. &amp; Deb, K. Opposition based learning: A literature review. <italic toggle="yes">Swarm Evol. Comput.</italic><bold>39</bold>, 1&#8211;23 (2018).</mixed-citation></citation-alternatives></ref><ref id="CR14"><label>14.</label><citation-alternatives><element-citation id="ec-CR14" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Bartz-Beielstein</surname><given-names>T</given-names></name><name name-style="western"><surname>Branke</surname><given-names>J</given-names></name><name name-style="western"><surname>Mehnen</surname><given-names>J</given-names></name><name name-style="western"><surname>Mersmann</surname><given-names>O</given-names></name></person-group><article-title>Evolutionary algorithms</article-title><source>Wiley Interdiscip. Rev. Data Mining Knowl. Discov.</source><year>2014</year><volume>4</volume><fpage>178</fpage><lpage>195</lpage></element-citation><mixed-citation id="mc-CR14" publication-type="journal">Bartz-Beielstein, T., Branke, J., Mehnen, J. &amp; Mersmann, O. Evolutionary algorithms. <italic toggle="yes">Wiley Interdiscip. Rev. Data Mining Knowl. Discov.</italic><bold>4</bold>, 178&#8211;195 (2014).</mixed-citation></citation-alternatives></ref><ref id="CR15"><label>15.</label><citation-alternatives><element-citation id="ec-CR15" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Alotaibi</surname><given-names>M</given-names></name><etal/></person-group><article-title>Hybrid gwqbba model for optimized classification of attacks in intrusion detection system</article-title><source>Alexand. Eng. J.</source><year>2025</year><volume>116</volume><fpage>9</fpage><lpage>19</lpage></element-citation><mixed-citation id="mc-CR15" publication-type="journal">Alotaibi, M. et al. Hybrid gwqbba model for optimized classification of attacks in intrusion detection system. <italic toggle="yes">Alexand. Eng. J.</italic><bold>116</bold>, 9&#8211;19 (2025).</mixed-citation></citation-alternatives></ref><ref id="CR16"><label>16.</label><citation-alternatives><element-citation id="ec-CR16" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yaqoob</surname><given-names>A</given-names></name><name name-style="western"><surname>Verma</surname><given-names>NK</given-names></name><name name-style="western"><surname>Aziz</surname><given-names>RM</given-names></name><name name-style="western"><surname>Shah</surname><given-names>MA</given-names></name></person-group><article-title>Optimizing cancer classification: a hybrid rdo-xgboost approach for feature selection and predictive insights</article-title><source>Cancer Immunol. Immunother.</source><year>2024</year><volume>73</volume><fpage>261</fpage><pub-id pub-id-type="pmid">39382649</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s00262-024-03843-x</pub-id><pub-id pub-id-type="pmcid">PMC11464649</pub-id></element-citation><mixed-citation id="mc-CR16" publication-type="journal">Yaqoob, A., Verma, N. K., Aziz, R. M. &amp; Shah, M. A. Optimizing cancer classification: a hybrid rdo-xgboost approach for feature selection and predictive insights. <italic toggle="yes">Cancer Immunol. Immunother.</italic><bold>73</bold>, 261 (2024).<pub-id pub-id-type="pmid">39382649</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s00262-024-03843-x</pub-id><pub-id pub-id-type="pmcid">PMC11464649</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR17"><label>17.</label><citation-alternatives><element-citation id="ec-CR17" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yang</surname><given-names>X</given-names></name><name name-style="western"><surname>Che</surname><given-names>H</given-names></name><name name-style="western"><surname>Leung</surname><given-names>M-F</given-names></name></person-group><article-title>Tensor-based unsupervised feature selection for error-robust handling of unbalanced incomplete multi-view data</article-title><source>Inf. Fusion</source><year>2025</year><volume>114</volume><fpage>102693</fpage></element-citation><mixed-citation id="mc-CR17" publication-type="journal">Yang, X., Che, H. &amp; Leung, M.-F. Tensor-based unsupervised feature selection for error-robust handling of unbalanced incomplete multi-view data. <italic toggle="yes">Inf. Fusion</italic><bold>114</bold>, 102693 (2025).</mixed-citation></citation-alternatives></ref><ref id="CR18"><label>18.</label><citation-alternatives><element-citation id="ec-CR18" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yaqoob</surname><given-names>A</given-names></name><name name-style="western"><surname>Verma</surname><given-names>NK</given-names></name></person-group><article-title>Feature selection in breast cancer gene expression data using kao and aoa with svm classification</article-title><source>J. Med. Syst.</source><year>2025</year><volume>49</volume><fpage>1</fpage><lpage>21</lpage><pub-id pub-id-type="pmid">40140121</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s10916-025-02171-6</pub-id></element-citation><mixed-citation id="mc-CR18" publication-type="journal">Yaqoob, A. &amp; Verma, N. K. Feature selection in breast cancer gene expression data using kao and aoa with svm classification. <italic toggle="yes">J. Med. Syst.</italic><bold>49</bold>, 1&#8211;21 (2025).<pub-id pub-id-type="pmid">40140121</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s10916-025-02171-6</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR19"><label>19.</label><citation-alternatives><element-citation id="ec-CR19" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhong</surname><given-names>K</given-names></name><name name-style="western"><surname>Xiao</surname><given-names>F</given-names></name><name name-style="western"><surname>Gao</surname><given-names>X</given-names></name></person-group><article-title>A multi-population competitive evolutionary algorithm based on genotype preference for multimodal multi-objective optimization</article-title><source>Swarm Evol. Comput.</source><year>2025</year><volume>92</volume><fpage>101826</fpage></element-citation><mixed-citation id="mc-CR19" publication-type="journal">Zhong, K., Xiao, F. &amp; Gao, X. A multi-population competitive evolutionary algorithm based on genotype preference for multimodal multi-objective optimization. <italic toggle="yes">Swarm Evol. Comput.</italic><bold>92</bold>, 101826 (2025).</mixed-citation></citation-alternatives></ref><ref id="CR20"><label>20.</label><citation-alternatives><element-citation id="ec-CR20" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tahmouresi</surname><given-names>A</given-names></name><name name-style="western"><surname>Rashedi</surname><given-names>E</given-names></name><name name-style="western"><surname>Yaghoobi</surname><given-names>MM</given-names></name><name name-style="western"><surname>Rezaei</surname><given-names>M</given-names></name></person-group><article-title>Gene selection using pyramid gravitational search algorithm</article-title><source>PLoS ONE</source><year>2022</year><volume>17</volume><fpage>e0265351</fpage><pub-id pub-id-type="pmid">35290401</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1371/journal.pone.0265351</pub-id><pub-id pub-id-type="pmcid">PMC8923457</pub-id></element-citation><mixed-citation id="mc-CR20" publication-type="journal">Tahmouresi, A., Rashedi, E., Yaghoobi, M. M. &amp; Rezaei, M. Gene selection using pyramid gravitational search algorithm. <italic toggle="yes">PLoS ONE</italic><bold>17</bold>, e0265351 (2022).<pub-id pub-id-type="pmid">35290401</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1371/journal.pone.0265351</pub-id><pub-id pub-id-type="pmcid">PMC8923457</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR21"><label>21.</label><citation-alternatives><element-citation id="ec-CR21" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Duval</surname><given-names>B</given-names></name><name name-style="western"><surname>Hao</surname><given-names>J-K</given-names></name></person-group><article-title>Advances in metaheuristics for gene selection and classification of microarray data</article-title><source>Brief. Bioinform.</source><year>2010</year><volume>11</volume><fpage>127</fpage><lpage>141</lpage><pub-id pub-id-type="pmid">19789265</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/bib/bbp035</pub-id></element-citation><mixed-citation id="mc-CR21" publication-type="journal">Duval, B. &amp; Hao, J.-K. Advances in metaheuristics for gene selection and classification of microarray data. <italic toggle="yes">Brief. Bioinform.</italic><bold>11</bold>, 127&#8211;141 (2010).<pub-id pub-id-type="pmid">19789265</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/bib/bbp035</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR22"><label>22.</label><mixed-citation publication-type="other">Yaqoob, A., Verma, N.&#160;K. &amp; Aziz, R.&#160;M. Improving breast cancer classification with mrmr+ ss0+ wsvm: a hybrid approach. In <italic toggle="yes">Multimedia Tools and Applications</italic> 1&#8211;26 (2024).</mixed-citation></ref><ref id="CR23"><label>23.</label><citation-alternatives><element-citation id="ec-CR23" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shukla</surname><given-names>AK</given-names></name></person-group><article-title>Multi-population adaptive genetic algorithm for selection of microarray biomarkers</article-title><source>Neural Comput. Appl.</source><year>2020</year><volume>32</volume><fpage>11897</fpage><lpage>11918</lpage></element-citation><mixed-citation id="mc-CR23" publication-type="journal">Shukla, A. K. Multi-population adaptive genetic algorithm for selection of microarray biomarkers. <italic toggle="yes">Neural Comput. Appl.</italic><bold>32</bold>, 11897&#8211;11918 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR24"><label>24.</label><citation-alternatives><element-citation id="ec-CR24" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Saheed</surname><given-names>YK</given-names></name><name name-style="western"><surname>Balogun</surname><given-names>BF</given-names></name><name name-style="western"><surname>Odunayo</surname><given-names>BJ</given-names></name><name name-style="western"><surname>Abdulsalam</surname><given-names>M</given-names></name></person-group><article-title>Microarray gene expression data classification via Wilcoxon sign rank sum and novel grey wolf optimized ensemble learning models</article-title><source>IEEE/ACM Trans. Comput. Biol. Bioinf.</source><year>2023</year><volume>20</volume><fpage>3575</fpage><lpage>3587</lpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/TCBB.2023.3305429</pub-id><pub-id pub-id-type="pmid">37581968</pub-id></element-citation><mixed-citation id="mc-CR24" publication-type="journal">Saheed, Y. K., Balogun, B. F., Odunayo, B. J. &amp; Abdulsalam, M. Microarray gene expression data classification via Wilcoxon sign rank sum and novel grey wolf optimized ensemble learning models. <italic toggle="yes">IEEE/ACM Trans. Comput. Biol. Bioinf.</italic><bold>20</bold>, 3575&#8211;3587 (2023).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/TCBB.2023.3305429</pub-id><pub-id pub-id-type="pmid">37581968</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR25"><label>25.</label><citation-alternatives><element-citation id="ec-CR25" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Vafashoar</surname><given-names>R</given-names></name><name name-style="western"><surname>Meybodi</surname><given-names>MR</given-names></name></person-group><article-title>A multi-population differential evolution algorithm based on cellular learning automata and evolutionary context information for optimization in dynamic environments</article-title><source>Appl. Soft Comput.</source><year>2020</year><volume>88</volume><fpage>106009</fpage></element-citation><mixed-citation id="mc-CR25" publication-type="journal">Vafashoar, R. &amp; Meybodi, M. R. A multi-population differential evolution algorithm based on cellular learning automata and evolutionary context information for optimization in dynamic environments. <italic toggle="yes">Appl. Soft Comput.</italic><bold>88</bold>, 106009 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR26"><label>26.</label><citation-alternatives><element-citation id="ec-CR26" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Mehta</surname><given-names>S</given-names></name><name name-style="western"><surname>Han</surname><given-names>F</given-names></name><name name-style="western"><surname>Ling</surname><given-names>Q</given-names></name><name name-style="western"><surname>Sohail</surname><given-names>M</given-names></name><name name-style="western"><surname>Nagra</surname><given-names>A</given-names></name></person-group><article-title>Morpso\_ecd+ elm: a unified framework for gene selection and cancer classification</article-title><source>IEEE J. Biomed. Health Inform.</source><year>2025</year><volume>1</volume><fpage>1</fpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/JBHI.2025.3526825</pub-id><pub-id pub-id-type="pmid">40138223</pub-id></element-citation><mixed-citation id="mc-CR26" publication-type="journal">Mehta, S., Han, F., Ling, Q., Sohail, M. &amp; Nagra, A. Morpso_ecd+ elm: a unified framework for gene selection and cancer classification. <italic toggle="yes">IEEE J. Biomed. Health Inform.</italic><bold>1</bold>, 1 (2025).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/JBHI.2025.3526825</pub-id><pub-id pub-id-type="pmid">40138223</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR27"><label>27.</label><citation-alternatives><element-citation id="ec-CR27" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dey</surname><given-names>A</given-names></name><name name-style="western"><surname>Sharma</surname><given-names>KD</given-names></name><name name-style="western"><surname>Sanyal</surname><given-names>T</given-names></name><name name-style="western"><surname>Bhattacharjee</surname><given-names>P</given-names></name></person-group><article-title>Identification of biomarkers for arsenicosis employing multiple kernel learning embedded multiobjective swarm intelligence</article-title><source>IEEE Trans. Nanobiosci.</source><year>2022</year><volume>22</volume><fpage>383</fpage><lpage>392</lpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/TNB.2022.3194091</pub-id><pub-id pub-id-type="pmid">35895661</pub-id></element-citation><mixed-citation id="mc-CR27" publication-type="journal">Dey, A., Sharma, K. D., Sanyal, T. &amp; Bhattacharjee, P. Identification of biomarkers for arsenicosis employing multiple kernel learning embedded multiobjective swarm intelligence. <italic toggle="yes">IEEE Trans. Nanobiosci.</italic><bold>22</bold>, 383&#8211;392 (2022).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/TNB.2022.3194091</pub-id><pub-id pub-id-type="pmid">35895661</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR28"><label>28.</label><mixed-citation publication-type="other">Pashaei, E., Pashaei, E. &amp; Mirjalili, S. Binary hiking optimization for gene selection: Insights from hnscc rna-seq data. In <italic toggle="yes">Expert Systems with Applications</italic> 126404 (2025).</mixed-citation></ref><ref id="CR29"><label>29.</label><citation-alternatives><element-citation id="ec-CR29" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tian</surname><given-names>C</given-names></name><name name-style="western"><surname>Jiao</surname><given-names>L</given-names></name><name name-style="western"><surname>Liu</surname><given-names>F</given-names></name><name name-style="western"><surname>Liu</surname><given-names>X</given-names></name><name name-style="western"><surname>Yang</surname><given-names>S</given-names></name></person-group><article-title>Robust and effective: A deep matrix factorization framework for classification</article-title><source>IEEE Trans. Neural Netw. Learn. Syst.</source><year>2024</year><volume>35</volume><fpage>9958</fpage><lpage>9969</lpage><pub-id pub-id-type="doi">10.1109/TNNLS.2023.3238104</pub-id><pub-id pub-id-type="pmid">37021990</pub-id></element-citation><mixed-citation id="mc-CR29" publication-type="journal">Tian, C., Jiao, L., Liu, F., Liu, X. &amp; Yang, S. Robust and effective: A deep matrix factorization framework for classification. <italic toggle="yes">IEEE Trans. Neural Netw. Learn. Syst.</italic><bold>35</bold>, 9958&#8211;9969. 10.1109/TNNLS.2023.3238104 (2024).<pub-id pub-id-type="pmid">37021990</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/TNNLS.2023.3238104</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR30"><label>30.</label><citation-alternatives><element-citation id="ec-CR30" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pirmoradi</surname><given-names>S</given-names></name><name name-style="western"><surname>Teshnehlab</surname><given-names>M</given-names></name><name name-style="western"><surname>Zarghami</surname><given-names>N</given-names></name><name name-style="western"><surname>Sharifi</surname><given-names>A</given-names></name></person-group><article-title>A self-organizing deep auto-encoder approach for classification of complex diseases using snp genomics data</article-title><source>Appl. Soft Comput.</source><year>2020</year><volume>97</volume><fpage>106718</fpage></element-citation><mixed-citation id="mc-CR30" publication-type="journal">Pirmoradi, S., Teshnehlab, M., Zarghami, N. &amp; Sharifi, A. A self-organizing deep auto-encoder approach for classification of complex diseases using snp genomics data. <italic toggle="yes">Appl. Soft Comput.</italic><bold>97</bold>, 106718 (2020).</mixed-citation></citation-alternatives></ref><ref id="CR31"><label>31.</label><citation-alternatives><element-citation id="ec-CR31" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Jaddi</surname><given-names>NS</given-names></name><etal/></person-group><article-title>Multi-population kidney-inspired algorithm with migration policy selections for feature selection problems</article-title><source>IEEE Access</source><year>2025</year><volume>1</volume><fpage>1</fpage></element-citation><mixed-citation id="mc-CR31" publication-type="journal">Jaddi, N. S. et al. Multi-population kidney-inspired algorithm with migration policy selections for feature selection problems. <italic toggle="yes">IEEE Access</italic><bold>1</bold>, 1 (2025).</mixed-citation></citation-alternatives></ref><ref id="CR32"><label>32.</label><mixed-citation publication-type="other">Yaqoob, A., Verma, N.&#160;K. &amp; Aziz, R.&#160;M. Metaheuristic algorithms and their applications in different fields: a comprehensive review. In <italic toggle="yes">Metaheuristics for Machine Learning: Algorithms and Applications</italic> 1&#8211;35 (2024).</mixed-citation></ref><ref id="CR33"><label>33.</label><citation-alternatives><element-citation id="ec-CR33" publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Yu</surname><given-names>X</given-names></name><name name-style="western"><surname>Gen</surname><given-names>M</given-names></name></person-group><source>Introduction to Evolutionary Algorithms</source><year>2010</year><publisher-name>Springer</publisher-name></element-citation><mixed-citation id="mc-CR33" publication-type="book">Yu, X. &amp; Gen, M. <italic toggle="yes">Introduction to Evolutionary Algorithms</italic> (Springer, 2010).</mixed-citation></citation-alternatives></ref><ref id="CR34"><label>34.</label><citation-alternatives><element-citation id="ec-CR34" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yaqoob</surname><given-names>A</given-names></name><name name-style="western"><surname>Bhat</surname><given-names>MA</given-names></name><name name-style="western"><surname>Khan</surname><given-names>Z</given-names></name></person-group><article-title>Dimensionality reduction techniques and their applications in cancer classification: a comprehensive review</article-title><source>Int. J. Genet. Modif. Recomb.</source><year>2023</year><volume>1</volume><fpage>34</fpage><lpage>45</lpage></element-citation><mixed-citation id="mc-CR34" publication-type="journal">Yaqoob, A., Bhat, M. A. &amp; Khan, Z. Dimensionality reduction techniques and their applications in cancer classification: a comprehensive review. <italic toggle="yes">Int. J. Genet. Modif. Recomb.</italic><bold>1</bold>, 34&#8211;45 (2023).</mixed-citation></citation-alternatives></ref><ref id="CR35"><label>35.</label><mixed-citation publication-type="other">Eberhart, R. &amp; Kennedy, J. Particle swarm optimization. In <italic toggle="yes">Proceedings of the IEEE International Conference on Neural Networks</italic>, vol.&#160;4, 1942&#8211;1948 (Citeseer, 1995).</mixed-citation></ref><ref id="CR36"><label>36.</label><citation-alternatives><element-citation id="ec-CR36" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Liang</surname><given-names>H</given-names></name><name name-style="western"><surname>Pang</surname><given-names>A</given-names></name><name name-style="western"><surname>Lin</surname><given-names>C</given-names></name><name name-style="western"><surname>Zhong</surname><given-names>J</given-names></name></person-group><article-title>A novel hybrid binary bat algorithm for global optimization</article-title><source>Int. J. Swarm Intell. Res.</source><year>2024</year><volume>15</volume><fpage>1</fpage><lpage>29</lpage></element-citation><mixed-citation id="mc-CR36" publication-type="journal">Liang, H., Pang, A., Lin, C. &amp; Zhong, J. A novel hybrid binary bat algorithm for global optimization. <italic toggle="yes">Int. J. Swarm Intell. Res.</italic><bold>15</bold>, 1&#8211;29 (2024).</mixed-citation></citation-alternatives></ref><ref id="CR37"><label>37.</label><citation-alternatives><element-citation id="ec-CR37" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Alomari</surname><given-names>OA</given-names></name><etal/></person-group><article-title>Gene selection for microarray data classification based on gray wolf optimizer enhanced with triz-inspired operators</article-title><source>Knowl.-Based Syst.</source><year>2021</year><volume>223</volume><fpage>107034</fpage><pub-id pub-id-type="doi">10.1016/j.knosys.2021.107034</pub-id></element-citation><mixed-citation id="mc-CR37" publication-type="journal">Alomari, O. A. et al. Gene selection for microarray data classification based on gray wolf optimizer enhanced with triz-inspired operators. <italic toggle="yes">Knowl.-Based Syst.</italic><bold>223</bold>, 107034. 10.1016/j.knosys.2021.107034 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR38"><label>38.</label><citation-alternatives><element-citation id="ec-CR38" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Holland</surname><given-names>JH</given-names></name></person-group><article-title>Genetic algorithms</article-title><source>Sci. Am.</source><year>1992</year><volume>267</volume><fpage>66</fpage><lpage>73</lpage></element-citation><mixed-citation id="mc-CR38" publication-type="journal">Holland, J. H. Genetic algorithms. <italic toggle="yes">Sci. Am.</italic><bold>267</bold>, 66&#8211;73 (1992).1411454
</mixed-citation></citation-alternatives></ref><ref id="CR39"><label>39.</label><citation-alternatives><element-citation id="ec-CR39" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Poli</surname><given-names>R</given-names></name></person-group><article-title>Analysis of the publications on the applications of particle swarm optimisation</article-title><source>J. Artif. Evol. Appl.</source><year>2008</year><volume>2008</volume><fpage>685175</fpage></element-citation><mixed-citation id="mc-CR39" publication-type="journal">Poli, R. Analysis of the publications on the applications of particle swarm optimisation. <italic toggle="yes">J. Artif. Evol. Appl.</italic><bold>2008</bold>, 685175 (2008).</mixed-citation></citation-alternatives></ref><ref id="CR40"><label>40.</label><citation-alternatives><element-citation id="ec-CR40" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Park</surname><given-names>S-Y</given-names></name><name name-style="western"><surname>Lee</surname><given-names>J-J</given-names></name></person-group><article-title>Stochastic opposition-based learning using a beta distribution in differential evolution</article-title><source>IEEE Trans. Cybern.</source><year>2016</year><volume>46</volume><fpage>2184</fpage><lpage>2194</lpage><pub-id pub-id-type="doi">10.1109/TCYB.2015.2469722</pub-id><pub-id pub-id-type="pmid">26390506</pub-id></element-citation><mixed-citation id="mc-CR40" publication-type="journal">Park, S.-Y. &amp; Lee, J.-J. Stochastic opposition-based learning using a beta distribution in differential evolution. <italic toggle="yes">IEEE Trans. Cybern.</italic><bold>46</bold>, 2184&#8211;2194. 10.1109/TCYB.2015.2469722 (2016).<pub-id pub-id-type="pmid">26390506</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/TCYB.2015.2469722</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR41"><label>41.</label><citation-alternatives><element-citation id="ec-CR41" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Abdi</surname><given-names>H</given-names></name><name name-style="western"><surname>Williams</surname><given-names>LJ</given-names></name></person-group><article-title>Principal component analysis</article-title><source>Wiley Interdiscip. Rev. Comput. Stat.</source><year>2010</year><volume>2</volume><fpage>433</fpage><lpage>459</lpage></element-citation><mixed-citation id="mc-CR41" publication-type="journal">Abdi, H. &amp; Williams, L. J. Principal component analysis. <italic toggle="yes">Wiley Interdiscip. Rev. Comput. Stat.</italic><bold>2</bold>, 433&#8211;459 (2010).</mixed-citation></citation-alternatives></ref><ref id="CR42"><label>42.</label><citation-alternatives><element-citation id="ec-CR42" publication-type="book"><person-group person-group-type="author"><name name-style="western"><surname>Biship</surname><given-names>CM</given-names></name></person-group><source>Pattern Recognition and Machine Learning (Information Science and Statistics)</source><year>2007</year><publisher-name>Springer</publisher-name></element-citation><mixed-citation id="mc-CR42" publication-type="book">Biship, C. M. <italic toggle="yes">Pattern Recognition and Machine Learning (Information Science and Statistics)</italic> (Springer, 2007).</mixed-citation></citation-alternatives></ref><ref id="CR43"><label>43.</label><citation-alternatives><element-citation id="ec-CR43" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Zhang</surname><given-names>L</given-names></name><etal/></person-group><article-title>A multi-population based evolutionary algorithm for many-objective recommendations</article-title><source>IEEE Trans. Emerg. Top. Comput. Intell.</source><year>2024</year><volume>1</volume><fpage>1</fpage></element-citation><mixed-citation id="mc-CR43" publication-type="journal">Zhang, L. et al. A multi-population based evolutionary algorithm for many-objective recommendations. <italic toggle="yes">IEEE Trans. Emerg. Top. Comput. Intell.</italic><bold>1</bold>, 1 (2024).</mixed-citation></citation-alternatives></ref><ref id="CR44"><label>44.</label><citation-alternatives><element-citation id="ec-CR44" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yaqoob</surname><given-names>A</given-names></name></person-group><article-title>Combining the mrmr technique with the northern goshawk algorithm (ngha) to choose genes for cancer classification</article-title><source>Int. J. Inf. Technol.</source><year>2024</year><volume>1</volume><fpage>1</fpage><lpage>12</lpage></element-citation><mixed-citation id="mc-CR44" publication-type="journal">Yaqoob, A. Combining the mrmr technique with the northern goshawk algorithm (ngha) to choose genes for cancer classification. <italic toggle="yes">Int. J. Inf. Technol.</italic><bold>1</bold>, 1&#8211;12 (2024).</mixed-citation></citation-alternatives></ref><ref id="CR45"><label>45.</label><citation-alternatives><element-citation id="ec-CR45" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kumar</surname><given-names>A</given-names></name><name name-style="western"><surname>Dutta</surname><given-names>K</given-names></name><name name-style="western"><surname>Srivastava</surname><given-names>A</given-names></name></person-group><article-title>Generating automated layout design using a multi-population genetic algorithm</article-title><source>J. Web Eng.</source><year>2023</year><volume>22</volume><fpage>357</fpage><lpage>384</lpage></element-citation><mixed-citation id="mc-CR45" publication-type="journal">Kumar, A., Dutta, K. &amp; Srivastava, A. Generating automated layout design using a multi-population genetic algorithm. <italic toggle="yes">J. Web Eng.</italic><bold>22</bold>, 357&#8211;384 (2023).</mixed-citation></citation-alternatives></ref><ref id="CR46"><label>46.</label><citation-alternatives><element-citation id="ec-CR46" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Ma</surname><given-names>H</given-names></name><etal/></person-group><article-title>Multi-population techniques in nature inspired optimization algorithms: A comprehensive survey</article-title><source>Swarm Evol. Comput.</source><year>2019</year><volume>44</volume><fpage>365</fpage><lpage>387</lpage></element-citation><mixed-citation id="mc-CR46" publication-type="journal">Ma, H. et al. Multi-population techniques in nature inspired optimization algorithms: A comprehensive survey. <italic toggle="yes">Swarm Evol. Comput.</italic><bold>44</bold>, 365&#8211;387 (2019).</mixed-citation></citation-alternatives></ref><ref id="CR47"><label>47.</label><citation-alternatives><element-citation id="ec-CR47" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Tian</surname><given-names>Y</given-names></name><name name-style="western"><surname>Wang</surname><given-names>R</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>Y</given-names></name><name name-style="western"><surname>Zhang</surname><given-names>X</given-names></name></person-group><article-title>Adaptive population sizing for multi-population based constrained multi-objective optimization</article-title><source>Neurocomputing</source><year>2025</year><volume>1</volume><fpage>129296</fpage></element-citation><mixed-citation id="mc-CR47" publication-type="journal">Tian, Y., Wang, R., Zhang, Y. &amp; Zhang, X. Adaptive population sizing for multi-population based constrained multi-objective optimization. <italic toggle="yes">Neurocomputing</italic><bold>1</bold>, 129296 (2025).</mixed-citation></citation-alternatives></ref><ref id="CR48"><label>48.</label><citation-alternatives><element-citation id="ec-CR48" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Rashedi</surname><given-names>E</given-names></name><name name-style="western"><surname>Nezamabadi-Pour</surname><given-names>H</given-names></name><name name-style="western"><surname>Saryazdi</surname><given-names>S</given-names></name></person-group><article-title>Gsa: A gravitational search algorithm</article-title><source>Inf. Sci.</source><year>2009</year><volume>179</volume><fpage>2232</fpage><lpage>2248</lpage></element-citation><mixed-citation id="mc-CR48" publication-type="journal">Rashedi, E., Nezamabadi-Pour, H. &amp; Saryazdi, S. Gsa: A gravitational search algorithm. <italic toggle="yes">Inf. Sci.</italic><bold>179</bold>, 2232&#8211;2248 (2009).</mixed-citation></citation-alternatives></ref><ref id="CR49"><label>49.</label><citation-alternatives><element-citation id="ec-CR49" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Shukla</surname><given-names>AK</given-names></name><name name-style="western"><surname>Singh</surname><given-names>P</given-names></name><name name-style="western"><surname>Vardhan</surname><given-names>M</given-names></name></person-group><article-title>Hybrid tlbo-gsa strategy for constrained and unconstrained engineering optimization functions</article-title><source>Hybrid Metaheurist. Res. Appl.</source><year>2018</year><volume>84</volume><fpage>41</fpage></element-citation><mixed-citation id="mc-CR49" publication-type="journal">Shukla, A. K., Singh, P. &amp; Vardhan, M. Hybrid tlbo-gsa strategy for constrained and unconstrained engineering optimization functions. <italic toggle="yes">Hybrid Metaheurist. Res. Appl.</italic><bold>84</bold>, 41 (2018).</mixed-citation></citation-alternatives></ref><ref id="CR50"><label>50.</label><mixed-citation publication-type="other">Suthaharan, S. &amp; Suthaharan, S. Support vector machine. In <italic toggle="yes">Machine Learning Models and Algorithms for Big Data Classification: Thinking with Examples for Effective Learning</italic> 207&#8211;235 (2016).</mixed-citation></ref><ref id="CR51"><label>51.</label><citation-alternatives><element-citation id="ec-CR51" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Gao</surname><given-names>L</given-names></name><name name-style="western"><surname>Ye</surname><given-names>M</given-names></name><name name-style="western"><surname>Lu</surname><given-names>X</given-names></name><name name-style="western"><surname>Huang</surname><given-names>D</given-names></name></person-group><article-title>Hybrid method based on information gain and support vector machine for gene selection in cancer classification</article-title><source>Genom. Proteom. Bioinform.</source><year>2017</year><volume>15</volume><fpage>389</fpage><lpage>395</lpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.gpb.2017.08.002</pub-id><pub-id pub-id-type="pmcid">PMC5828665</pub-id><pub-id pub-id-type="pmid">29246519</pub-id></element-citation><mixed-citation id="mc-CR51" publication-type="journal">Gao, L., Ye, M., Lu, X. &amp; Huang, D. Hybrid method based on information gain and support vector machine for gene selection in cancer classification. <italic toggle="yes">Genom. Proteom. Bioinform.</italic><bold>15</bold>, 389&#8211;395 (2017).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.gpb.2017.08.002</pub-id><pub-id pub-id-type="pmcid">PMC5828665</pub-id><pub-id pub-id-type="pmid">29246519</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR52"><label>52.</label><citation-alternatives><element-citation id="ec-CR52" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Dabba</surname><given-names>A</given-names></name><name name-style="western"><surname>Tari</surname><given-names>A</given-names></name><name name-style="western"><surname>Meftali</surname><given-names>S</given-names></name><name name-style="western"><surname>Mokhtari</surname><given-names>R</given-names></name></person-group><article-title>Gene selection and classification of microarray data method based on mutual information and moth flame algorithm</article-title><source>Expert Syst. Appl.</source><year>2021</year><volume>166</volume><fpage>114012</fpage></element-citation><mixed-citation id="mc-CR52" publication-type="journal">Dabba, A., Tari, A., Meftali, S. &amp; Mokhtari, R. Gene selection and classification of microarray data method based on mutual information and moth flame algorithm. <italic toggle="yes">Expert Syst. Appl.</italic><bold>166</bold>, 114012 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR53"><label>53.</label><citation-alternatives><element-citation id="ec-CR53" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Yaqoob</surname><given-names>A</given-names></name><name name-style="western"><surname>Mir</surname><given-names>MA</given-names></name><name name-style="western"><surname>Jagannadha Rao</surname><given-names>G</given-names></name><name name-style="western"><surname>Tejani</surname><given-names>GG</given-names></name></person-group><article-title>Transforming cancer classification: The role of advanced gene selection</article-title><source>Diagnostics</source><year>2024</year><volume>14</volume><fpage>2632</fpage><pub-id pub-id-type="pmid">39682540</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3390/diagnostics14232632</pub-id><pub-id pub-id-type="pmcid">PMC11640257</pub-id></element-citation><mixed-citation id="mc-CR53" publication-type="journal">Yaqoob, A., Mir, M. A., Jagannadha Rao, G. &amp; Tejani, G. G. Transforming cancer classification: The role of advanced gene selection. <italic toggle="yes">Diagnostics</italic><bold>14</bold>, 2632 (2024).<pub-id pub-id-type="pmid">39682540</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.3390/diagnostics14232632</pub-id><pub-id pub-id-type="pmcid">PMC11640257</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR54"><label>54.</label><citation-alternatives><element-citation id="ec-CR54" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Kadota</surname><given-names>M</given-names></name><etal/></person-group><article-title>Identification of novel gene amplifications in breast cancer and coexistence of gene amplification with an activating mutation of pik3ca</article-title><source>Can. Res.</source><year>2009</year><volume>69</volume><fpage>7357</fpage><lpage>7365</lpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.1158/0008-5472.CAN-09-0064</pub-id><pub-id pub-id-type="pmcid">PMC2745517</pub-id><pub-id pub-id-type="pmid">19706770</pub-id></element-citation><mixed-citation id="mc-CR54" publication-type="journal">Kadota, M. et al. Identification of novel gene amplifications in breast cancer and coexistence of gene amplification with an activating mutation of pik3ca. <italic toggle="yes">Can. Res.</italic><bold>69</bold>, 7357&#8211;7365 (2009).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1158/0008-5472.CAN-09-0064</pub-id><pub-id pub-id-type="pmcid">PMC2745517</pub-id><pub-id pub-id-type="pmid">19706770</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR55"><label>55.</label><citation-alternatives><element-citation id="ec-CR55" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Lee</surname><given-names>J</given-names></name><name name-style="western"><surname>Choi</surname><given-names>IY</given-names></name><name name-style="western"><surname>Jun</surname><given-names>C-H</given-names></name></person-group><article-title>An efficient multivariate feature ranking method for gene selection in high-dimensional microarray data</article-title><source>Expert Syst. Appl.</source><year>2021</year><volume>166</volume><fpage>113971</fpage></element-citation><mixed-citation id="mc-CR55" publication-type="journal">Lee, J., Choi, I. Y. &amp; Jun, C.-H. An efficient multivariate feature ranking method for gene selection in high-dimensional microarray data. <italic toggle="yes">Expert Syst. Appl.</italic><bold>166</bold>, 113971 (2021).</mixed-citation></citation-alternatives></ref><ref id="CR56"><label>56.</label><citation-alternatives><element-citation id="ec-CR56" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Almotairi</surname><given-names>KH</given-names></name></person-group><article-title>Gene selection for high-dimensional imbalanced biomedical data based on marine predators algorithm and evolutionary population dynamics</article-title><source>Arab. J. Sci. Eng.</source><year>2024</year><volume>49</volume><fpage>3935</fpage><lpage>3961</lpage></element-citation><mixed-citation id="mc-CR56" publication-type="journal">Almotairi, K. H. Gene selection for high-dimensional imbalanced biomedical data based on marine predators algorithm and evolutionary population dynamics. <italic toggle="yes">Arab. J. Sci. Eng.</italic><bold>49</bold>, 3935&#8211;3961 (2024).</mixed-citation></citation-alternatives></ref><ref id="CR57"><label>57.</label><citation-alternatives><element-citation id="ec-CR57" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pashaei</surname><given-names>E</given-names></name><name name-style="western"><surname>Pashaei</surname><given-names>E</given-names></name><name name-style="western"><surname>Aydin</surname><given-names>N</given-names></name></person-group><article-title>Gene selection using hybrid binary black hole algorithm and modified binary particle swarm optimization</article-title><source>Genomics</source><year>2018</year><volume>1</volume><fpage>1</fpage><pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.ygeno.2018.04.004</pub-id><pub-id pub-id-type="pmid">29660477</pub-id></element-citation><mixed-citation id="mc-CR57" publication-type="journal">Pashaei, E., Pashaei, E. &amp; Aydin, N. Gene selection using hybrid binary black hole algorithm and modified binary particle swarm optimization. <italic toggle="yes">Genomics</italic><bold>1</bold>, 1 (2018).<pub-id pub-id-type="doi" assigning-authority="pmc">10.1016/j.ygeno.2018.04.004</pub-id><pub-id pub-id-type="pmid">29660477</pub-id></mixed-citation></citation-alternatives></ref><ref id="CR58"><label>58.</label><citation-alternatives><element-citation id="ec-CR58" publication-type="journal"><person-group person-group-type="author"><name name-style="western"><surname>Pereira</surname><given-names>DG</given-names></name><name name-style="western"><surname>Afonso</surname><given-names>A</given-names></name><name name-style="western"><surname>Medeiros</surname><given-names>FM</given-names></name></person-group><article-title>Overview of Friedman&#8217;s test and post-hoc analysis</article-title><source>Commun. Stat.-Simul. Comput.</source><year>2015</year><volume>44</volume><fpage>2636</fpage><lpage>2653</lpage></element-citation><mixed-citation id="mc-CR58" publication-type="journal">Pereira, D. G., Afonso, A. &amp; Medeiros, F. M. Overview of Friedman&#8217;s test and post-hoc analysis. <italic toggle="yes">Commun. Stat.-Simul. Comput.</italic><bold>44</bold>, 2636&#8211;2653 (2015).</mixed-citation></citation-alternatives></ref></ref-list></back></article></pmc-articleset>